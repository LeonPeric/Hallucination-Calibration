{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:06.687600300Z",
     "start_time": "2024-05-23T22:34:06.175759Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:06.781100700Z",
     "start_time": "2024-05-23T22:34:06.668101800Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dataset = False\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:08.894101600Z",
     "start_time": "2024-05-23T22:34:06.727603800Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.lib.fact_dataset_generator import FactDatasetGenerator\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "load_model = True\n",
    "load_dataset = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:08.971600700Z",
     "start_time": "2024-05-23T22:34:08.895600700Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.033599300Z",
     "start_time": "2024-05-23T22:34:08.972102300Z"
    }
   },
   "outputs": [],
   "source": [
    "true_dist_size = 1000\n",
    "training_dataset_size = int(0.8 * true_dist_size)\n",
    "alpha = 1\n",
    "dataset = FactDatasetGenerator(number_person=100,  distribution=\"zipf\", dataset_folder='../src/data/', food_list_name=\"food_list_small.txt\",true_dist_size=true_dist_size, experiment_path=\"../src/experiment/small_dataset/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.128097800Z",
     "start_time": "2024-05-23T22:34:09.034600600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "10100\n"
     ]
    }
   ],
   "source": [
    "if load_dataset:\n",
    "    dataset.load_dataset()\n",
    "    true_dist = dataset.true_dist \n",
    "    training_data = dataset.training_data\n",
    "else:\n",
    "    # Generate all possible facts\n",
    "    temp = dataset.generate_all_possibilities()\n",
    "    # Sample true dist (zipf)\n",
    "    true_dist = dataset.generate_true_dist(alpha=alpha)\n",
    "    # Sample training data uniformly, %80 of true dist\n",
    "   \n",
    "    training_data = dataset.sample_training_data(training_dataset_size,true_dist.tolist())\n",
    "    print(dataset.vocab_size)\n",
    "    print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.195601600Z",
     "start_time": "2024-05-23T22:34:09.127098100Z"
    }
   },
   "outputs": [],
   "source": [
    "true_dist_df = pd.DataFrame(true_dist,columns=[\"facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.270098200Z",
     "start_time": "2024-05-23T22:34:09.190099800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       facts\n0      Bendite,beef tartare \n1            El,carrot cake \n2              Shaina,gyoza \n3              Rossy,samosa \n4       Shaun,club sandwich \n..                       ...\n995          Flore,pad thai \n996  Violetta,club sandwich \n997          Mirilla,donuts \n998           Farly,ravioli \n999         Shina,apple pie \n\n[1000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bendite,beef tartare</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>El,carrot cake</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Shaina,gyoza</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rossy,samosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Shaun,club sandwich</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>Violetta,club sandwich</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Mirilla,donuts</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>Farly,ravioli</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>Shina,apple pie</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.377601200Z",
     "start_time": "2024-05-23T22:34:09.267099100Z"
    }
   },
   "outputs": [],
   "source": [
    "true_duplicates_count = true_dist_df.groupby(list(true_dist_df.columns)).size().reset_index(name='count_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.391601700Z",
     "start_time": "2024-05-23T22:34:09.328600200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              facts  count_true\n0              Albertine,apple pie            1\n1           Albertine,beef tartare            1\n2           Albertine,french fries            1\n3              Albertine,ice cream            1\n4    Albertine,spaghetti carbonara            1\n..                              ...         ...\n507              Winfield,tiramisu            1\n508                  Xenos,baklava            1\n509             Xenos,french toast            3\n510               Zeb,cheese plate            1\n511                      Zeb,ramen            1\n\n[512 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,apple pie</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albertine,beef tartare</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albertine,french fries</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albertine,spaghetti carbonara</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>Winfield,tiramisu</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>Xenos,baklava</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>Xenos,french toast</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>Zeb,cheese plate</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>511</th>\n      <td>Zeb,ramen</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>512 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.469601900Z",
     "start_time": "2024-05-23T22:34:09.390101600Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dist_df = pd.DataFrame(training_data,columns=[\"facts\"])\n",
    "training_duplicates_count = training_dist_df.groupby(list(training_dist_df.columns)).size().reset_index(name='count_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.556101700Z",
     "start_time": "2024-05-23T22:34:09.453601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              facts  count_train\n0           Albertine,french fries             1\n1              Albertine,ice cream             1\n2    Albertine,spaghetti carbonara             1\n3               Archibald,omelette             2\n4                  Archibald,pizza             1\n..                              ...          ...\n418         Winfield,seaweed salad             1\n419              Winfield,tiramisu             1\n420                  Xenos,baklava             1\n421             Xenos,french toast             3\n422               Zeb,cheese plate             1\n\n[423 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,french fries</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albertine,spaghetti carbonara</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Archibald,omelette</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Archibald,pizza</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>Winfield,seaweed salad</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>Winfield,tiramisu</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>420</th>\n      <td>Xenos,baklava</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>Xenos,french toast</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>Zeb,cheese plate</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>423 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.631599200Z",
     "start_time": "2024-05-23T22:34:09.514099800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "## get the training  datasets\n",
    "train_dataset = [torch.tensor(x, dtype=torch.long) for x in dataset.tokenized_training_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:09.652598500Z",
     "start_time": "2024-05-23T22:34:09.578099300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataset object at 0x0000026FA3E52100>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "## create a dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Assuming each item in data is a sequence and we use the same sequence shifted by one as the target\n",
    "        x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "\n",
    "## create the datasets\n",
    "train_data = MyDataset(train_dataset)\n",
    "# test_data = MyDataset(test_dataset)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:10.273099700Z",
     "start_time": "2024-05-23T22:34:09.639599800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 37.93M\n"
     ]
    }
   ],
   "source": [
    "## import mingpt\n",
    "sys.path.append('minGPT/')\n",
    "from src.minGPT.mingpt.model import GPT\n",
    "from src.minGPT.mingpt.utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.n_layer=12\n",
    "model_config.n_head=8\n",
    "model_config.n_embd=512\n",
    "model_config.vocab_size = dataset.vocab_size\n",
    "model_config.model_type = None\n",
    "model_config.block_size = 3\n",
    "\n",
    "# model_config.model_type = 'gpt-nano'\n",
    "# model_config.vocab_size = dataset.vocab_size\n",
    "# model_config.block_size = 2\n",
    "\n",
    "model = GPT(model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:34:10.336097600Z",
     "start_time": "2024-05-23T22:34:10.274601700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from src.minGPT.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-5 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 20000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:22.174960400Z",
     "start_time": "2024-05-23T22:34:10.336597600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Batu\\AppData\\Local\\Temp\\ipykernel_38464\\4291040295.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
      "C:\\Users\\Batu\\AppData\\Local\\Temp\\ipykernel_38464\\4291040295.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 5.51930\n",
      "iter_dt 2.75ms; iter 100: train loss 3.13728\n",
      "iter_dt 2.65ms; iter 200: train loss 3.02431\n",
      "iter_dt 2.65ms; iter 300: train loss 2.87767\n",
      "iter_dt 2.70ms; iter 400: train loss 2.99615\n",
      "iter_dt 2.75ms; iter 500: train loss 3.00743\n",
      "iter_dt 2.75ms; iter 600: train loss 2.71108\n",
      "iter_dt 2.65ms; iter 700: train loss 2.94277\n",
      "iter_dt 2.55ms; iter 800: train loss 2.80742\n",
      "iter_dt 2.55ms; iter 900: train loss 2.79740\n",
      "iter_dt 2.80ms; iter 1000: train loss 3.00692\n",
      "iter_dt 2.55ms; iter 1100: train loss 2.72116\n",
      "iter_dt 2.65ms; iter 1200: train loss 2.74233\n",
      "iter_dt 2.60ms; iter 1300: train loss 2.87459\n",
      "iter_dt 2.60ms; iter 1400: train loss 2.74971\n",
      "iter_dt 2.65ms; iter 1500: train loss 2.76788\n",
      "iter_dt 2.65ms; iter 1600: train loss 2.65292\n",
      "iter_dt 2.60ms; iter 1700: train loss 2.67550\n",
      "iter_dt 2.60ms; iter 1800: train loss 2.82998\n",
      "iter_dt 2.60ms; iter 1900: train loss 2.63101\n",
      "iter_dt 2.55ms; iter 2000: train loss 2.72308\n",
      "iter_dt 2.60ms; iter 2100: train loss 2.51961\n",
      "iter_dt 2.60ms; iter 2200: train loss 2.70206\n",
      "iter_dt 2.65ms; iter 2300: train loss 2.72513\n",
      "iter_dt 2.60ms; iter 2400: train loss 2.56392\n",
      "iter_dt 2.60ms; iter 2500: train loss 2.77528\n",
      "iter_dt 2.70ms; iter 2600: train loss 2.86122\n",
      "iter_dt 2.55ms; iter 2700: train loss 2.74193\n",
      "iter_dt 2.65ms; iter 2800: train loss 2.71821\n",
      "iter_dt 2.60ms; iter 2900: train loss 2.65128\n",
      "iter_dt 2.80ms; iter 3000: train loss 2.84493\n",
      "iter_dt 2.60ms; iter 3100: train loss 2.67631\n",
      "iter_dt 2.65ms; iter 3200: train loss 2.66274\n",
      "iter_dt 2.65ms; iter 3300: train loss 2.79436\n",
      "iter_dt 2.65ms; iter 3400: train loss 2.54725\n",
      "iter_dt 2.60ms; iter 3500: train loss 2.73354\n",
      "iter_dt 2.85ms; iter 3600: train loss 2.60160\n",
      "iter_dt 2.55ms; iter 3700: train loss 2.58684\n",
      "iter_dt 2.70ms; iter 3800: train loss 2.66865\n",
      "iter_dt 2.55ms; iter 3900: train loss 2.55735\n",
      "iter_dt 2.70ms; iter 4000: train loss 2.66108\n",
      "iter_dt 2.65ms; iter 4100: train loss 2.74506\n",
      "iter_dt 2.85ms; iter 4200: train loss 2.72706\n",
      "iter_dt 2.60ms; iter 4300: train loss 2.65141\n",
      "iter_dt 2.70ms; iter 4400: train loss 2.66884\n",
      "iter_dt 3.05ms; iter 4500: train loss 2.77568\n",
      "iter_dt 3.10ms; iter 4600: train loss 2.45055\n",
      "iter_dt 2.60ms; iter 4700: train loss 2.84247\n",
      "iter_dt 2.60ms; iter 4800: train loss 2.37787\n",
      "iter_dt 2.60ms; iter 4900: train loss 2.51414\n",
      "iter_dt 2.60ms; iter 5000: train loss 2.70064\n",
      "iter_dt 2.65ms; iter 5100: train loss 2.54381\n",
      "iter_dt 2.70ms; iter 5200: train loss 2.82233\n",
      "iter_dt 2.65ms; iter 5300: train loss 2.74787\n",
      "iter_dt 2.60ms; iter 5400: train loss 2.67492\n",
      "iter_dt 2.80ms; iter 5500: train loss 2.65803\n",
      "iter_dt 2.75ms; iter 5600: train loss 2.74030\n",
      "iter_dt 2.60ms; iter 5700: train loss 2.54893\n",
      "iter_dt 2.60ms; iter 5800: train loss 2.52037\n",
      "iter_dt 2.65ms; iter 5900: train loss 2.74194\n",
      "iter_dt 2.70ms; iter 6000: train loss 2.61513\n",
      "iter_dt 2.85ms; iter 6100: train loss 2.64452\n",
      "iter_dt 2.65ms; iter 6200: train loss 2.66890\n",
      "iter_dt 2.90ms; iter 6300: train loss 2.58947\n",
      "iter_dt 2.65ms; iter 6400: train loss 2.69651\n",
      "iter_dt 2.75ms; iter 6500: train loss 2.66463\n",
      "iter_dt 2.55ms; iter 6600: train loss 2.80122\n",
      "iter_dt 2.85ms; iter 6700: train loss 2.70775\n",
      "iter_dt 2.65ms; iter 6800: train loss 2.66312\n",
      "iter_dt 2.70ms; iter 6900: train loss 2.48184\n",
      "iter_dt 2.65ms; iter 7000: train loss 2.89913\n",
      "iter_dt 3.30ms; iter 7100: train loss 2.82565\n",
      "iter_dt 2.90ms; iter 7200: train loss 2.56959\n",
      "iter_dt 2.75ms; iter 7300: train loss 2.80362\n",
      "iter_dt 2.70ms; iter 7400: train loss 2.72006\n",
      "iter_dt 2.75ms; iter 7500: train loss 2.54206\n",
      "iter_dt 2.75ms; iter 7600: train loss 2.65252\n",
      "iter_dt 2.70ms; iter 7700: train loss 2.54460\n",
      "iter_dt 2.75ms; iter 7800: train loss 2.68063\n",
      "iter_dt 2.75ms; iter 7900: train loss 2.53339\n",
      "iter_dt 2.80ms; iter 8000: train loss 2.49294\n",
      "iter_dt 2.70ms; iter 8100: train loss 2.62640\n",
      "iter_dt 3.00ms; iter 8200: train loss 2.76287\n",
      "iter_dt 2.75ms; iter 8300: train loss 2.73035\n",
      "iter_dt 2.80ms; iter 8400: train loss 2.78509\n",
      "iter_dt 2.70ms; iter 8500: train loss 2.83779\n",
      "iter_dt 2.75ms; iter 8600: train loss 2.58165\n",
      "iter_dt 2.75ms; iter 8700: train loss 2.62974\n",
      "iter_dt 2.75ms; iter 8800: train loss 2.62141\n",
      "iter_dt 2.75ms; iter 8900: train loss 2.79577\n",
      "iter_dt 2.75ms; iter 9000: train loss 2.82760\n",
      "iter_dt 2.80ms; iter 9100: train loss 2.52852\n",
      "iter_dt 2.75ms; iter 9200: train loss 2.67339\n",
      "iter_dt 2.85ms; iter 9300: train loss 2.45761\n",
      "iter_dt 2.75ms; iter 9400: train loss 2.68042\n",
      "iter_dt 2.85ms; iter 9500: train loss 2.86390\n",
      "iter_dt 2.70ms; iter 9600: train loss 2.63697\n",
      "iter_dt 2.70ms; iter 9700: train loss 2.58815\n",
      "iter_dt 2.75ms; iter 9800: train loss 2.73474\n",
      "iter_dt 2.85ms; iter 9900: train loss 2.58188\n",
      "iter_dt 2.65ms; iter 10000: train loss 2.65238\n",
      "iter_dt 2.95ms; iter 10100: train loss 2.75002\n",
      "iter_dt 2.70ms; iter 10200: train loss 2.51555\n",
      "iter_dt 2.70ms; iter 10300: train loss 2.70802\n",
      "iter_dt 2.65ms; iter 10400: train loss 2.66573\n",
      "iter_dt 2.65ms; iter 10500: train loss 2.73421\n",
      "iter_dt 2.80ms; iter 10600: train loss 2.71720\n",
      "iter_dt 2.75ms; iter 10700: train loss 2.55939\n",
      "iter_dt 2.80ms; iter 10800: train loss 2.57172\n",
      "iter_dt 2.75ms; iter 10900: train loss 2.62826\n",
      "iter_dt 2.80ms; iter 11000: train loss 2.83900\n",
      "iter_dt 2.75ms; iter 11100: train loss 2.57197\n",
      "iter_dt 2.70ms; iter 11200: train loss 2.78014\n",
      "iter_dt 2.65ms; iter 11300: train loss 2.69849\n",
      "iter_dt 2.80ms; iter 11400: train loss 2.88312\n",
      "iter_dt 3.00ms; iter 11500: train loss 2.67511\n",
      "iter_dt 2.65ms; iter 11600: train loss 2.43006\n",
      "iter_dt 2.75ms; iter 11700: train loss 2.77962\n",
      "iter_dt 2.85ms; iter 11800: train loss 2.92708\n",
      "iter_dt 2.70ms; iter 11900: train loss 2.61650\n",
      "iter_dt 2.65ms; iter 12000: train loss 2.54761\n",
      "iter_dt 2.95ms; iter 12100: train loss 2.75927\n",
      "iter_dt 3.50ms; iter 12200: train loss 2.68430\n",
      "iter_dt 3.00ms; iter 12300: train loss 2.64955\n",
      "iter_dt 3.10ms; iter 12400: train loss 3.00310\n",
      "iter_dt 2.65ms; iter 12500: train loss 2.70504\n",
      "iter_dt 2.65ms; iter 12600: train loss 2.71657\n",
      "iter_dt 2.70ms; iter 12700: train loss 2.76245\n",
      "iter_dt 2.65ms; iter 12800: train loss 2.69961\n",
      "iter_dt 2.75ms; iter 12900: train loss 2.70592\n",
      "iter_dt 2.65ms; iter 13000: train loss 2.66475\n",
      "iter_dt 2.70ms; iter 13100: train loss 2.68466\n",
      "iter_dt 2.65ms; iter 13200: train loss 2.72786\n",
      "iter_dt 2.70ms; iter 13300: train loss 2.70438\n",
      "iter_dt 2.65ms; iter 13400: train loss 2.64067\n",
      "iter_dt 2.65ms; iter 13500: train loss 2.67888\n",
      "iter_dt 2.70ms; iter 13600: train loss 2.81010\n",
      "iter_dt 2.70ms; iter 13700: train loss 2.54218\n",
      "iter_dt 2.65ms; iter 13800: train loss 2.66115\n",
      "iter_dt 2.80ms; iter 13900: train loss 2.60785\n",
      "iter_dt 2.65ms; iter 14000: train loss 2.68817\n",
      "iter_dt 3.50ms; iter 14100: train loss 2.73304\n",
      "iter_dt 2.65ms; iter 14200: train loss 2.61565\n",
      "iter_dt 2.80ms; iter 14300: train loss 2.58996\n",
      "iter_dt 2.60ms; iter 14400: train loss 2.71118\n",
      "iter_dt 2.85ms; iter 14500: train loss 2.64601\n",
      "iter_dt 2.60ms; iter 14600: train loss 2.66987\n",
      "iter_dt 3.15ms; iter 14700: train loss 2.77810\n",
      "iter_dt 2.85ms; iter 14800: train loss 2.77628\n",
      "iter_dt 2.80ms; iter 14900: train loss 2.68348\n",
      "iter_dt 2.65ms; iter 15000: train loss 2.56930\n",
      "iter_dt 2.70ms; iter 15100: train loss 2.63355\n",
      "iter_dt 2.55ms; iter 15200: train loss 2.63177\n",
      "iter_dt 2.70ms; iter 15300: train loss 2.78089\n",
      "iter_dt 2.70ms; iter 15400: train loss 2.53099\n",
      "iter_dt 2.70ms; iter 15500: train loss 2.50479\n",
      "iter_dt 2.75ms; iter 15600: train loss 2.73413\n",
      "iter_dt 2.70ms; iter 15700: train loss 2.58818\n",
      "iter_dt 2.65ms; iter 15800: train loss 2.60238\n",
      "iter_dt 2.75ms; iter 15900: train loss 2.77425\n",
      "iter_dt 2.65ms; iter 16000: train loss 2.61201\n",
      "iter_dt 2.70ms; iter 16100: train loss 2.69632\n",
      "iter_dt 2.75ms; iter 16200: train loss 2.56940\n",
      "iter_dt 2.85ms; iter 16300: train loss 2.65888\n",
      "iter_dt 2.65ms; iter 16400: train loss 2.55476\n",
      "iter_dt 2.60ms; iter 16500: train loss 2.72107\n",
      "iter_dt 3.35ms; iter 16600: train loss 2.63085\n",
      "iter_dt 3.35ms; iter 16700: train loss 2.69515\n",
      "iter_dt 2.70ms; iter 16800: train loss 2.68982\n",
      "iter_dt 2.70ms; iter 16900: train loss 2.77016\n",
      "iter_dt 2.80ms; iter 17000: train loss 2.80493\n",
      "iter_dt 2.75ms; iter 17100: train loss 2.69870\n",
      "iter_dt 2.90ms; iter 17200: train loss 2.57407\n",
      "iter_dt 2.80ms; iter 17300: train loss 2.58827\n",
      "iter_dt 2.65ms; iter 17400: train loss 2.77990\n",
      "iter_dt 2.75ms; iter 17500: train loss 2.58208\n",
      "iter_dt 2.65ms; iter 17600: train loss 2.65112\n",
      "iter_dt 2.80ms; iter 17700: train loss 2.55016\n",
      "iter_dt 2.65ms; iter 17800: train loss 2.56780\n",
      "iter_dt 2.70ms; iter 17900: train loss 2.81819\n",
      "iter_dt 3.00ms; iter 18000: train loss 2.80716\n",
      "iter_dt 2.80ms; iter 18100: train loss 2.78716\n",
      "iter_dt 2.80ms; iter 18200: train loss 2.72405\n",
      "iter_dt 2.70ms; iter 18300: train loss 2.76762\n",
      "iter_dt 2.70ms; iter 18400: train loss 2.75950\n",
      "iter_dt 2.80ms; iter 18500: train loss 2.82695\n",
      "iter_dt 2.65ms; iter 18600: train loss 2.73070\n",
      "iter_dt 3.15ms; iter 18700: train loss 2.60433\n",
      "iter_dt 2.70ms; iter 18800: train loss 2.51809\n",
      "iter_dt 2.75ms; iter 18900: train loss 2.72311\n",
      "iter_dt 2.85ms; iter 19000: train loss 2.59255\n",
      "iter_dt 2.85ms; iter 19100: train loss 2.55380\n",
      "iter_dt 2.65ms; iter 19200: train loss 2.78532\n",
      "iter_dt 2.65ms; iter 19300: train loss 2.73748\n",
      "iter_dt 2.70ms; iter 19400: train loss 2.54805\n",
      "iter_dt 2.70ms; iter 19500: train loss 2.72825\n",
      "iter_dt 2.65ms; iter 19600: train loss 2.80892\n",
      "iter_dt 2.65ms; iter 19700: train loss 2.47482\n",
      "iter_dt 2.75ms; iter 19800: train loss 2.85013\n",
      "iter_dt 2.90ms; iter 19900: train loss 2.70500\n",
      "Best loss is: 2.377873420715332 on epoch: 4800\n"
     ]
    }
   ],
   "source": [
    "best_iter = 100000000000000\n",
    "best_epoch = 0\n",
    "def batch_end_callback(trainer):\n",
    "    global best_iter\n",
    "    global best_epoch\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 100:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "        if trainer.loss.item() < best_iter:\n",
    "            best_iter = trainer.loss.item()\n",
    "            best_epoch = trainer.iter_num\n",
    "            torch.save(model.state_dict(), dataset.experiment_path[:-5] + \"model.pt\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(dataset.experiment_path[:-5]+ \"model.pt\"))\n",
    "else:\n",
    "    trainer.run()\n",
    "    print(f\"Best loss is: {best_iter} on epoch: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:22.268462400Z",
     "start_time": "2024-05-23T22:43:22.166960500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GPT(\n  (transformer): ModuleDict(\n    (wte): Embedding(202, 512)\n    (wpe): Embedding(3, 512)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x Block(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): CausalSelfAttention(\n          (c_attn): Linear(in_features=512, out_features=1536, bias=True)\n          (c_proj): Linear(in_features=512, out_features=512, bias=True)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): ModuleDict(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (act): NewGELU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=512, out_features=202, bias=False)\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's perform some evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate unconditioned facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:22.646459800Z",
     "start_time": "2024-05-23T22:43:22.259462300Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.292456500Z",
     "start_time": "2024-05-23T22:43:22.647460300Z"
    }
   },
   "outputs": [],
   "source": [
    "n_sequences = 1000\n",
    "from collections import defaultdict\n",
    "collected_generations = []\n",
    "\n",
    "for _ in range(n_sequences):\n",
    "    x = torch.Tensor([0]).unsqueeze(0).long().to(device)\n",
    "    y_gen = model.generate(x, 2, do_sample=True)\n",
    "    name = food_item = dataset.decode([y_gen[0][1]])[0]\n",
    "    food_item = dataset.decode([y_gen[0][2]])[0]\n",
    "    collected_generations.append(f\"{name},{food_item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.385458Z",
     "start_time": "2024-05-23T22:43:43.292456500Z"
    }
   },
   "outputs": [],
   "source": [
    "collected_generations_df = pd.DataFrame(collected_generations, columns=[\"facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.477959400Z",
     "start_time": "2024-05-23T22:43:43.385458Z"
    }
   },
   "outputs": [],
   "source": [
    "collected_generations_counts = collected_generations_df.groupby(list(collected_generations_df.columns)).size().reset_index(name='count_generated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.570958900Z",
     "start_time": "2024-05-23T22:43:43.478458900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 facts  count_generated\n0                 Albertine,ice cream                 1\n1                  Archibald,omelette                 6\n2                     Archibald,pizza                 1\n3                Arlen,chocolate cake                 2\n4               Astrix,baby back ribs                 1\n..                                 ...              ...\n330  lasagna ,grilled cheese sandwich                 1\n331               macarons ,guacamole                 1\n332              miso soup ,escargots                 1\n333             poutine ,clam chowder                 1\n334             ramen ,chocolate cake                 1\n\n[335 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Archibald,omelette</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Archibald,pizza</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arlen,chocolate cake</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Astrix,baby back ribs</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>lasagna ,grilled cheese sandwich</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>macarons ,guacamole</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>miso soup ,escargots</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>poutine ,clam chowder</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>ramen ,chocolate cake</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>335 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_generations_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.662958200Z",
     "start_time": "2024-05-23T22:43:43.570958900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge true dist and training dist dataframes, outer is used to include data that is not in training data as well\n",
    "merged_df = pd.merge(true_duplicates_count, training_duplicates_count, on='facts', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.756956600Z",
     "start_time": "2024-05-23T22:43:43.663958100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add generated_df to true and training dfs \n",
    "# outer can be used to include all facts in true dist\n",
    "# inner can be used to only show the comparison of generated facts\n",
    "comparison_df = pd.merge(merged_df, collected_generations_counts, on='facts', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.850456600Z",
     "start_time": "2024-05-23T22:43:43.757456900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 facts  count_true  count_train  \\\n0                 Albertine,apple pie          1.0          NaN   \n1              Albertine,beef tartare          1.0          NaN   \n2              Albertine,french fries          1.0          1.0   \n3                 Albertine,ice cream          1.0          1.0   \n4       Albertine,spaghetti carbonara          1.0          1.0   \n..                                 ...         ...          ...   \n541  lasagna ,grilled cheese sandwich          NaN          NaN   \n542               macarons ,guacamole          NaN          NaN   \n543              miso soup ,escargots          NaN          NaN   \n544             poutine ,clam chowder          NaN          NaN   \n545             ramen ,chocolate cake          NaN          NaN   \n\n     count_generated  \n0                NaN  \n1                NaN  \n2                NaN  \n3                1.0  \n4                NaN  \n..               ...  \n541              1.0  \n542              1.0  \n543              1.0  \n544              1.0  \n545              1.0  \n\n[546 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n      <th>count_train</th>\n      <th>count_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,apple pie</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albertine,beef tartare</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albertine,french fries</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albertine,ice cream</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albertine,spaghetti carbonara</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>lasagna ,grilled cheese sandwich</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>542</th>\n      <td>macarons ,guacamole</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>543</th>\n      <td>miso soup ,escargots</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>544</th>\n      <td>poutine ,clam chowder</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>545</th>\n      <td>ramen ,chocolate cake</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>546 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:43.944456100Z",
     "start_time": "2024-05-23T22:43:43.850456600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in 0 for facts that not appear\n",
    "comparison_df = comparison_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:44.034958800Z",
     "start_time": "2024-05-23T22:43:43.942456500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the counts by length\n",
    "comparison_df[\"count_generated\"] = comparison_df['count_generated']/len(collected_generations)\n",
    "comparison_df[\"count_train\"] = comparison_df['count_train']/len(training_data)\n",
    "comparison_df[\"count_true\"] = comparison_df['count_true']/len(true_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:44.128454500Z",
     "start_time": "2024-05-23T22:43:44.035958300Z"
    }
   },
   "outputs": [],
   "source": [
    "comparison_df = comparison_df.sort_values(by=['count_generated'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:44.221456300Z",
     "start_time": "2024-05-23T22:43:44.131958900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                    facts  count_true  count_train  count_generated\n188       Flore,pad thai        0.112      0.11250            0.101\n337       Mirilla,donuts        0.059      0.06375            0.066\n444  Shaun,club sandwich        0.046      0.03875            0.040\n243      Jeffie,macarons        0.016      0.01750            0.022\n260       Juliana,waffles       0.018      0.01750            0.019\n..                    ...         ...          ...              ...\n151        Enid,tiramisu        0.001      0.00125            0.000\n380    Nicol,peking duck        0.001      0.00000            0.000\n383    Ninnetta,beignets        0.001      0.00000            0.000\n386       Olga,foie gras        0.001      0.00125            0.000\n0    Albertine,apple pie        0.001      0.00000            0.000\n\n[546 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n      <th>count_train</th>\n      <th>count_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>188</th>\n      <td>Flore,pad thai</td>\n      <td>0.112</td>\n      <td>0.11250</td>\n      <td>0.101</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>Mirilla,donuts</td>\n      <td>0.059</td>\n      <td>0.06375</td>\n      <td>0.066</td>\n    </tr>\n    <tr>\n      <th>444</th>\n      <td>Shaun,club sandwich</td>\n      <td>0.046</td>\n      <td>0.03875</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>243</th>\n      <td>Jeffie,macarons</td>\n      <td>0.016</td>\n      <td>0.01750</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>Juliana,waffles</td>\n      <td>0.018</td>\n      <td>0.01750</td>\n      <td>0.019</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>Enid,tiramisu</td>\n      <td>0.001</td>\n      <td>0.00125</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>Nicol,peking duck</td>\n      <td>0.001</td>\n      <td>0.00000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>383</th>\n      <td>Ninnetta,beignets</td>\n      <td>0.001</td>\n      <td>0.00000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>Olga,foie gras</td>\n      <td>0.001</td>\n      <td>0.00125</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Albertine,apple pie</td>\n      <td>0.001</td>\n      <td>0.00000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n<p>546 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:44.314955900Z",
     "start_time": "2024-05-23T22:43:44.221958500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "facts              Flore,pad thai Mirilla,donuts Shaun,club sandw...\ncount_true                                                       1.0\ncount_train                                                      1.0\ncount_generated                                                  1.0\ndtype: object"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.042455700Z",
     "start_time": "2024-05-23T22:43:44.316958700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x400 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABRUAAAFsCAYAAABSGl5pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6O0lEQVR4nO3dd3wU1fr48Wc3bRMgAQMktBQhUi5IBylKEQ3KFbAAokixgCgKokj5Ui0UCxcUlYtXEAtSvIgFhUv1SlEkCIICKr0FsCUQTILk+f3BL3MzZBNyJslmwc/79doX7M6ZOefMzDlz5skUl6qqAAAAAAAAAEABuUu6AAAAAAAAAAAuLQQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYCSwpAtQFLKysuTo0aNSpkwZcblcJV0cAAAAAAAA4JKiqnLq1CmpXLmyuN0Xvw7xsggqHj16VKpVq1bSxQAAAAAAAAAuaYcOHZKqVateNN1lEVQsU6aMiJyvdHh4eAmXBgAAAAAAALi0pKamSrVq1aw428VcFkHF7Fuew8PDCSoCAAAAAAAADhX00YK8qAUAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABg5LJ4piIAAAAAAIC/OXfunJw9e7akiwFYAgICJDAwsMDPTcwPQUUAAAAAAIAidvr0aTl8+LCoakkXBbAJCwuTSpUqSXBwcKGWQ1ARAAAAAACgCJ07d04OHz4sYWFhUqFChSK5KgwoLFWVzMxMOXnypOzbt08SEhLE7Xb+ZESCigAAAAAAAEXo7NmzoqpSoUIFCQ0NLeniAJbQ0FAJCgqSAwcOSGZmpng8HsfL4kUtAAAAAAAAxYArFOGPCnN1om05RbIUAAAAAAAAAH8ZBBUBAAAAAAAAGOGZigAAAAAAAD4QN2KpT/PbP7mTT/PDX8vlf6Xi+IjzHwAAAAAAAPi1/fv3i8vlkq1btxZ4nr59+0rXrl2LrUzw7vIPKgIAAAAAAOAv7+zZsyVdhMvKZRtUjBux1OeXFQMAAAAAAFzKsrKy5LnnnpMaNWpISEiIxMTEyLPPPisiItu3b5f27dtLaGioREZGSv/+/eX06dPWvG3btpUhQ4bYlte1a1fp27ev9T0uLk4mTpwo9957r5QpU0ZiYmJk1qxZ1vT4+HgREWnYsKG4XC5p27ZtvuUdP368zJ07Vz788ENxuVzicrlk7dq11hWPCxYskDZt2ojH45F3331Xxo8fLw0aNLAtY9q0aRIXF2f77V//+pfUrl1bPB6P1KpVS1599dWCrcC/kMs2qAgAAAAAAAAzI0eOlMmTJ8uYMWPk+++/l3nz5klUVJSkpaVJYmKilCtXTr7++mtZtGiRrFy5UgYNGmScx4svvihNmjSRb775Rh566CEZOHCg7N69W0RENm3aJCIiK1eulGPHjsnixYvzXdYTTzwh3bt3l44dO8qxY8fk2LFj0rJlS2v6iBEjZPDgwbJz505JTEwsUPneffddGTt2rDz77LOyc+dOmThxoowZM0bmzp1rXNfLGS9qAQAAAAAAgJw6dUqmT58uM2bMkD59+oiISPXq1aV169by+uuvS3p6urz11ltSqlQpERGZMWOG3HLLLTJlyhSJiooqcD4333yzPPTQQyIiMnz4cPnHP/4ha9askZo1a0qFChVERCQyMlKio6MvuqzSpUtLaGioZGRkeE0/ZMgQue222wpcNhGRcePGyYsvvmjNFx8fL99//73885//tNYLCCoCAAAAAABARHbu3CkZGRly/fXXe51Wv359K6AoItKqVSvJysqS3bt3GwUVr776auv/LpdLoqOj5cSJE4UrfB6aNGlilD4tLU327Nkj9913nzzwwAPW73/++adERPAi4JwIKgIAAAAAAEBCQ0MLNb/b7RZVtf3m7eUoQUFBtu8ul0uysrIKlXdecgZBRS5exuxnRL7++uvSvHlzW7qAgIBiKeOlimcqAgAAAAAAQBISEiQ0NFRWrVqVa1rt2rVl27ZtkpaWZv22fv16cbvdUrNmTRERqVChghw7dsyafu7cOdmxY4dRGYKDg615TeYpaPoKFSpIcnKyLbC4detW6/9RUVFSuXJl2bt3r9SoUcP2yX6JDM7jSkUAAAAAAACIx+OR4cOHy5NPPinBwcHSqlUrOXnypHz33Xdy9913y7hx46RPnz4yfvx4OXnypDzyyCNyzz33WLc+t2/fXoYOHSpLly6V6tWry9SpU+X33383KkPFihUlNDRUli1bJlWrVhWPx3PR247j4uJk+fLlsnv3bomMjMw3fdu2beXkyZPy3HPPyR133CHLli2Tzz77TMLDw600EyZMkEcffVQiIiKkY8eOkpGRIZs3b5bffvtNhg4dalSfyxlBRQAAAAAAAB/YP7lTSRfhosaMGSOBgYEyduxYOXr0qFSqVEkefPBBCQsLk+XLl8vgwYOladOmEhYWJrfffrtMnTrVmvfee++Vbdu2Se/evSUwMFAee+wxadeunVH+gYGB8tJLL8lTTz0lY8eOlWuvvVbWrl2b7zwPPPCArF27Vpo0aSKnT5+WNWvWSFxcnNe0tWvXlldffVUmTpwoTz/9tNx+++3yxBNPyKxZs6w0999/v4SFhcnzzz8vw4YNk1KlSkm9evVkyJAhRnW53Ln0whvJL0GpqakSEREhKSkpVmQ5bsRSERHZ77nrfKLxKSVVPAAAAAAA8BeSnp4u+/btk/j4ePF4PCVdHMAmr/3TW3wtPzxTEQAAAAAAAIARgooAAAAAAADwW6VLl87z88UXX5R08f6yeKYiAAAAAAAA/FbOtzNfqEqVKr4rCGwIKgIAAAAAAMBv1ahRo6SLAC+4/RkAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABghKAiAAAAAAAAACMEFQEAAAAAAAAYIagIAAAAAAAA/H9t27aVIUOGlHQx/F5gSRcAAAAAAADgL2F8hI/zS/FtfkVg//79Eh8fL9988400aNCgQPP07dtXfv/9d1myZEmRlGHx4sUSFBRUJMu6nBFUBAAAAAAAwGXv7NmzBQoWXnHFFT4ozaWP258BAAAAAAAgIiJZWVny3HPPSY0aNSQkJERiYmLk2WefFRGR7du3S/v27SU0NFQiIyOlf//+cvr0aWteb7cNd+3aVfr27Wt9j4uLk4kTJ8q9994rZcqUkZiYGJk1a5Y1PT4+XkREGjZsKC6XS9q2bZtvecePHy9z586VDz/8UFwul7hcLlm7dq3s379fXC6XLFiwQNq0aSMej0feffdd+eWXX6Rnz55SpUoVCQsLk3r16sl7771nW+aF9bhYmf+qCCoCAAAAAABARERGjhwpkydPljFjxsj3338v8+bNk6ioKElLS5PExEQpV66cfP3117Jo0SJZuXKlDBo0yDiPF198UZo0aSLffPONPPTQQzJw4EDZvXu3iIhs2rRJRERWrlwpx44dk8WLF+e7rCeeeEK6d+8uHTt2lGPHjsmxY8ekZcuW1vQRI0bI4MGDZefOnZKYmCjp6enSuHFjWbp0qezYsUP69+8v99xzj5WvkzL/VXH7MwAAAAAAAOTUqVMyffp0mTFjhvTp00dERKpXry6tW7eW119/XdLT0+Wtt96SUqVKiYjIjBkz5JZbbpEpU6ZIVFRUgfO5+eab5aGHHhIRkeHDh8s//vEPWbNmjdSsWVMqVKggIiKRkZESHR190WWVLl1aQkNDJSMjw2v6IUOGyG233Wb77YknnrD+/8gjj8jy5ctl4cKF0qxZM0dl/qsiqAgAAAAAAADZuXOnZGRkyPXXX+91Wv369a2AoohIq1atJCsrS3bv3m0UVLz66qut/7tcLomOjpYTJ04UrvB5aNKkie37uXPnZOLEibJw4UI5cuSIZGZmSkZGhoSFhflNmS8VBBUBAAAAAAAgoaGhhZrf7XaLqtp+O3v2bK50F74sxeVySVZWVqHyzkvOIKiIyPPPPy/Tp0+XadOmSb169aRUqVIyZMgQyczMzHc5vizzpYJnKgIAAAAAAEASEhIkNDRUVq1alWta7dq1Zdu2bZKWlmb9tn79enG73dYtwBUqVJBjx45Z08+dOyc7duwwKkNwcLA1r8k8BU2/fv166dKli/Tq1Uvq168vV155pfzwww9GZcR5joKKr7zyisTFxYnH45HmzZvn+zDL7777Tm6//XaJi4sTl8sl06ZNK/QyAQAAAAAAULQ8Ho8MHz5cnnzySXnrrbdkz5498uWXX8obb7whd999t3g8HunTp4/s2LFD1qxZI4888ojcc8891q3P7du3l6VLl8rSpUtl165dMnDgQPn999+NylCxYkUJDQ2VZcuWyfHjxyUlJeWi88TFxcm3334ru3fvlp9//tnr1ZHZEhISZMWKFbJhwwbZuXOnDBgwQI4fP25URpxnfPvzggULZOjQoTJz5kxp3ry5TJs2TRITE2X37t1SsWLFXOnPnDkjV155pXTr1k0ee+yxIlmmE/Xm1hMRke19thfJ8gAAAAAAAIyMv3iArKSNGTNGAgMDZezYsXL06FGpVKmSPPjggxIWFibLly+XwYMHS9OmTSUsLExuv/12mTp1qjXvvffeK9u2bZPevXtLYGCgPPbYY9KuXTuj/AMDA+Wll16Sp556SsaOHSvXXnutrF27Nt95HnjgAVm7dq00adJETp8+LWvWrJG4uDivaUePHi179+6VxMRECQsLk/79+0vXrl0LFLyEnUsvvNn9Ipo3by5NmzaVGTNmiIhIVlaWVKtWTR555BEZMWJEvvPGxcXJkCFDZMiQIUW2TBGR1NRUiYiIkJSUFAkPDz+f14ilIiKy33OXiIjUi48REYKKAAAAAACgeKWnp8u+ffskPj5ePB5PSRcHsMlr//QWX8uP0e3PmZmZkpSUJB06dPjfAtxu6dChg2zcuNFkUYVaZkZGhqSmpto+AAAAAAAAAHzDKKj4888/y7lz53K9JjwqKkqSk5MdFcDJMidNmiQRERHWp1q1ao7yBgAAAAAAgH8rXbp0np8vvviipIv3l2X8TEV/MHLkSBk6dKj1PTU1lcAiAAAAAADAZWjr1q15TqtSpYrvCgIbo6Bi+fLlJSAgINdbcY4fPy7R0dGOCuBkmSEhIRISEuIoPwAAAAAAAFw6atSoUdJFgBdGtz8HBwdL48aNZdWqVdZvWVlZsmrVKmnRooWjAhTHMgEAAAAAAAAUH+Pbn4cOHSp9+vSRJk2aSLNmzWTatGmSlpYm/fr1ExGR3r17S5UqVWTSpEkicv5FLN9//731/yNHjsjWrVuldOnSVqT5YssEAAAAAAAA4D+Mg4o9evSQkydPytixYyU5OVkaNGggy5Yts160cvDgQXG7/3cB5NGjR6Vhw4bW9xdeeEFeeOEFadOmjaxdu7ZAywQAAAAAAADgP1yqqiVdiMJKTU2ViIgISUlJkfDwcBERiRuxVERE9nvuEhGRevExIiKyvc/2kikkAAAAAAD4S0hPT5d9+/ZJfHy8eDyeki4OYJPX/uktvpYfo2cqAgAAAAAAAABBRQAAAAAAAOAy0bdvX+natWux52P8TEUAAAAAAACYqze3nk/zuxQfAbd//36Jj4+Xb775Rho0aFDSxfGZvn37yu+//y5Lliwp6aIUGFcqAgAAAAAAAMXg7NmzJV2EYkNQEQAAAAAAACIikpWVJc8995zUqFFDQkJCJCYmRp599lkREdm+fbu0b99eQkNDJTIyUvr37y+nT5+25m3btq0MGTLEtryuXbtK3759re9xcXEyceJEuffee6VMmTISExMjs2bNsqbHx8eLiEjDhg3F5XJJ27ZtL1rmP//8Ux599FEpW7asREZGyvDhw6VPnz62W4CzsrJk0qRJEh8fL6GhoVK/fn15//33relr164Vl8slq1atkiZNmkhYWJi0bNlSdu/ebcvrww8/lEaNGonH45Err7xSJkyYIH/++ac13eVyyWuvvSadO3eWUqVKybPPPivnzp2T++67z8q7Zs2aMn36dGue8ePHy9y5c+XDDz8Ul8slLpdL1q5dKyIihw4dku7du0vZsmXliiuukC5dusj+/futec+dOydDhw616v7kk0+Kr97JTFARAAAAAAAAIiIycuRImTx5sowZM0a+//57mTdvnkRFRUlaWpokJiZKuXLl5Ouvv5ZFixbJypUrZdCgQcZ5vPjii9KkSRP55ptv5KGHHpKBAwdawbtNmzaJiMjKlSvl2LFjsnjx4osub8qUKfLuu+/KnDlzZP369ZKamprrNuJJkybJW2+9JTNnzpTvvvtOHnvsMenVq5d8/vnntnT/93//Jy+++KJs3rxZAgMD5d5777WmffHFF9K7d28ZPHiwfP/99/LPf/5T3nzzTSvomm38+PFy6623yvbt2+Xee++VrKwsqVq1qixatEi+//57GTt2rIwaNUoWLlwoIiJPPPGEdO/eXTp27CjHjh2TY8eOScuWLeXs2bOSmJgoZcqUkS+++ELWr18vpUuXlo4dO0pmZqa1Lt98802ZPXu2rFu3Tn799Vf54IMPzDaIQzxTEQAAAAAAAHLq1CmZPn26zJgxQ/r06SMiItWrV5fWrVvL66+/Lunp6fLWW29JqVKlRERkxowZcsstt8iUKVMkKiqqwPncfPPN8tBDD4mIyPDhw+Uf//iHrFmzRmrWrCkVKlQQEZHIyEiJjo4u0PJefvllGTlypNx6661WuT799FNrekZGhkycOFFWrlwpLVq0EBGRK6+8UtatWyf//Oc/pU2bNlbaZ5991vo+YsQI6dSpk6Snp4vH45EJEybIiBEjrHVz5ZVXytNPPy1PPvmkjBs3zlrGXXfdJf369bOVccKECdb/4+PjZePGjbJw4ULp3r27lC5dWkJDQyUjI8NW53feeUeysrLkX//6l7hcLhERmTNnjpQtW1bWrl0rN954o0ybNk1Gjhwpt912m4iIzJw5U5YvX16g9VZYBBUBAAAAAAAgO3fulIyMDLn++uu9Tqtfv74VUBQRadWqlWRlZcnu3buNgopXX3219X+XyyXR0dFy4sQJR2VOSUmR48ePS7NmzazfAgICpHHjxpKVlSUiIj/99JOcOXNGbrjhBtu8mZmZ0rBhwzzLVqlSJREROXHihMTExMi2bdtk/fr1tisTz507J+np6XLmzBkJCwsTEZEmTZrkKucrr7wis2fPloMHD8off/whmZmZF30RzbZt2+Snn36SMmXK2H5PT0+XPXv2SEpKihw7dkyaN29uTQsMDJQmTZr45BZogooAAAAAAACQ0NDQQs3vdrtzBbO8vagkKCjI9t3lclkBwOKQ/dzHpUuXSpUqVWzTQkJC8ixb9tWB2WU7ffq0TJgwwboqMCePx2P9P2fgVURk/vz58sQTT8iLL74oLVq0kDJlysjzzz8vX3311UXL3bhxY3n33XdzTcu+orMkEVQEAAAAAACAJCQkSGhoqKxatUruv/9+27TatWvLm2++KWlpaVbQbP369eJ2u6VmzZoicj7QdezYMWuec+fOyY4dO6Rdu3YFLkNwcLA1b0FERERIVFSUfP3113LddddZ827ZssW6ErBOnToSEhIiBw8etN3qbKpRo0aye/duqVGjhtF869evl5YtW1q3fIuI7Nmzx5YmODg4V50bNWokCxYskIoVK0p4eLjXZVeqVEm++uorq+5//vmnJCUlSaNGjYzK6AQvagEAAAAAAIB4PB4ZPny4PPnkk/LWW2/Jnj175Msvv5Q33nhD7r77bvF4PNKnTx/ZsWOHrFmzRh555BG55557rFuf27dvL0uXLpWlS5fKrl27ZODAgfL7778blaFixYoSGhoqy5Ytk+PHj0tKSspF53nkkUdk0qRJ8uGHH8ru3btl8ODB8ttvv1lXGpYpU0aeeOIJeeyxx2Tu3LmyZ88e2bJli7z88ssyd+7cApdt7Nix8tZbb8mECRPku+++k507d8r8+fNl9OjR+c6XkJAgmzdvluXLl8sPP/wgY8aMka+//tqWJi4uTr799lvZvXu3/Pzzz3L27Fm5++67pXz58tKlSxf54osvZN++fbJ27Vp59NFH5fDhwyIiMnjwYJk8ebIsWbJEdu3aJQ899JDxOneKKxUBAAAAAAB8YHuf7SVdhIsaM2aMBAYGytixY+Xo0aNSqVIlefDBByUsLEyWL18ugwcPlqZNm0pYWJjcfvvtMnXqVGvee++9V7Zt2ya9e/eWwMBAeeyxx4yuUhQ5/0zAl156SZ566ikZO3asXHvttbJ27dp85xk+fLgkJydL7969JSAgQPr37y+JiYkSEBBgpXn66aelQoUKMmnSJNm7d6+ULVtWGjVqJKNGjSpw2RITE+WTTz6Rp556SqZMmSJBQUFSq1atXFd1XmjAgAHyzTffSI8ePcTlcknPnj3loYceks8++8xK88ADD8jatWulSZMmcvr0aVmzZo20bdtW/vvf/8rw4cPltttuk1OnTkmVKlXk+uuvt65cfPzxx+XYsWPSp08fcbvdcu+998qtt95aoGBsYbnUF09uLGapqakSEREhKSkp1kqNG7FURET2e+4SEZF68TEicmk0YAAAAAAAcOlKT0+Xffv2SXx8vO1Ze/CNrKwsqV27tnTv3l2efvrpki6O38lr//QWX8sPVyoCAAAAAADgknXgwAH5z3/+I23atJGMjAyZMWOG7Nu3T+66666SLtpljaAiAAAAAAAA/Fbp0qXznPbZZ59JXFycvPnmm/LEE0+IqkrdunVl5cqVUrt2bR+W8q+HoCIAAAAAAAD81tatW/OcVqVKFQkNDZX169f7rkAQEYKKAAAAAAAA8GM1atQo6SLAC3dJFwAAAAAAAOBydBm8GxeXoaLaLwkqAgAAAAAAFKGAgAAREcnMzCzhkgC5nTlzRkREgoKCCrUcbn8GAAAAAAAoQoGBgRIWFiYnT56UoKAgcbu5pgslT1XlzJkzcuLECSlbtqwV/HaKoCIAAAAAAEARcrlcUqlSJdm3b58cOHCgpIsD2JQtW1aio6MLvRyCigAAAAAAAEUsODhYEhISuAUafiUoKKjQVyhmI6gIAAAAAABQDNxut3g8npIuBlAsuKkfAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYISgIgAAAAAAAAAjBBUBAAAAAAAAGCGoCAAAAAAAAMAIQUUAAAAAAAAARggqAgAAAAAAADBCUBEAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABghKAiAAAAAAAAACMEFQEAAAAAAAAYIagIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjDgKKr7yyisSFxcnHo9HmjdvLps2bco3/aJFi6RWrVri8XikXr168umnn9qmnz59WgYNGiRVq1aV0NBQqVOnjsycOdNJ0QAAAAAAAAAUM+Og4oIFC2To0KEybtw42bJli9SvX18SExPlxIkTXtNv2LBBevbsKffdd59888030rVrV+natavs2LHDSjN06FBZtmyZvPPOO7Jz504ZMmSIDBo0SD766CPnNQMAAAAAAABQLIyDilOnTpUHHnhA+vXrZ11RGBYWJrNnz/aafvr06dKxY0cZNmyY1K5dW55++mlp1KiRzJgxw0qzYcMG6dOnj7Rt21bi4uKkf//+Ur9+/YteAQkAAAAAAADA94yCipmZmZKUlCQdOnT43wLcbunQoYNs3LjR6zwbN260pRcRSUxMtKVv2bKlfPTRR3LkyBFRVVmzZo388MMPcuONN3pdZkZGhqSmpto+AAAAAAAAAHzDKKj4888/y7lz5yQqKsr2e1RUlCQnJ3udJzk5+aLpX375ZalTp45UrVpVgoODpWPHjvLKK6/Idddd53WZkyZNkoiICOtTrVo1k2oAAAAAAAAAKAS/ePvzyy+/LF9++aV89NFHkpSUJC+++KI8/PDDsnLlSq/pR44cKSkpKdbn0KFDPi4xAAAAAAAA8NcVaJK4fPnyEhAQIMePH7f9fvz4cYmOjvY6T3R0dL7p//jjDxk1apR88MEH0qlTJxERufrqq2Xr1q3ywgsv5Lp1WkQkJCREQkJCTIoOAAAAAAAAoIgYXakYHBwsjRs3llWrVlm/ZWVlyapVq6RFixZe52nRooUtvYjIihUrrPRnz56Vs2fPitttL0pAQIBkZWWZFA8AAAAAAACADxhdqSgiMnToUOnTp480adJEmjVrJtOmTZO0tDTp16+fiIj07t1bqlSpIpMmTRIRkcGDB0ubNm3kxRdflE6dOsn8+fNl8+bNMmvWLBERCQ8PlzZt2siwYcMkNDRUYmNj5fPPP5e33npLpk6dWoRVBQAAAAAAAFAUjIOKPXr0kJMnT8rYsWMlOTlZGjRoIMuWLbNexnLw4EHbVYctW7aUefPmyejRo2XUqFGSkJAgS5Yskbp161pp5s+fLyNHjpS7775bfv31V4mNjZVnn31WHnzwwSKoIgAAAAAAAICi5FJVLelCFFZqaqpERERISkqKhIeHi4hI3IilIiKy33OXiIjUi48REZHtfbaXTCEBAAAAAAAAP+UtvpYfv3j7MwAAAAAAAIBLB0FFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYISgIgAAAAAAAAAjBBUBAAAAAAAAGCGoCAAAAAAAAMAIQUUAAAAAAAAARggqAgAAAAAAADBCUBEAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABghKAiAAAAAAAAACMEFQEAAAAAAAAYIagIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGCEoCIAAAAAAAAAIwQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYISgYh7qza0n9ebWK+liAAAAAAAAAH6HoCIAAAAAAAAAIwQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYCS7oAfmd8xPl/42NKthwAAAAAAACAn+JKRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGDEUVDxlVdekbi4OPF4PNK8eXPZtGlTvukXLVoktWrVEo/HI/Xq1ZNPP/00V5qdO3dK586dJSIiQkqVKiVNmzaVgwcPOikeAAAAAAAAgGJkHFRcsGCBDB06VMaNGydbtmyR+vXrS2Jiopw4ccJr+g0bNkjPnj3lvvvuk2+++Ua6du0qXbt2lR07dlhp9uzZI61bt5ZatWrJ2rVr5dtvv5UxY8aIx+NxXjMAAAAAAAAAxcKlqmoyQ/PmzaVp06YyY8YMERHJysqSatWqySOPPCIjRozIlb5Hjx6SlpYmn3zyifXbNddcIw0aNJCZM2eKiMidd94pQUFB8vbbbzuqRGpqqkREREhKSoqEh4eLiEjciKUiIrLfc5eIiNSLjxERke19tue/sPERZukBAAAAAACAS5y3+Fp+jK5UzMzMlKSkJOnQocP/FuB2S4cOHWTjxo1e59m4caMtvYhIYmKilT4rK0uWLl0qV111lSQmJkrFihWlefPmsmTJkjzLkZGRIampqbYPAAAAAAAAAN8wCir+/PPPcu7cOYmKirL9HhUVJcnJyV7nSU5Ozjf9iRMn5PTp0zJ58mTp2LGj/Oc//5Fbb71VbrvtNvn888+9LnPSpEkSERFhfapVq2ZSDQAAAAAAAACFUOJvf87KyhIRkS5dushjjz0mDRo0kBEjRsjf//536/boC40cOVJSUlKsz6FDh3xZZAAAAAAAAOAvLdAkcfny5SUgIECOHz9u+/348eMSHR3tdZ7o6Oh805cvX14CAwOlTp06tjS1a9eWdevWeV1mSEiIhISEmBQdAAAAAAAAQBExulIxODhYGjduLKtWrbJ+y8rKklWrVkmLFi28ztOiRQtbehGRFStWWOmDg4OladOmsnv3bluaH374QWJjY02KVyhxI5ZaL3cBAAAAAAAAkDejKxVFRIYOHSp9+vSRJk2aSLNmzWTatGmSlpYm/fr1ExGR3r17S5UqVWTSpEkiIjJ48GBp06aNvPjii9KpUyeZP3++bN68WWbNmmUtc9iwYdKjRw+57rrrpF27drJs2TL5+OOPZe3atUVTSwAAAAAAAABFxjio2KNHDzl58qSMHTtWkpOTpUGDBrJs2TLrZSwHDx4Ut/t/F0C2bNlS5s2bJ6NHj5ZRo0ZJQkKCLFmyROrWrWulufXWW2XmzJkyadIkefTRR6VmzZry73//W1q3bl0EVQQAAAAAAABQlFyqqiVdiMJKTU2ViIgISUlJkfDwcBER61bm/Z67RESkXnyMiIhs77Pd6zJM0wMAAAAAAACXC2/xtfyU+NufAQAAAAAAAFxaCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGCEoCIAAAAAAAAAIwQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYISgIgAAAAAAAAAjBBUBAAAAAAAAGCGoCAAAAAAAAMAIQUUAAAAAAAAARggqAgAAAAAAADBCUBEAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABghKAiAAAAAAAAACMEFQEAAAAAAAAYIagIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGCEoCIAAAAAAAAAIwQVHYobsVTiRiwt6WIAAAAAAAAAPkdQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGCEoCIAAAAAAAAAIwQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMOAoqvvLKKxIXFycej0eaN28umzZtyjf9okWLpFatWuLxeKRevXry6aef5pn2wQcfFJfLJdOmTXNSNAAAAAAAAADFzDiouGDBAhk6dKiMGzdOtmzZIvXr15fExEQ5ceKE1/QbNmyQnj17yn333SfffPONdO3aVbp27So7duzIlfaDDz6QL7/8UipXrmxeEwAAAAAAAAA+YRxUnDp1qjzwwAPSr18/qVOnjsycOVPCwsJk9uzZXtNPnz5dOnbsKMOGDZPatWvL008/LY0aNZIZM2bY0h05ckQeeeQReffddyUoKMhZbQAAAAAAAAAUO6OgYmZmpiQlJUmHDh3+twC3Wzp06CAbN270Os/GjRtt6UVEEhMTbemzsrLknnvukWHDhsnf/va3i5YjIyNDUlNTbR8AAAAAAAAAvmEUVPz555/l3LlzEhUVZfs9KipKkpOTvc6TnJx80fRTpkyRwMBAefTRRwtUjkmTJklERIT1qVatmkk1ik29ufWk3tx6JV0MAAAAAAAAoFiV+Nufk5KSZPr06fLmm2+Ky+Uq0DwjR46UlJQU63Po0KFiLiUAAAAAAACAbEZBxfLly0tAQIAcP37c9vvx48clOjra6zzR0dH5pv/iiy/kxIkTEhMTI4GBgRIYGCgHDhyQxx9/XOLi4rwuMyQkRMLDw20fAAAAAAAAAL5hFFQMDg6Wxo0by6pVq6zfsrKyZNWqVdKiRQuv87Ro0cKWXkRkxYoVVvp77rlHvv32W9m6dav1qVy5sgwbNkyWL19uWh8AAAAAAAAAxSzQdIahQ4dKnz59pEmTJtKsWTOZNm2apKWlSb9+/UREpHfv3lKlShWZNGmSiIgMHjxY2rRpIy+++KJ06tRJ5s+fL5s3b5ZZs2aJiEhkZKRERkba8ggKCpLo6GipWbNmYetX/MZH/O//8TElVw4AAAAAAADAR4yDij169JCTJ0/K2LFjJTk5WRo0aCDLli2zXsZy8OBBcbv/dwFky5YtZd68eTJ69GgZNWqUJCQkyJIlS6Ru3bpFVwsAAAAAAAAAPmMcVBQRGTRokAwaNMjrtLVr1+b6rVu3btKtW7cCL3///v1OigUAAAAAAADAB0r87c8AAAAAAAAALi0EFQEAAAAAAAAYIagIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGCEoCIAAAAAAAAAIwQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYISgIgAAAAAAAAAjBBUBAAAAAAAAGCGoCAAAAAAAAMAIQUUAAAAAAAAARggqAgAAAAAAADBCUBEAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABghKAiAAAAAAAAACMEFQEAAAAAAAAYIagIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGCEoCIAAAAAAAAAIwQVAQAAAAAAABghqAgAAAAAAADACEFFAAAAAAAAAEYIKgIAAAAAAAAwQlARAAAAAAAAgBGCigAAAAAAAACMEFQEAAAAAAAAYISgYgmqN7ee1Jtbr6SLAQAAAAAAABhxFFR85ZVXJC4uTjwejzRv3lw2bdqUb/pFixZJrVq1xOPxSL169eTTTz+1pp09e1aGDx8u9erVk1KlSknlypWld+/ecvToUSdFAwAAAAAAAFDMjIOKCxYskKFDh8q4ceNky5YtUr9+fUlMTJQTJ054Tb9hwwbp2bOn3HffffLNN99I165dpWvXrrJjxw4RETlz5oxs2bJFxowZI1u2bJHFixfL7t27pXPnzoWrGQAAAAAAAIBiYRxUnDp1qjzwwAPSr18/qVOnjsycOVPCwsJk9uzZXtNPnz5dOnbsKMOGDZPatWvL008/LY0aNZIZM2aIiEhERISsWLFCunfvLjVr1pRrrrlGZsyYIUlJSXLw4MHC1Q4AAAAAAABAkTMKKmZmZkpSUpJ06NDhfwtwu6VDhw6yceNGr/Ns3LjRll5EJDExMc/0IiIpKSnicrmkbNmyJsUDAAAAAAAA4AOBJol//vlnOXfunERFRdl+j4qKkl27dnmdJzk52Wv65ORkr+nT09Nl+PDh0rNnTwkPD/eaJiMjQzIyMqzvqampJtUAAAAAAAAAUAh+9fbns2fPSvfu3UVV5bXXXssz3aRJkyQiIsL6VKtWzYelvESMjzj/AQAAAAAAAIqYUVCxfPnyEhAQIMePH7f9fvz4cYmOjvY6T3R0dIHSZwcUDxw4ICtWrMjzKkURkZEjR0pKSor1OXTokEk1AAAAAAAAABSCUVAxODhYGjduLKtWrbJ+y8rKklWrVkmLFi28ztOiRQtbehGRFStW2NJnBxR//PFHWblypURGRuZbjpCQEAkPD7d9/grqza0n9ebWyzdN3IilEjdiqdE8AAAAAAAAgAmjZyqKiAwdOlT69OkjTZo0kWbNmsm0adMkLS1N+vXrJyIivXv3lipVqsikSZNERGTw4MHSpk0befHFF6VTp04yf/582bx5s8yaNUtEzgcU77jjDtmyZYt88skncu7cOet5i1dccYUEBwcXVV0BAAAAAAAAFAHjoGKPHj3k5MmTMnbsWElOTpYGDRrIsmXLrJexHDx4UNzu/10A2bJlS5k3b56MHj1aRo0aJQkJCbJkyRKpW7euiIgcOXJEPvroIxERadCggS2vNWvWSNu2bR1WDQAAAAAAAEBxMA4qiogMGjRIBg0a5HXa2rVrc/3WrVs36datm9f0cXFxoqpOinHZy76Nef/kTiVcEgAAAAAAAOB/HAUVUUjZb2WOjyme9AAAAAAAAEAxMnpRCwAAAAAAAAAQVAQAAAAAAABghKAiAAAAAAAAACM8U9GHrBeveEq4IPmoN7eeiIhs77O9hEsCAAAAAAAAf8WVigAAAAAAAACMEFQEAAAAAAAAYITbnwE/8b/b4+86/8P4lBIsDQAAAAAAQN64UhEAAAAAAACAEYKKAAAAAAAAAIwQVAQAAAAAAABghKAiAAAAAAAAACMEFYFLWNyIpdYLXgAAAAAAAHyFoCIAAAAAAAAAIwQV/+KK4kq3enPrSb259YqoRAAAAAAAAPB3BBUBAAAAAAAAGAks6QLAT4yPOP9vfEzJlgPOZG+/8SklWw4AAAAAAPCXwJWK8LniuF2aF5YAAAAAAAD4DkFFAAAAAAAAAEYIKgIAAAAAAAAwQlARfs/J7dK8kRoAAAAAAKD4EFQEAAAAAAAAYISgIow4eSHKpfASFV9cDVnc6Z3OAwAAAAAAYCqwpAuAv5DxEef/jY+5tPP4K8peryIi41NKrhwAAAAAAMAvcKUiAAAAAAAAACNcqQj8hWXfKr29z3av07NvW9/vKfg8pnkUNr3TeQAAAAAAgHMEFeFMztthudUY3nC7u//IXk/cug4AAAAAKCIEFeF3rKvjJne6pPP4q/J2daO/8cXVkP5w9eSlsC0AAAAAAJcmnqkIAAAAAAAAwAhXKsJ/+ePts9z2DZQcbuMGAAAAAL9BUBEoAG4j9S+X4/bw11uy/eE2bgAAAACA/+H2ZwAAAAAAAABGCCoCAAAAAAAAMMLtz0Bx88WzIU1RpuJzudTDoeK4JfvC29398bbvS7FM1nqd3KlQ5brU/G9/uut/P/KcTlyucj4Lmv0cAAAUMa5UBAAAAAAAAGCEKxWBYuKPLxOhTMXncqkHCsbbVX5/RZfiFZolkYc/lskXefhjmXyRhz+8FItjEgAA8AWCigD+OkxvTc5521hx3c78V71d2h/r7WR7+2M9TPliP79cXA7b+6/qr9q+AXiX3b55LACKyuWwT/miDv64nvyxTJcQbn8GAAAAAAAAYIQrFQFc9kxvA/PFbWN/1VvT/LHe/lgm+Bf2kUuXk213KWzvv+pt3/6Yhz+WyRd5+GOZCjLP5fjyN1/k4Y9l8kUef5UXCha2Dv6Sh6lL4Xh/KSCoCACXmuK+JY/bBIsP6wnwjrZx6XKy7fzxOAagZPjj44kAFBhBRQC4RBT3X9Mu1yt6/AHrCRfzV335D23j0uWPxwz2p0vbX7UfNOWv68m0XP54JxEuL5fiVaMlkUdhrwDlmYoAAAAAAAAAjDi6UvGVV16R559/XpKTk6V+/fry8ssvS7NmzfJMv2jRIhkzZozs379fEhISZMqUKXLzzTdb01VVxo0bJ6+//rr8/vvv0qpVK3nttdckISHBSfEAALh8bqd0eltQcdbbF2Xyx3qb8sd6++LxBv64D/qCP25vJy6XdVvcefjj9vbX9u2P9TZ1udTbH7e3L1wOfa2/Pp7IHx9n4Y/19sftXUTryTiouGDBAhk6dKjMnDlTmjdvLtOmTZPExETZvXu3VKxYMVf6DRs2SM+ePWXSpEny97//XebNmyddu3aVLVu2SN26dUVE5LnnnpOXXnpJ5s6dK/Hx8TJmzBhJTEyU77//Xjwerm8GABTc5XJ7jD/eFuSLMvljvU2xLQqeh6nLZXuzbgvGH+vtj9vbH8vkdB4T/rh/OJnHH+vhj/2BE/5Y78uh7fkij8ul3v64vYt6PRnf/jx16lR54IEHpF+/flKnTh2ZOXOmhIWFyezZs72mnz59unTs2FGGDRsmtWvXlqeffloaNWokM2bMEJHzVylOmzZNRo8eLV26dJGrr75a3nrrLTl69KgsWbKkUJUDAAAAAAAAUPSMrlTMzMyUpKQkGTlypPWb2+2WDh06yMaNG73Os3HjRhk6dKjtt8TERCtguG/fPklOTpYOHTpY0yMiIqR58+ayceNGufPOO3MtMyMjQzIyMqzvKSkpIiKSmppq/ZaVceb8by4VEZFzf5zLlSanwqb3RR4XS++LPKg39abe1NuXZfJFHtSbelNv6u3LMvkiD+pNvak39fZlmXyRB/Wm3tTbN/XO/ldVvczthRo4cuSIiohu2LDB9vuwYcO0WbNmXucJCgrSefPm2X575ZVXtGLFiqqqun79ehURPXr0qC1Nt27dtHv37l6XOW7cOBURPnz48OHDhw8fPnz48OHDhw8fPnz4FOHn0KFDBYoTOnpRS0kbOXKk7erHrKws+fXXXyUyMlJcLpctbWpqqlSrVk0OHTok4eHhF112cae/XPLwxzL5Ig9/LJMv8vDHMvkiD38sky/y8Mcy+SIPfyyTL/LwxzL5Ig9/LJMv8vDHMvkiD38sky/y8Mcy+SIPfyyTL/LwxzL5Ig9/LJMv8vDHMvkiD38sky/y8Mcy+SIPfyyTL/IoyTKpqpw6dUoqV65coHyNgorly5eXgIAAOX78uO3348ePS3R0tNd5oqOj802f/e/x48elUqVKtjQNGjTwusyQkBAJCQmx/Va2bNl8yx4eHl7gjeGL9JdLHv5YJl/k4Y9l8kUe/lgmX+Thj2XyRR7+WCZf5OGPZfJFHv5YJl/k4Y9l8kUe/lgmX+Thj2XyRR7+WCZf5OGPZfJFHv5YJl/k4Y9l8kUe/lgmX+Thj2XyRR7+WCZf5OGPZfJFHiVVpoiIiALPb/SiluDgYGncuLGsWrXK+i0rK0tWrVolLVq08DpPixYtbOlFRFasWGGlj4+Pl+joaFua1NRU+eqrr/JcJgAAAAAAAICSY3z789ChQ6VPnz7SpEkTadasmUybNk3S0tKkX79+IiLSu3dvqVKlikyaNElERAYPHixt2rSRF198UTp16iTz58+XzZs3y6xZs0RExOVyyZAhQ+SZZ56RhIQEiY+PlzFjxkjlypWla9euRVdTAAAAAAAAAEXCOKjYo0cPOXnypIwdO1aSk5OlQYMGsmzZMomKihIRkYMHD4rb/b8LIFu2bCnz5s2T0aNHy6hRoyQhIUGWLFkidevWtdI8+eSTkpaWJv3795fff/9dWrduLcuWLROPx1PoCoaEhMi4ceNy3S5dUukvlzz8sUy+yMMfy+SLPPyxTL7Iwx/L5Is8/LFMvsjDH8vkizz8sUy+yMMfy+SLPPyxTL7Iwx/L5Is8/LFMvsjDH8vkizz8sUy+yMMfy+SLPPyxTL7Iwx/L5Is8/LFMvsjDH8vkizz8sUx5cakW9D3RAAAAAAAAAGD4TEUAAAAAAAAAIKgIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAICRwJIuwOVgwoQJ8vDDD0v58uULPM/x48clIyNDYmJivE5PTk6Wr776SpKTk0VEJDo6Wpo3by7R0dFFUmZvzp49K0FBQXlO37Rpk2zcuNFWphYtWkizZs2KrUy+9Ntvv8nHH38svXv3LrEy/Pnnn7JmzRo5ePCgxMbGSrt27SQgIKBA85ruhxfbBy/37V2cLtaWCiojI0Pcbre1rD179sjs2bOt/eO+++6T+Pj4Ai3rYtvbRFJSkjRu3LjQyylOv//+uyxatMhaV926dZOIiIgCz1+c/UG/fv3k2WeflcqVKxf5si+UlpYmSUlJct111xVL+vz8+eef8t1339n6kDp16hRJ28i2d+9eWbdunRw7dkzcbrdceeWVcsMNN0h4eLjX9CVxbHXCybjir8Rp+77yyitl+fLlkpCQ4INSFp+i7M8v5HQcUtRjkJwK25/n59y5c7b6ffXVV5KRkSEtWrQosr4qu1/N2U81atRIXC5XkSwfBeeL49KFiqrf+fnnny/rY0J+fcgnn3wimzZtksTERGnVqpWsXr1aXnjhBcnKypLbbrtN+vfvn2seVZX9+/dLtWrVJDAwUDIzM+WDDz6QjIwMufnmm0t8XRbmnK+o+HI8v3r16lzjtc6dO5fY8fjYsWPy2muv5SpT165dpW/fvj7fFpc8vcxs3bpV33jjDd2zZ4+qqu7YsUMHDhyoAwYM0GXLltnSnjx50mjZKSkpuT6///67BgUF6VdffWX9llNqaqrefffdGhMTo71799aMjAx96KGH1OVyqdvt1uuuu842z+nTp/Xuu+/WgIAADQwM1IoVK2rFihU1MDBQAwICtFevXpqWluZw7Zy3YMECzcjIsL6//PLLGhMTo263WyMjI3XChAm29MePH9fWrVury+XS2NhYbdasmTZr1kxjY2PV5XJp69at9fjx417z2rNnj86dO1cnT56szz33nL7//vu51lFefvvtN501a5aOHj1aX3/9df39999t002338Vs3bpV3W637bdXXnlFr7/+eu3WrZuuXLkyV/7x8fFel3X69Gn9/PPPdf78+bpw4ULdvHmzZmVl5Uo3aNAg/fjjj1VV9dChQ1qrVi0NCAjQqKgoDQgI0Hr16unhw4dt85juh6b7oNPtbdL2vNm7d6/+5z//0e3bt180bVE4e/asHjhwoFDzmLalbH/++aft+5dffqmff/65ZmZm2n5v06aNLlq0SFVV161bpyEhIXr11Vdrjx49tGHDhhoWFqYbNmywzWO6vZOSknTv3r3W97feektbtmypVatW1VatWul7772Xq/wul0urV6+uzz77rB45cuRiq81y/PhxXbVqldWWk5OTdcqUKTpp0iT99ttvC7SMC9dRtltvvdVaVzt27NDy5ctrhQoVtHnz5hoVFaXR0dH6/fffF7is3vqDbAVt39u2bfP6CQoK0g8++MD6fqGsrCzdu3evnj17VlVVMzIydP78+Tp37lzjfi+/epim/+qrr3TatGk6YsQIHTFihE6bNk2/+uqrXOnOnTun//d//6dly5ZVl8tl+5QtW1ZHjx6t586dM6rHhU6fPq133HGHtVy3263R0dEaEBCgpUuX1hkzZuRKb3ps3bx5s6OynTlzRt944w3t16+fduzYUW+++WYdNGhQrmOIqrNxhTft2rXT/fv3Oypv9v58ocIcvwvbn19YJtP2PX36dK+fgIAAHTlypPX9QkXRR40fPz7fdvrzzz/r6tWr9ZdfflHV82OJyZMn64QJE3L1Uab9eV4yMzP1hx9+yDWOUjUfhxT3GETVWX9uOl47evSotmrVSgMCAvS6667TX3/9VTt16mT1KVdddZUePXrU6/o06QuHDRumYWFh6na71e12W8uPjY3Vjz76yOvy85LfuCWvPvXcuXP5jnUuNtbOyaRPKIq2pKrat2/fAo0zLlaPwhyXClpvp/2OasHGhW63W9u3b6/vvvuupqenX3Sd5FTQffZiTMbOeR2XTPuQmTNnamBgoDZu3FjDw8P17bff1jJlyuj999+vAwYM0NDQUJ02bZotj127dmlsbKy63W6tUaOG7t27Vxs3bqylSpXSsLAwLV++vP7www8XrUNeY05V8/NQJ+d8Ts5DTebxxXj++PHj2qxZM3W73RoYGKhut1sbN25sjdmGDRtmS5+ZmanDhg3T6tWra9OmTfWNN96wTU9OTjYa16qq/vrrrzp37lzr+9dff60RERHauHFjbd26tQYEBOg999yjPXr00LJly2rLli01NTW1QMsuaB+lmv+x2Ok8f/75p+7Zs8fqv9LT03XBggX63nvvaXJy8kWXb3IMyM9lFVT897//rQEBARoZGamlS5fWFStWaNmyZbVDhw6amJioAQEB+u6771rpTTvn7AHBhZ/sgVH2vzkNGjRIa9WqpS+99JK2bdtWu3TponXr1tV169bp559/rnXq1NFRo0ZZ6e+77z5NSEjQZcuW2Q4wf/75py5fvlyvuuoqvf/++215mDY+t9ttBYVmz56tHo9Hx44dq0uXLtVnnnlGS5Uqpa+//rqV/vbbb9cWLVrorl27cq2TXbt2acuWLfWOO+6w/W56wqdqPog03X7eDmI5P1988YVtPU2fPl3DwsL04Ycf1l69emlwcLBOnDgxz/Wqaj6AjIqKsk66unfvrh06dLAOUr/88ov+/e9/z7VuTfdD033QyfY2bXsDBw7UU6dOqer5E/Dbb7/dVvZ27dpZ07MV9UHGNNjibR7TtmR6EhMeHm4Netq0aaOPPfaYrTyjR4/WVq1a2X4z3d5XX321rlixQlVVX3/9dQ0NDdVHH31UX3vtNR0yZIiWLl0617p2uVz6wAMPWEGZTp066QcffJBrUJzTmjVrtFSpUupyuTQ6Olq3bt2qVatW1YSEBK1Zs6aGhITo8uXLrfSmAdty5crpzp07VVX1pptu0rvuusuaPzMzU++77z698cYbrfSm/YGqefvO2SYv/OR1zCiqgXC2oggqmv6hYdiwYVqhQgWdOXOm7tu3T8+cOaNnzpzRffv26T//+U+tWLGiPvnkk7Y8TNt3//79tVWrVrp9+3b98ccf9Y477tAnn3xS09LS9I033tCwsDBbn+Pk2OpksP3jjz9qbGysVqxYUatVq6Yul0s7deqkzZs314CAAO3WrZsVLFY1788//PBDr5+AgACdMWOG9d3Ehdvc9PjtpD83LZNp+3a5XFq1alWNi4uzfVwul1apUkXj4uJynYyZ9lFOAsJfffWVRkREqMvl0nLlyunmzZs1Pj5eExIStHr16hoaGqpJSUlWetP+XFV1ypQpeubMGVU9v38//vjjGhwcbJ3Q9evXz3aibDoOKe4xiJPt7WS8ds8992jLli31o48+0h49emjLli312muv1cOHD+uBAwe0VatW+vDDD9vmMe0Lhw8frrVr19aPP/5YV6xYodddd51OmTJFd+7cqWPGjMm1T12Mt/45JSVFu3Xrph6PRytWrKhjxoyx9XEX1t1JwNa0TzBtS6rmf4QzrYeT45JpvZ30OybjQpfLpR07dtTg4GAtV66cDho0SL/55hvNT2EuDPHG2z5oelwy7UPq1Kmjs2bNUlXV1atXq8fj0VdeecWaPmfOHK1du7atTF26dNHOnTvrt99+q0OGDNHatWtrly5dNDMzU9PT0/WWW27RXr16WemdXCRgeh5q2tc66ddM5/HFeL5Hjx7atWtXTUlJ0fT0dB00aJD27t1bVVVXrVqlkZGRtqDwuHHjNCoqSp9//nn9v//7P42IiND+/fvb6uByuS66vnO6cL9t1aqVjh8/3vr+9ttva/PmzVX1fACyQYMG+uijj9qWYdpHmR6Lncyzbds2rVSpkrrdbq1bt64ePHhQ69atq6VKldLSpUtruXLldNOmTbY8ivoijGyXVVCxUaNG+swzz6iq6nvvvadly5bVp556ypr+wgsvaIMGDazvpp1zlSpVtFOnTrp69Wpdu3atrl27VtesWaMBAQE6Z84c67ecqlWrpqtXr1ZV1SNHjqjL5bL+SqGq+sknn2jNmjWt72XLltX169fnWYZ169Zp2bJlbb+ZNj6Xy2UdQJo1a6bPPfecbXmvvvqqNmzY0PpeunRp3bJlS55l2rx5s5YuXdr2m+kJn6qzkwaT7Zd9kLrYwSxbnTp1bGVcv369VqhQQceMGWOt1ws7c9MBpMfjsa4Sq1q1aq6/Gm7fvl3Lly9v+810PzTdB51sb9O2lzMYN3LkSK1ataquXr1a09LSdN26dVq9enUdMWKELY+iPsgURVDRtC2ZnsSUKlXKahNRUVG6detW2/J/+umnXNvCdHuHhoZaf0lu2LChNXDL9u6772qdOnVsv2XX++zZs/r+++/rzTffbP219cknn9Tdu3fnWnetW7fWhx9+WE+dOqXPP/+8VqlSxVbXJ554Qlu2bGl9Nw3YhoaG6k8//aSqqpUqVcq1D+/evVsjIiJsdTDpD1TN23f9+vW1U6dOunPnTt2/f7/u379f9+3bp4GBgbpixQrrt5xMB8LlypXL9xMeHp4rOGOSXtX8Dw1RUVH5Xp28bNkyrVixou030/Zdvnx525WEv/76q3o8HutqwxkzZtj6HCfHVieD7ZtuukkHDBhgXbk6efJkvemmm1RV9YcfftC4uDgdN26cld60P88vUJ3zxNfEhf2a6fHbSX9uWibT9j1gwABt0KBBroFxYGCgfvfdd17zdNJHmf6huUOHDnr//fdramqqPv/881q1alVbMLtfv37atWtX67tpf55druzt8fzzz2u5cuV09uzZ+t133+k777yjFStW1ClTpljpTcchxT0GUTXf3k7Ga5UqVdKNGzeq6vkTepfLZbuqZ9WqVXrllVfa5jHtCytVqqT//e9/re+HDx/W0qVLWwGIp556Slu0aJFrWXnxNm559NFH9aqrrtJFixbp66+/rrGxsdqpUydr/Hxh32k61lY17xNM25Kq+R/hTOvh5LhkWm8n/Y7JuDB77HXy5El94YUXtE6dOup2u7VRo0b66quver160smFAvnxtg+aHpdM+5DQ0FDb1ZFBQUG2q+D37dunYWFhtjJVqFDBOic8ffq0ulwu/eKLL6zp69ev15iYGOu76Zgzu94m56Gmfa2Tfs10Hl+M58PDw3XHjh3W99OnT2tQUJC1v7799tu2Y0CNGjVsx4gff/xRa9SooX379tWsrCyv9Ta9UCA0NNS6s071/EUDQUFB1pV9//nPf7Ry5cq2PEz7KNNjsZN5EhMT9Y477tDt27fr4MGDtXbt2tqtWzfNzMzUs2fPaq9evbRDhw62PJwcAwrisgoqlipVSvft26eq528fCwoKsl2Cu2fPHtsJuGnn/Msvv2jXrl21Xbt2tsuT8ztYhISE6MGDB63vYWFhtga6f/9+W0cYHh6uX3/9dZ513LRpk4aHh9t+M218LpdLT5w4oarnT8y8BSrKlCljfY+MjMwVLM1pzZo1GhkZafvN9IRP1VlQwGT7hYeH65QpU6yD1YWf119/PVeHk70/Zdu+fbtGRUXpiBEj8hykmgwgr776ap0/f76qqtauXdu6Yizbhg0b9IorrrD9Zrofmu6DTra307anqlq3bl2dN2+ebXkffvihXnXVVbbfTPfzhg0b5vupVatWru1nOo9pWzI9iWnfvr0VqGzZsqXt0n1V1ffff982KFJ1tr2z22rFihW91iE0NNT2W87tl+3w4cP61FNP6ZVXXqlut1uvvfZa2/Tw8HCrfZ89e1YDAwNtg68ffvjBa/tWLVjAtnnz5lZAtGHDhvrBBx/Y0v/nP//R6OhoW3lM+gNV8/adkZGhgwcP1jp16tj6s/yOGaYD4bCwMH388cf1zTff9PqZMGGCrR6m6VXN/9AQFhaW7+1t27Zt01KlStl+M23fZcuWtV2xmZmZqYGBgVZ7/OGHH9Tj8VjTnRxbnQy2w8LCbOXKyMjQoKAg/fnnn1VVdcmSJRoXF2dNN+3PO3bsqJ06dcrV/vLbp0wDyabHbyf9uWmZTNu3qurixYu1WrVq+vLLLxdoPZn2UU7+0FyuXDkr4JCZmalut9t2YpmUlKRVqlSxvpv256r27dGwYUP95z//aZv+zjvv6N/+9jfru+k4pLjHIKrm29vJeM3j8djKVapUKf3xxx+t7wcOHMh17DPtC8uUKZPrxDUwMFCPHTumqqrfffedre5Oxi0xMTG6Zs0a6/vJkye1WbNmeuONN2p6enquupuOtVXN+wTTtqRq/kc403o4OS45OZcx7XdMxoXexl4bNmzQe++9V8uUKaNhYWF6zz332Kab7rNO9kHT45JpH1K1alVr7JX9h4mlS5da09euXatVq1a1zXNhILJ06dLW/qKqevDgQQ0JCbG+m445c85T0PNQ077WSb9mOo8vxvMVKlSwbdczZ86o2+22HgGyZ88e27bwVofDhw/rVVddpXfffbceOXIkz8B2QS8UiI2N1XXr1lnfjx49qi6Xy7pKcN++fbYxpKp5H2V6LHYyT84xxZkzZzQgIMA2ptixY0euc3Ynx4CCuKyCitHR0Vbn/+uvv6rL5bIdaDdt2mQbhDjpnFXPdyyVK1e2Bs75HSwqV65su5WlZ8+etjx37Nih5cqVs77fdddd2rBhQ68HgC1btmjjxo317rvvtv1u2vhcLpe+9dZb+uGHH2rVqlVzPZNtx44dtpOrhx56SGNjY3Xx4sW2DjIlJUUXL16scXFxOmjQINsyTE/4VM0Hkabbr23btrn+IpDT1q1bbX/NrVatmi2AkO27777TqKgo7d27d65OzXQAOWfOHK1ataquWbNG33rrLa1du7auXLlSjxw5oqtXr9Z69erluiUvW0H3Q9N90Mn2dtL2cgbjcv4FS/X8ScaFg3nT/TwkJET79Omj48eP9/oZMGBAru1nOo9pWzI9idmwYYNGRETouHHj9OWXX9by5cvr6NGj9d1339WxY8dq2bJlc+3Tptu7V69eet9996mqardu3XT06NG25U2cOFHr1atn+y3nX9K8Wblypd51112233Ju57S0NHW73dZAWvX8gD7nX2hNA7affPKJXnHFFTpnzhydM2eOxsXF6b/+9S9dv369zp49W6tVq2Z7botpf6Bq3r6zffrpp1q1alWdOHGiNU9exwzTgXDLli1zPUvownrk3GdN06ua/6Hh5ptv1htvvNHr84ZOnjxpnYDkZNq+b7jhBttfxp9//nmtVKmS9X3Lli22/cnJsdXJYPvC9vfbb7+py+Wyns2zd+9e2/bLZjKumDp1qlarVs0WhM0vvWkg2fT47aQ/Ny2TafvOdvjwYW3fvr127NhRjx07lu96Mu2jnPyhOecf4FTPt++cfcqBAwds69a0P1e1b4/IyMhcz7Xcu3dvkYxDimsMomq+vZ2M12JiYmwnX8OHD7dOclXP94UX3ili2he2bNnSuotD9X93cmTbvn27re5Oxi2hoaG25yKrnn+OZYsWLbR9+/a6d+/eQgfoTfsE07akav5HONN6ODkuOTmXUTXrd0zGhfmNvU6fPq3/+te/cl0BarrPOtkHVc2PS6oF70MefvhhTUhI0GeeeUabNWumffr00Vq1aulnn32my5Yt03r16um9995rm6d69eq2P8i++uqrtmfkJSUl5XtecrExZ/Y8Juehpn2tk37NdB5fjOdvvfVWvf322/X06dOamZmpQ4YM0Ro1aljTv/zyS9u2iI+P9/oM6iNHjuhVV12lN9xwQ656m14oMHjwYK1bt65+9tlnunr1am3Xrp22bdvWmr5s2TKtXr26LQ/TPsr0WOxknpx9VGZmpgYEBNiOtzt37sx1fHVyDCiIyyqo2KtXL23evLm+8847esstt2hiYqJec801unPnTt21a5e2adMm13NhTDvnbN99953Wr19fe/bsmW+n2bFjR505c2aeZZ4zZ44tj19//VU7duyoLpdLr7jiCq1Vq5bWqlVLr7jiCnW73XrTTTfpb7/9ZluGaeO78JLdnAMeVdV//etftr/GpKen64MPPmjd0+/xeNTj8ajL5dLg4GAdOHBgrmdJmJ7wqZoPIk2336xZs/J8QLLq+UvCcz5foWfPnjpkyBCvaXfs2KEVKlTI1amZDiBVVV988UUNCwvT0NBQax1nf7p27Zrvs6gKsh+a7oN5bW+3253n9jZtey6XSwcMGKCPPfaYVqxYUf/zn//YlpeUlJRr/zDdzxs3bqyvvvpqnvX+5ptvcm0/03lM25KTk5gNGzboNddckyuvKlWqeA0OmW7vI0eOaFxcnF533XU6dOhQDQ0N1datW+sDDzyg1113nQYHB9v+Ipxdb5Nn8Kiev63373//u65bt0779++vTZo00U6dOunp06c1LS1N77jjDu3YsaMtD5OArer5KzerVq2a6/YEj8ejQ4YMsd22atofqDpr3zmXd9NNN+m1116b7zHDdCD87LPP5ipnTgcPHtS+ffs6Tq9q/oeG7Ge6BAYGasOGDbVjx47asWNHbdiwoQYGBurVV19tO4lSNW/fSUlJesUVV2h0dLTGxMRocHCw7aVCM2bMsJ7Zo+rs2OpksN2nTx9t06aN7ty5U/fu3Wu9VCnb2rVrtVq1al6XV9Bxher5vqhOnTrav39/TUtLyze9aSDZ9PjtpD93Etw2ad85ZWVl6cSJE61noeW1nkz7qGwmAeFatWrpqlWrrO+ffPKJdWWE6vmTq5xX3Jj256rnt8ezzz6r06dP10qVKuV6Cc+2bduKbBxSHGOQbCbb28l4rXPnzvnugzNmzND27dvbfjPtC1euXKkhISHarFkzve666zQwMFD/8Y9/WNOff/55Wx5Oxi01a9bMdYxWVT116pS2aNFC69evX+gAvWmf4LQtqRb8j3Cm9XByXHJyLpOtoP2OybjQydjLdJ91sg/mnFbQ41K2gvQhp0+f1gceeEDr1q2r/fv314yMDH3++ec1ODhYXS6Xtm3bNtd6GTBgQK7blXOaNGmS3nzzzdZ3J2NOJ3EEk77WSb9mOo8vxvN79uzR6tWra2BgoAYFBWnZsmVtV2nOmTPH9oiU++67L1eQONvhw4e1Ro0auepteqHAqVOntHv37hoYGKgul0tbtmxp++PM8uXLdeHChV6XVdA+ysmx2HSe66+/Xu+77z49fPiwTpgwQWvUqKH9+vWzpj/00EO5/vjt9I+0F3NZBRWTk5P1hhtu0NKlS2tiYqL+/vvvOmjQIOuS14SEBNsVH04aUk4ZGRn62GOPaYMGDXL9lTDbL7/8kutEJadPP/3UdkVXtp07d+rs2bN14sSJOnHiRJ09e7Z1//uFnDS+/Hz88cdenzuSkpKiq1at0nnz5um8efN01apVeb71zfSEL5vJILKw2+9itm3bprNnz85z+vbt23OdnJsOILP99ttvumDBAp08ebJOnDhR58yZU+CXMVxsP3S6D6akpOjq1aut7b169eo8t7dp22vTpo22bdvW+lx44H/66ae1TZs2tt9M9/NHH31UBw8enGe9f/rpJ9tfpZzOk58L25KTk5hsJ06c0C+//FI3bNiQZ3+j6mx7//bbbzp8+HCtU6eOejweDQ4O1tjYWL3rrru83jK6du1a28smCuKHH37QhIQEdblcWrt2bT18+LB27txZAwMDNTAwUCtUqGD765ppwDbbn3/+qZs2bdL58+frvHnzdM2aNQV+g5uqen2Lczan7Tun6dOna9euXfXQoUNep5sOhH3ByR8azp07p59++qmOHTtW+/fvr/3799exY8fqZ5995vUNm06OY0ePHtVZs2bpyy+/fNETl2wmx1Ynx5jjx49bfwRwu90aGxtr+4v2okWL9KWXXspz/oKMK7KdOXNGBwwYoAkJCfmetJoGkk2P3076cyfBbdXCte+kpCSdNm2a/vrrr16nm/ZRORU0IDx+/HjburzQqFGj9LbbbrO+O+nPY2NjbS+JyNlHqapOmzZNr7nmmlzL+u2333ThwoXG45DiGoOont/eX3311UW3t5Px2sV89dVXua4ScdIXbt26VUeNGqWPP/54roD7hZyMQR555JE8n4mXmpqqzZs3L3SA3rRPKExbUi34H+FM62F6XHJ6LpPT5s2b8+13TMaFb775pvFbn0332cKOgwt6XMrJ5LiX0x9//GE0vlP93xhv7969thcjOhlzOj0PLWhf66RfM53HF+N51fNXNC5fvlw//vjji741e//+/fk+//TIkSP65ptv2n5zcqGA6vl9yPRFctnLu1gf5eRYbDrPpk2bNDIyUt1ut1aoUEF37NihzZs31+joaK1cubKGhoZ6/YO90z/S5selqiqXub1798qZM2ekVq1aEhgYaP0+d+5cufPOOyUkJKQES1d4Bw4ckF27dkliYqLX6UePHpUVK1ZInz59ijTf4OBg2bZtm9SuXdvr9GPHjsknn3wiGRkZ0r59e6lTp06Blnvu3DnZsmWL7N27V7KysqRSpUrSuHFjKVOmjC2dv26/bdu2ycKFCyUjI0MSExPlhhtuKOkilZi82l5B5gsODpaqVatav5XUfu5LmzZtkrCwMKlbt26+6S7W9vzZL7/8IpGRkdb3VatWyR9//CEtWrSw/X4xn3zyiQQFBeW5Pzh1sXVb0u1737594vF4pFKlSj7NV0QkNTVVkpKSJDk5WUREoqOjpXHjxhIeHl7oZftj+/7888+lVatWRn1Xth9//FEyMjKM+z4nPvroI1mzZo2MHDlSKlasWCTLdHr89sZbf+4Lx44dk9dee03WrVsnx44dE7fbLVdeeaV07dpV+vbtKwEBAV7nc9pHZWZmyogRI2TNmjWyePFiiY+PNy7zmTNnJCAgoFjHNV9++aWEhIRIw4YNiy2Py11x9oWmfvvtNzl69Kj87W9/8zr91KlTsmXLFmnTpo3t94KOtbM56RMKe7x/6aWXZM2aNfLyyy/n2X+cO3dOkpKSZN++fQWqh6mi7AudKOi48GJ8vc8W9XHJaX9+IafjZ29jTn89D/WVohrPX8oK0kflxcmx2Ns8aWlpsmvXLqlZs6aULl1a0tPT5d1335U//vhDbrjhBqlZs6bXZZkeAy7mLxFULG7t27eXOXPmSGxsbKHnycjIELfbLUFBQSIismfPHpk9e7YcPHhQYmNj5b777nM0UPVm06ZNsnHjRtsBpkWLFtKsWTNbuqFDh3qdf/r06dKrVy+r45g6dWqRlKs4/fHHH5KUlCRXXHFFroFBenq6LFy4UHr37m37vaDrqTCc5JGVlSVut9vr74cPH5aYmBjHeThZTzmlpaXJwoUL5aeffpLKlSvLnXfeme8BJmf6SpUqSc+ePS+ZA5Kqyv79+6VatWoSGBgomZmZ8sEHH0hGRobcfPPNUr58ecfLdtL2/v3vf8tNN90kYWFhjvMtrN9++00+/vjjfPeR4rBt2zZJSkqStm3bypVXXinfffedvPLKK5KVlSW33nqrbTDoq37NpExOmB4zfHWMKc52URz18NU+e+jQIRk3bpzMnj07zzT79u2z+sILTyQfeeQR6d69u1x77bXFWk4TviiT6fbevHmzdOjQQWrUqCGhoaGyceNGueuuuyQzM1OWL18uderUkWXLlhVZ4KGoeNs/irstOcmjuNNnW716da4gQufOnSUhIcFrepNxkS/H26bjNRSf4t4WM2bMkE2bNsnNN98sd955p7z99tsyadIkycrKkttuu02eeuqpQv+hyRfnJb6W33HPSX9+KZ275hUTKKrxfH7r1lf9oOl5ZWHHzpfyeeUly/jaRj/38ccf65gxY6w3+qxatUpvuukmTUxMzPUGHdXzl0Hv3bvXuvQ3IyND58+fr3Pnzs11ee6HH37o9RMQEKAzZsywvhdmnjZt2uiiRYtUVXXdunUaEhKiV199tfVcprCwsFzPech26NAhr5fwZmZm2u7JP378uLZu3VpdLpfGxsZqs2bNtFmzZhobG6sul0tbt25tu5zb5XJpgwYNbLc3tW3bVl0ulzZt2lTbtm2r7dq1y3e7XOjXX3/N9SZb03rkpV27dra3L2XbvXu3VUe3263XXXed7dL3C9+Idfz4cW3VqlWB11NO3m6jyP4950sYTLeF6vnbkrt166Yej0crVqyoY8aMsV2m7K0eJnl4W09HjhzJc/mq599ilv0MmIMHD2psbKxGRERo06ZN9YorrtCKFSvabmkwTZ/t559/1tWrV1vznjx5UidPnqwTJkyw3n6Vk0n7djLPrl27NDY2Vt1ut9aoUUP37t2rjRs31lKlSmlYWJiWL1/e6y0Nq1at0gkTJuiDDz6oDz30kL7wwgte0zlpey6XS8PDw/WBBx7QL7/80msdi5u356FdKCsrS1evXq2zZs3STz75RDMzM72mKei2+Pe//60BAQEaGRmppUuX1hUrVmjZsmW1Q4cOmpiYqAEBAfruu+9a6Z2s2/fff99662NBmJYpm8lxzPSY4eQYc+jQIdv6/u9//6t33XWXtm7dWu++++5c6Z22i4yMDF2wYIEOGTJE77zzTr3zzjt1yJAhunDhQs3IyChUvS8mr33WtM8xzWfgwIHW8e7MmTN6++23W7ehuN1ubdeune14mPOREpMnT7ZeEpSf9PR0W/v66aefdNSoUdqrVy/9v//7P699rcm2cFKm7HXxxhtvWC8q2bFjhw4cOFAHDBiQ69Yn0+3dqlUr261Ob7/9tjZv3lxVz48/GjRooI8++miBypntwnGLaX9QEBfuH07akun2Ns2juNOrnh+3NGvWTN1utwYGBqrb7dbGjRtbz6e78HlPpuMi1aLvQ7LzmTBhguNyOdmnTPvnC+U8Fn/88cdej8V5iY+PL/Cjei6W/oUXXvA6dr+Ygo6nnOwj2Qp6XvL0009rmTJl9Pbbb9fo6GidPHmyRkZG6jPPPKMTJ07UChUq6NixYx3n4eScQdX83Fj1/O3/06ZN0xEjRuiIESN02rRptmc/mriwXZge95z0507PXfM6f8vKyrKdvxVkngvP+UxjAk7G897Wbc63H1+4boujH7zwWGl6/u1k7HzheWVcXFyBzitNFeWYMK9YiJM8vLXXTZs2+aQe2S6roOLMmTM1MDBQGzdurOHh4fr2229rmTJl9P7779cBAwZoaGio7bkVpgOd7MZw4XMXcn4uPCCZzhMeHm7l2aZNG33sscdsyxs9erS2atXK9tvRo0e1adOm6na7NSAgQO+55x5bh3FhY7399tu1RYsWumvXrlzrcNeuXdqyZUvb81kmTZqk8fHxtoeLq178rV758XYCZ1oP0865a9eu2qlTJz158qT++OOP2qlTJ42Pj7c6/MKuJ1XzQYuTPB599FG96qqrdNGiRfr6669rbGysdurUyTrRS05Otj2M1jQP0/Wkan+uyN13360tW7bU33//XVXPPwy3Q4cO2rNnT8fpVc93mBEREepyubRcuXK6efNmjY+P14SEBK1evbqGhobanuHh5ETGdJ4uXbpo586d9dtvv9UhQ4Zo7dq1tUuXLpqZmanp6el6yy23aK9evaz0pidKTtqey+XSp556Shs2bKgul0v/9re/6T/+8Q/9+eefvaZ3IiUlJd/PF198kWsfuemmm6xt/Msvv2jz5s3V5XJZD42uVauW9cYzVfNt0ahRI+sZONkvUHnqqaes6S+88II2aNDA+u503ZoM8EzLpGp+HDM9Zjg5xjRr1sx6o+OSJUvU7XZr586ddfjw4XrrrbdqUFCQ7Y2Ppu1CVfXHH3/UK6+8Uj0ej7Zp00a7d++u3bt31zZt2qjH49EaNWrY3ohpWg8n+6xpn6Oa93Ep+/OPf/wjzzcvjhw5UqtWraqrV6/WtLQ0XbdunVavXt32AHOXy6UrV67UwYMHa/ny5TUoKEg7d+6sH3/8cZ4nNqYnDabbwkmZTE8aTLd3aGhorje1BwUFaXJysqqef7th5cqVvZYtLxeOW5yc8JnuH07akun2Ns2juNOrqvbo0UO7du2qKSkpmp6eroMGDbKeXbdq1SqNjIy09YOm4yJVZ33hxVy4j5iWy8k+Zdo/mx6LVc8/C9jbJyAgQEeOHGl9d5o+u+4BAQHaoUMHnT9/fq4/XlzIdDzlZB8xPS+pXr26/vvf/1bV8/tCQECAvvPOO9b0xYsX2956a5qHk3MG0zGF08Blfi5sF6bHPSf9uekYz0nQ2XQe05iAk/G86br1RT9oel7pZOzs5LzSlJMxYX68xUJM83DSXou6Htkuq6BinTp1rFdkr169Wj0ej77yyivW9Dlz5mjt2rWt76YDnY4dO2qnTp1ybZyLvf3ZZJ5SpUpZD42Piory+kr70qVL237r3bu3Nm/eXL/++mtdsWKFNm7cWJs0aWI9FPjCA2Xp0qVtD46/0ObNm3PlsWnTJr3qqqv08ccft/6KmV+9nZzAmdbDtHOuWLGifvvtt9b3rKwsffDBBzUmJkb37NmTq1Nzsp5MBy1O8oiJibE91PzkyZParFkzvfHGGzU9Pb3Q9TBdT6r2zvzKK6/M9TDy9evX2954appeVbVDhw56//33a2pqqj7//PNatWpVvf/++63p/fr1065du1rfnZzImM5ToUIF/eabb1T1/JveXC6X7c2969ev15iYGOu76YmSqnnby7luN2/erAMHDtSyZctqSEiIduvW7aIPii+I7LaV1yevP7Bkl2vgwIFap04d66+Ghw4d0saNG+uDDz5opTfdFqVKldJ9+/ap6vl9NigoyLYf79mzp9D9mukAz0mZTI9jpscMJ8eYUqVKWduqefPmOnnyZNv0l19+2fYAc9N2oXq+fXfp0sXry6BSUlK0S5cueuONNzquh5N91rTPyZmPyUlDdruoW7eu9QbhbB9++KFeddVVXtNnZmbqggULrCBc5cqVddSoUbaAn6r5SYPptnBSJtOTBtPtHRsba12Vo3r+xN3lcllvWt63b596PJ5cdTMZtzg54TPdP5y0JdPtbZpHcafPrsOOHTus76dPn9agoCBrn3z77be1Zs2a1nTTcZGqs75w27Zt+X4WLFhgy8e0XE72KdP+2fRYnD1P1apVbS8QiIuLU5fLpVWqVNG4uDiNj493nD57njlz5miXLl00KChIIyMjdfDgwblelpPNdDzlZB8xPS8JDQ21XZkWFBRk24/379+vYWFhjvNwcs5gOqZwErg0bRemxz0n/bmq2RjPSdDZdB7TmICT8bzpunXSD5oeK03PK52MnZ2cV5oyHRM6iYWY5uGkvToZ2xbEZRVU9NaZ5zwY7du3z9aZOxnoTJ06VatVq2b7q9/Frtgzmad9+/b63HPPqapqy5Ytc10W+/777+cqU+XKlW2XpGefcDdo0EB/+eWXXI01MjJS165dm2d516xZo5GRkbl+P3XqlPbu3Vuvvvpq3b59uwYFBeV78m16AmdaD9POuUyZMl4v6X344Ye1atWq+t///rfQ68l00OIkj9DQ0FyXcKempmqLFi20ffv2unfv3kLlYbqeVM9v7+y/bFeuXDnXIHD//v22A75pelXVcuXKWeXKzMxUt9tt21+SkpK0SpUq1ncn7dt0ngv7nNKlS9vecn3w4EENCQmxvpueKGUzbXsXtok//vhD33rrLW3btq263W6Ni4vzOm9BhYeH65QpU3Tt2rVeP6+//nq+QcWaNWvmelTEypUrbScZptsiOjpaN2/erKrnbylwuVy2trhp0yaNjo7OVRen67YgAzwnZTI9jpkeM5wcYyIiInTbtm2qen5wmP3/bD/99JOtTKbtInuevE4eVVW//fZbDQ0NdVwPJ/usaZ+jer4/W7JkSZ71+Oabb3KdXGX3heXLl7f1D6rn+8Kc9fbWvlVVDxw4oOPGjbOu7s3J9KTBdFs4LZPJSYPp9h48eLDWrVtXP/vsM129erW2a9fO9sbSZcuWafXq1W3LMB23ODnhM90/nLQlJ9vbJI/iTq96vv/P2Q+fOXNG3W63davWnj17cuVhMi5SddYX5hcU9raPmJbLyT5l2j+bHotVVQcMGKANGjTINTbMa7xtmv7Cch0/flynTJmitWrVUrfbrU2bNtVZs2bZ3vRrOp5yso+YnpfEx8frZ599pqrn35Drdrt14cKF1vSlS5fmGn+Z5OH0nMFkTOEkcGnaLkyPe07682wFHeM5CTo7mcckJuBkPG+6bgvTDxb0WGl6Xulk7OzkvNKU6ZjQSSzENA8n7dXJ2LYgLqugYvaOqXr+deMul0uXLl1qTV+7dq1WrVrV+u5koKN6ftBXp04d7d+/v6alpRXoNuCCzrNhwwaNiIjQcePG6csvv6zly5fX0aNH67vvvqtjx47VsmXL6pQpU2zzlCpVKtdtnGfPntWuXbvq1Vdfrd9++61tp33ooYc0NjZWFy9ebLsSISUlRRcvXqxxcXE6aNCgPOvy3nvvaVRUlLrd7jzr7eQEzrQeqmadc9OmTfWtt97yWt6HH35Yy5YtW+j1ZDpocZJHzZo1bft1tlOnTmmLFi20fv36hcrDdD2pnu8469Wrpw0bNtTSpUvr+++/b5v++eef5+poTdKr2k9CVc+315y3Qxw4cMB2wHAa2DCZp3r16rZA16uvvmob9CYlJdkOfKYnShcqSNvLeeuDNz/++KOOGjUqz+kF0bZt21z9UE5bt27N9RfdnAf8ihUreh3oFOZEtFevXtq8eXN955139JZbbtHExES95pprdOfOnbpr1y5t06ZNrr/W5VSQdWs6wHNSJtPjmOkxw8kxpnPnztbtMomJibluW3v99dc1ISHB+m7aLlRVK1WqZOvHL/TRRx9ppUqVHNfDyT5r2ueoqt5yyy06ZsyYAufjcrl0wIAB+thjj2nFihVzBQ2SkpK0fPnytvT5te+srKxcyzA9aTDdFk7KZHrSYLq9T506pd27d9fAwEB1uVzasmVL27F5+fLltpN9VfNxi5MTPtP9w0lbMt3epnkUd3pV1VtvvVVvv/12PX36tGZmZuqQIUNst41++eWXtnlMx0WqzvrCyMhIfeONN3T//v1eP0uXLrXlY1ouJ/uUaf9seizOtnjxYq1WrZq+/PLL1m/5nf+Yps+rH/nvf/+rffr00VKlSmmpUqWs303HU072EdPzktGjR2uFChX0/vvv1/j4eB0xYoTGxMToa6+9pjNnztRq1arlunLYJA8n5wymYwongUvTdmF63HPSn1/oYmM8J0FnJ/OoFjwm4GQ8b7punfSDpsdK0/NKJ2NnJ+eVpkzHhE5jISZ5OGmvTsa2BXFZBRUffvhhTUhI0GeeeUabNWumffr00Vq1aulnn32my5Yt03r16um9995rpXcy0Ml25swZHTBggCYkJGhAQECBni1Y0Hk2bNig11xzTa6/9lSpUiXXrZGqqvXq1cvVeFT/d1CKiYmx7bTp6en64IMPanBwsLrdbvV4POrxeNTlcmlwcLAOHDhQ09PT863LoUOHdMmSJXr69Gmv052cwJnWI1tBO+eJEyfqTTfdlGeZBg4caCuTk/VkOmjJKw+3251nHo888kiewZHU1FRt3rx5oba36XpSVR0/frztc+FD9p944gm98847HadXVa1Vq5bt2SiffPKJdeuD6vmTjJwDIyft23SeAQMG6Ouvv655mTRpkt58883Wd9MTJW8u1vYudoJfFGbNmpXrxCWn5ORk20O1s8t1880366233qrlypXLFbT48ssvNSoqyvpuui2Sk5P1hhtu0NKlS2tiYqL+/vvvOmjQIOsvgQkJCbagpDcXW7emAzwnZTI9jqmaHzNM03///fcaGRmpvXv31qefflpLly6tvXr10meffVZ79+6tISEhOmfOHCu9abtQVR0zZoyWK1dOp06dqtu2bdPk5GRNTk7Wbdu26dSpU/WKK67QcePGOa6Hk33WtM9RPX8CnH2lijenT5+2DQDbtGlje4j8hevt6aef1jZt2ljf4+LijJ+PanrSYLotnJTJyUmD6X6rej4g4+3lB96YjlucnPCZ7h9O2pLp9jbNo7jTq54PCFWvXl0DAwM1KChIy5YtqytWrLCmz5kzx/ZcMNNxUTbTferGG2/Up59+Os+6XLiPmJbLyT5l2j+bHotzOnz4sLZv3147duyox44du+hFFSbpL1b3lJQU6zZeVfPxlJN9xPS85Ny5c/rss8/q3//+d504caJmZWXpe++9p9WqVdPIyEjt27dvrvGFSR5OzktMxxROApem7cL0uJfNpD/3Jr8xnpOgs5N5shUkJuBkPO9k3Zr2g6bHStPzSidjZyfnlaZMx4ROYiGmeThpr07GtgVxWQUVT58+rQ888IDWrVtX+/fvrxkZGfr8889rcHCwulwubdu2ra1xOhnoXOjDDz/URx991KjRf/jhhzpkyJCLznPixAn98ssvdcOGDbaI8oWefPJJ2/ONcjp79qx27tw5106ren6HW7Vqlc6bN0/nzZunq1at8voMJSecnMA5rYeqsyBvQZmsJ6cD25SUFF29erWVx+rVq/PM49dff831l+UL8/H2V4vi3N6+MH78eH3vvffynD5q1Ci97bbbrO9O2ndR9Amq56/MUVXdu3ev7Q1npidKTuzfv9/K35/07dvX9lmwYIFt+rBhwzQxMdH6XlTbYs+ePbp9+3brDdKFUVQB2/zKZHocyynnMaMgb7kr6DFG9fwtdHfeeaeWKVPGGnAGBQVpy5Yt9YMPPihItfNsF9kmT56slSpVst0y4nK5tFKlSvkOzEzrXVCmfU5x2LNnjx46dKjQyzE9aXC6LQoqv5MGl8uV7x8BTPZbE7NmzcozOJld5pzjFl/8Aedi8mpLTgKwF7pYey3u9Glpabp8+XL9+OOPbW839iavcVF2HnmNi7IVdJ9avHixvv322/mW480337xoubJdWC6n+5RJ/2x6LL5QVlaWTpw40XohysXG2wVNb1p30/GUk7FzYc5LCspJHibjedMxhZOLHUzbRV6y22tRHfdMODl/c3rOl1N+MYH9+/d7fdlZYcb4+a3bgo6lnJzjF4WiHM87YTomNB1TOMnDSXstrrGtS1VVLnPp6ely9uxZKVOmjNF8+/btE4/HI5UqVco3XXBwsGzbtk1q165dmGI69ueff8qZM2ckPDw8z+lHjhyR2NjYfJdzOdTjo48+kjVr1sjIkSOlYsWKxVLO/NbTb7/9JkePHpW//e1vXuc9deqUbNmyRdq0aVMsZTNR0tu7qJ05c0YCAgIkJCSkQOkL2r6dzJPfuj1z5oysX79eMjIy5JprrpHy5csXOP/LWVpamgQEBIjH4ylQeifbr7AOHDggMTEx4nK5CrUcJ23P9DhWXO1bVeXEiROSlZUl5cuXl6CgoALPW9Ay7du3T5KTk0VEJDo6WuLj44s8j6Jg2uf4g5MnT8revXslKytLKlWqJHFxcfmmL8y2cGLv3r1y5swZqVWrlgQGBhZrXoVVVP1BcTLd3jmZtqXiTu/EpTbOKew+VZj+OVtBj8VJSUmybt066d27t5QrV+6iyzVNXxDFPZ4qqvOr4s6jOMYUqampkpSUZOv/GzdunGc5i0JJtlcn528ldc5H3+mffDEmzCuPomyvTuvh3yO2IuLxeMTj8cihQ4dk3LhxMnv2bGvazp075csvv5QWLVpIrVq1ZNeuXTJ9+nTJyMiQXr16Sfv27a20Q4cO9br8c+fOyeTJkyUyMlJERKZOnWqb/scff0hSUpJcccUVUqdOHdu09PR0WbhwofTu3dtx+sDAwHx3mmPHjsmECROsejutR2GkpaXJwoUL5aeffpJKlSpJz549rXyymdZDJPf2u+qqq+TTTz+VESNG5Np+ppysp3LlyklycrLMmTOnQPuUiPn2Np2nJLZ3Sfjll18K1b69udh+62TdHjhwQA4fPiwtWrSQ8uXLG5epIJzsUyWdx6+//lro7Vfc9Y6NjfXJMcObvI5jTvIozHpyuVwSFRVl+60oypRTfHx8ruBVSdfbG299jhO+aK/Z+23Lli2lefPmsmvXLpkyZcpF+52CbIuiKFPNmjVLvH3nLFNB2rdpf+CUk3qbbG/TtlTc6Z3U21fj84vx1jZM8ijsPlWQ/vlivB2LvWncuLE0bty4wHmYpr+Qt3lMx1PFfX7lhEkevhhTiNj7wXbt2lnr9e2333bUrxX1GKE4lCtXzhbs9jb+vzA46GQef+vXimJbFOQc35QvjvdFrTjOQ03zKIr26nhsa3xt4yVs69attsuQP/vsMw0ODtYrrrhCPR6PfvbZZ1qhQgXt0KGDtm/fXgMCAmz3nLtcLm3QoIHtWQVt27ZVl8ulTZs21bZt22q7du1see7evVtjY2OtW4iuu+46220eF74ZyjS9k3o7qYep2rVrWw9LPnjwoMbFxWlERIQ2bdpUr7jiCq1YsaLxbWqF3X6mnKwn0zJ5295Hjhyxpnvb3qb7iC+2tz8oiv3DdL81XbfFvc+qFk8f4os8Crv9fFFvXxwzLqaw/fmleoy5FOrthD/utxdTFPW+HNq3v/bnxd1PFXd6J/X2RR4FcWHbMM2jOPYp0/bqpH2XRB7+0IcURV9okocvjq2+2Af98bzEyXmr6Tz+2K85yaM4zvELUwd/URJtyR+OGdkuq9ufP/roo3yn7927Vx5//HE5d+6ciIi0bNlS2rdvL88884zMnz9fHnroIRk4cKA8++yzIiIycuRISUpKkv/85z8iIjJ58mSZNWuW/Otf/7JFfYOCgmTbtm25IukiIrfeequcPXtW3nzzTfn9999lyJAh8v3338vatWslJiZGjh8/LpUrV7bKZJreSb2d1MOU2+2W5ORkqVixovTq1Uv27dsnn376qURERMjp06fl1ltvlQoVKsi8efMc18N0+5lysp5My+Rke5vO44vt7Qu+2D9M91vTdVvc+6yIs33KF3kU9/bzRb19ccwo7v7cX48xl0O9nfDH/dYX9b4c2re/9ufF3U8Vd3on9fZFHiLmbcM0Dyf7lGmZnLRvf8zDF32IL/pCkzx8cWz1xT7oj+clTs5bTefxx37NSR5O1pUJXxzvnfDHtuSLPArMOAzpx7Ij2hc+mDrnJ2fkNTw8XH/88UdVPf/GrsDAQN2yZYs1ffv27bnegLZp0ya96qqr9PHHH9fMzExV1XzfZlaxYkX99ttvre9ZWVn64IMPakxMjO7ZsydXtN00vZN6O6mHqZwPXL7yyitzvdJ+/fr1Wq1atULVw8n2M2W6nkzL5GR7O5mnuLe3L/hi/3Cy35qsW1/ss072D1/kUdzbzxf19sUxo7j7c389xlwu9Tblj/utL+p9ObRvf+3PfdFPFXd6X4xzfNEnmObhdNxiUiYn7dsf8/BFH+KLvtA0j+I+tvpiH3RSj+Lmcjk7bzWZx1/7NSf7lOm6MuGL470T/tiWfNVeC8JtFoL0b5UqVZLFixdLVlaW18+WLVtyzeP6/w9Ddrvd4vF4JCIiwppWpkwZSUlJsaVv2rSpJCUlycmTJ6VJkyayY8eOfB+o/Mcff9geNu5yueS1116TW265Rdq0aSM//PBDodI7rbdpPZzIXl56enqulylUqVJFTp48Weh6mG4/U07Wk0mZnGxvJ/P4YnsXN1/tH6b7rem6Le591sn+4Ys8inv7+aLepmUSMd8/irs/99djzOVSb1P+uN/6ot6mZfLH9eQkvSmn9S7ufqq40/tinOOLPsFJHqbbzrRMTtq3P+Zhuq789Rhgmocvjq3FvQ86qYcvmI7/Tefx136tMOe6JuuqoHx1vDflr23JF3kUxGUVVGzcuLEkJSXlOd3lconmuNs7Li5OfvzxR+v7xo0bJSYmxvp+8OBBr28WLV26tMydO1dGjhwpHTp0yPfy0Fq1asnmzZtz/T5jxgzp0qWLdO7cuVDpRczr7aQeTlx//fXSqFEjSU1Nld27d9umHThwINdDXH21/UyZrCfTMjnZ3k7mMa2HP/LV/mG634oUfN36Yp91un8Udx7Fvf18UW9fHDOKuz/312PM5VRvE/643/qi3pdD+/bX/twX/VRxp/fFOMcXfYJpHk62nWmZnLRvf8zDF32IL/pCJ3kU57HVF/ugk3r4gpPxv8k8/tqvmeYh4mxdFZQvjvdO+GNb8mV7vZjL6u3Pw4YNk7S0tDyn16hRQ9asWWN9HzhwoK3R1K1b15b+s88+y/eNOXfeeae0bt1akpKSJDY21muaW2+9Vd577z255557ck2bMWOGZGVlycyZMx2nFzGvt5N6mBo3bpzte+nSpW3fP/74Y7n22mttv/l6+5kqyHoyLZOT7e1kHtN6+CNf7B9O9tucLrZufbHPFnb/KK48inv7+aLevjhmFHd/7q/HmMux3gXhj/utL+p9ObRvf+3PfdFPFXd6X4xzfNEnmObhZNuZlslJ+/bHPHzRh/iiLyxMHsVxbPXFPuikHsXNyfjfdB5/7ddM8yjsudLF+OJ474Q/tqWSaK95uaxe1AIAAAAAAACg+F1Wtz8DAAAAAAAAKH4EFQEAAAAAAAAYIagIAAAAAAAAwAhBRQAAAAAAAABGCCoCAAAAAAAAMEJQEQAAAAAAAIARgooAAAAAAAAAjBBUBAAAAAAAAGDk/wERkMZm80hpjwAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Only the top 100 facts graphed for visibility \n",
    "comparison_df[:100].plot.bar(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hallucination rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.167957400Z",
     "start_time": "2024-05-23T22:43:45.043956100Z"
    }
   },
   "outputs": [],
   "source": [
    "# True hallucination rate (generations not in true dist)\n",
    "true_hallucinations = pd.merge(collected_generations_counts, true_duplicates_count, on='facts', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.261457200Z",
     "start_time": "2024-05-23T22:43:45.168457700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 facts  count_generated  count_true\n0                 Albertine,ice cream                 1         1.0\n1                  Archibald,omelette                 6         2.0\n2                     Archibald,pizza                 1         2.0\n3                Arlen,chocolate cake                 2         3.0\n4               Astrix,baby back ribs                 1         1.0\n..                                 ...              ...         ...\n330  lasagna ,grilled cheese sandwich                 1         NaN\n331               macarons ,guacamole                 1         NaN\n332              miso soup ,escargots                 1         NaN\n333             poutine ,clam chowder                 1         NaN\n334             ramen ,chocolate cake                 1         NaN\n\n[335 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n      <th>count_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Archibald,omelette</td>\n      <td>6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Archibald,pizza</td>\n      <td>1</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arlen,chocolate cake</td>\n      <td>2</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Astrix,baby back ribs</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>lasagna ,grilled cheese sandwich</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>macarons ,guacamole</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>miso soup ,escargots</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>poutine ,clam chowder</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>ramen ,chocolate cake</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>335 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.353456300Z",
     "start_time": "2024-05-23T22:43:45.261457200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate of true hallucinations: 0.034 \n"
     ]
    }
   ],
   "source": [
    "true_hallucinations = true_hallucinations.fillna(0)\n",
    "try:\n",
    "    number_of_true_hallucinations =true_hallucinations[\"count_true\"].value_counts()[0]\n",
    "    true_hallucinations_rate = number_of_true_hallucinations / len(collected_generations)\n",
    "except:\n",
    "    number_of_true_hallucinations = 0\n",
    "    true_hallucinations_rate = 0\n",
    "print(f\"Rate of true hallucinations: {true_hallucinations_rate} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.446456200Z",
     "start_time": "2024-05-23T22:43:45.353956400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Naive hallucination rate (every generation not in training data)\n",
    "naive_hallucinations = pd.merge(collected_generations_counts, training_duplicates_count, on='facts', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.538955100Z",
     "start_time": "2024-05-23T22:43:45.446956600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                 facts  count_generated  count_train\n0                 Albertine,ice cream                 1          1.0\n1                  Archibald,omelette                 6          2.0\n2                     Archibald,pizza                 1          1.0\n3                Arlen,chocolate cake                 2          3.0\n4               Astrix,baby back ribs                 1          1.0\n..                                 ...              ...          ...\n330  lasagna ,grilled cheese sandwich                 1          NaN\n331               macarons ,guacamole                 1          NaN\n332              miso soup ,escargots                 1          NaN\n333             poutine ,clam chowder                 1          NaN\n334             ramen ,chocolate cake                 1          NaN\n\n[335 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n      <th>count_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Archibald,omelette</td>\n      <td>6</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Archibald,pizza</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arlen,chocolate cake</td>\n      <td>2</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Astrix,baby back ribs</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>lasagna ,grilled cheese sandwich</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>macarons ,guacamole</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>miso soup ,escargots</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>poutine ,clam chowder</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>ramen ,chocolate cake</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>335 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.632455700Z",
     "start_time": "2024-05-23T22:43:45.540455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate of naive hallucinations: 0.034 \n"
     ]
    }
   ],
   "source": [
    "naive_hallucinations = naive_hallucinations.fillna(0)\n",
    "try:\n",
    "    number_of_naive_hallucinations = naive_hallucinations[\"count_train\"].value_counts()[0]\n",
    "    naive_hallucinations_rate = number_of_naive_hallucinations / len(collected_generations)\n",
    "except:\n",
    "    number_of_naive_hallucinations = 0\n",
    "    naive_hallucinations_rate = 0\n",
    "\n",
    "print(f\"Rate of naive hallucinations: {naive_hallucinations_rate} \")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "naive_hallucinations_df = naive_hallucinations[naive_hallucinations[\"count_train\"] == 0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.725456200Z",
     "start_time": "2024-05-23T22:43:45.632955800Z"
    }
   },
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                      facts  count_generated  count_train\n8                         Astrix,pork chop                 1          0.0\n18                         Benita,pad thai                 1          0.0\n49                      Deane,tuna tartare                 1          0.0\n61              Deidre,macaroni and cheese                 1          0.0\n75                          Edith,Augustine                1          0.0\n76                            Edith,Valerie                1          0.0\n95                        Ermentrude,ramen                 1          0.0\n108                        Felicio,Violetta                1          0.0\n132                        Jacinthe,paella                 1          0.0\n135                          Jammal,Kathlin                1          0.0\n157                   Karil,fish and chips                 1          0.0\n162               Katey,chicken quesadilla                 1          0.0\n166                           Katey,waffles                1          0.0\n176                        Koressa,oysters                 1          0.0\n218                         Morry,pad thai                 1          0.0\n229                    Neddy,croque madame                 1          0.0\n233                        Neddy,guacamole                 1          0.0\n249                        Ranee,pork chop                 1          0.0\n261                     Rossy,caesar salad                 1          0.0\n285                            Simon,Marlin                1          0.0\n297                           Tana,baklava                 1          0.0\n309                          Violetta,Arlen                1          0.0\n323               chicken curry ,dumplings                 1          0.0\n324                 chicken wings ,cannoli                 1          0.0\n325                fish and chips ,poutine                 1          0.0\n326                french fries ,escargots                 1          0.0\n327  french onion soup ,chicken quesadilla                 1          0.0\n328                fried calamari ,mussels                 1          0.0\n329                  frozen yogurt ,donuts                 1          0.0\n330       lasagna ,grilled cheese sandwich                 1          0.0\n331                    macarons ,guacamole                 1          0.0\n332                   miso soup ,escargots                 1          0.0\n333                  poutine ,clam chowder                 1          0.0\n334                  ramen ,chocolate cake                 1          0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n      <th>count_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>Astrix,pork chop</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Benita,pad thai</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Deane,tuna tartare</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>Deidre,macaroni and cheese</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>Edith,Augustine</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>Edith,Valerie</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Ermentrude,ramen</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>Felicio,Violetta</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>132</th>\n      <td>Jacinthe,paella</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>Jammal,Kathlin</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>Karil,fish and chips</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>162</th>\n      <td>Katey,chicken quesadilla</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>Katey,waffles</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>Koressa,oysters</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>Morry,pad thai</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>229</th>\n      <td>Neddy,croque madame</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>233</th>\n      <td>Neddy,guacamole</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>249</th>\n      <td>Ranee,pork chop</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>Rossy,caesar salad</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>285</th>\n      <td>Simon,Marlin</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>Tana,baklava</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>309</th>\n      <td>Violetta,Arlen</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>chicken curry ,dumplings</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>324</th>\n      <td>chicken wings ,cannoli</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>325</th>\n      <td>fish and chips ,poutine</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>326</th>\n      <td>french fries ,escargots</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>327</th>\n      <td>french onion soup ,chicken quesadilla</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>328</th>\n      <td>fried calamari ,mussels</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>frozen yogurt ,donuts</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>lasagna ,grilled cheese sandwich</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>macarons ,guacamole</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>miso soup ,escargots</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>poutine ,clam chowder</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>ramen ,chocolate cake</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_hallucinations_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.818455900Z",
     "start_time": "2024-05-23T22:43:45.725456200Z"
    }
   },
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hallucinations_list = naive_hallucinations_df[\"facts\"].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:45.911455800Z",
     "start_time": "2024-05-23T22:43:45.818455900Z"
    }
   },
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Monofact rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.003958Z",
     "start_time": "2024-05-23T22:43:45.912455800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.43875"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    MF = training_duplicates_count[\"count_train\"].value_counts()[1] / len(training_data)\n",
    "    mf_df = training_duplicates_count[training_duplicates_count[\"count_train\"] == 1]\n",
    "    monofact_list = mf_df[\"facts\"].tolist()\n",
    "except:\n",
    "    MF = 0\n",
    "MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.097456100Z",
     "start_time": "2024-05-23T22:43:46.004457900Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.lib.calibration import miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.190958300Z",
     "start_time": "2024-05-23T22:43:46.097956200Z"
    }
   },
   "outputs": [],
   "source": [
    "comparison_sorted_by_generated = comparison_df.sort_values(by='count_generated', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.283458100Z",
     "start_time": "2024-05-23T22:43:46.191458100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive binning with 9 bins\n",
      "bin with g_proba / p_proba 0.101 0.112\n",
      "bin with g_proba / p_proba 0.10600000000000001 0.105\n",
      "bin with g_proba / p_proba 0.10899999999999999 0.09399999999999999\n",
      "bin with g_proba / p_proba 0.10900000000000004 0.08700000000000002\n",
      "bin with g_proba / p_proba 0.10900000000000003 0.05500000000000001\n",
      "bin with g_proba / p_proba 0.11000000000000007 0.054000000000000006\n",
      "bin with g_proba / p_proba 0.11100000000000006 0.066\n",
      "bin with g_proba / p_proba 0.11100000000000008 0.07100000000000001\n",
      "bin with g_proba / p_proba 0.11100000000000008 0.10600000000000004\n",
      "bin with g_proba / p_proba 0.023000000000000013 0.2500000000000001\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.2577857142857143"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscalibration_rate = miscalibration(comparison_sorted_by_generated['count_generated'], comparison_sorted_by_generated['count_true'])\n",
    "miscalibration_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.375956Z",
     "start_time": "2024-05-23T22:43:46.283958100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive binning with 9 bins\n",
      "bin with g_proba / p_proba 0.101 0.1125\n",
      "bin with g_proba / p_proba 0.10600000000000001 0.10250000000000001\n",
      "bin with g_proba / p_proba 0.10899999999999999 0.09125000000000003\n",
      "bin with g_proba / p_proba 0.10900000000000004 0.09125000000000003\n",
      "bin with g_proba / p_proba 0.10900000000000003 0.06375000000000001\n",
      "bin with g_proba / p_proba 0.11000000000000007 0.0625\n",
      "bin with g_proba / p_proba 0.11100000000000006 0.07750000000000001\n",
      "bin with g_proba / p_proba 0.11100000000000008 0.08625\n",
      "bin with g_proba / p_proba 0.11100000000000008 0.12375\n",
      "bin with g_proba / p_proba 0.023000000000000013 0.18875\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.21769325396825395"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscalibration(comparison_sorted_by_generated['count_generated'], comparison_sorted_by_generated['count_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if it holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.468955700Z",
     "start_time": "2024-05-23T22:43:46.376958100Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_names = len(set([t[1] for t in train_dataset]))\n",
    "unique_foods = len(set([t[2] for t in train_dataset]))\n",
    "# Possible generations\n",
    "POSS_GENERATIONS = unique_names * unique_foods\n",
    "\n",
    "# Facts to all possibilities - facts, approximated\n",
    "APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS = 300 * len(training_duplicates_count) / (POSS_GENERATIONS - len(training_duplicates_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.546456100Z",
     "start_time": "2024-05-23T22:43:46.469455900Z"
    }
   },
   "outputs": [],
   "source": [
    "HALLUCINATION_RATE = true_hallucinations_rate\n",
    "\n",
    "#MF = 0.43875\n",
    "\n",
    "MISCALIBRATION = miscalibration_rate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.43875"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.638955Z",
     "start_time": "2024-05-23T22:43:46.547458800Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.2577857142857143"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MISCALIBRATION"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.733455400Z",
     "start_time": "2024-05-23T22:43:46.639956100Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.825454900Z",
     "start_time": "2024-05-23T22:43:46.733455400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.1984123881878179"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:46.918455200Z",
     "start_time": "2024-05-23T22:43:46.825957300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.1809642857142857"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF - MISCALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.011455900Z",
     "start_time": "2024-05-23T22:43:46.918955600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.24748737341529162"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 / np.sqrt(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.104955100Z",
     "start_time": "2024-05-23T22:43:47.012458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "-0.2649354758888238"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_hallucination_rate = MF - MISCALIBRATION - (7 / np.sqrt(len(training_data))) - APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS\n",
    "estimated_hallucination_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.197457900Z",
     "start_time": "2024-05-23T22:43:47.105455900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.034"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HALLUCINATION_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.290455400Z",
     "start_time": "2024-05-23T22:43:47.197956600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HALLUCINATION_RATE > MF - MISCALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.367957700Z",
     "start_time": "2024-05-23T22:43:47.291458800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HALLUCINATION_RATE > MF - MISCALIBRATION - (7 / np.sqrt(len(training_data))) - APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "def save_results():\n",
    "    experiment = {}\n",
    "    experiment['number of person'] = dataset.number_person\n",
    "    experiment['food_list'] = dataset.food_list_name\n",
    "    experiment['true_dist_size'] = dataset.true_dist_size\n",
    "    experiment['training_set_size'] = len(training_data)\n",
    "    experiment['zipf_alpha'] = alpha\n",
    "    experiment['monofact_rate'] = MF\n",
    "    experiment['miscalibration_rate'] = MISCALIBRATION\n",
    "    experiment['facts_to_possible_hallucinations_ratio'] = APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS\n",
    "    experiment['estimated_hallucinations_rate'] = estimated_hallucination_rate\n",
    "    experiment['naive_hallucinations_rate'] = naive_hallucinations_rate\n",
    "    experiment['true_hallucinations_rate'] = true_hallucinations_rate\n",
    "    \n",
    "    json_str = json.dumps(experiment)\n",
    "    with open('experiment/experiments.json', 'a') as file:\n",
    "        file.write(json_str + '\\n')\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.445957100Z",
     "start_time": "2024-05-23T22:43:47.367957700Z"
    }
   },
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#save_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:47.523455500Z",
     "start_time": "2024-05-23T22:43:47.445957100Z"
    }
   },
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 2.0796e-02,  8.9657e-03, -6.4650e-03, -1.8630e-02, -5.7323e-03,\n",
      "           1.8417e-02,  1.7914e-02,  6.1629e-02,  5.3536e-02,  1.1334e-02,\n",
      "           1.7572e-02,  4.0279e-02, -7.2621e-02, -1.4879e-02,  4.1121e-02,\n",
      "           3.7028e-02,  4.4371e-02,  7.8964e-02, -7.4553e-03, -2.5165e-02,\n",
      "          -8.1933e-02, -4.0355e-02,  5.6867e-02,  3.4438e-02,  7.1217e-03,\n",
      "           4.1960e-02, -4.7407e-02,  2.2690e-02, -3.2619e-02, -4.2211e-02,\n",
      "          -7.9445e-02, -3.9048e-02, -1.5100e-02, -1.6916e-02, -3.0170e-02,\n",
      "           3.5362e-02,  1.7993e-02, -3.8807e-02,  6.7489e-03,  3.6690e-02,\n",
      "           2.0515e-02, -1.6652e-02, -2.1622e-02, -4.9308e-02,  4.8472e-02,\n",
      "           5.0284e-02,  4.5561e-05, -5.6428e-02, -1.5680e-02, -3.0394e-02,\n",
      "           1.3529e-02,  6.0318e-02, -7.9437e-02, -3.6272e-02,  1.2556e-02,\n",
      "          -2.5714e-02,  1.5133e-02,  3.6589e-02,  3.0724e-02, -4.3153e-02,\n",
      "          -3.6944e-02, -3.1468e-02, -5.2988e-02, -1.3803e-02,  3.5970e-02,\n",
      "          -2.1776e-02,  9.7697e-04,  1.0225e-02,  5.6987e-03, -6.2827e-03,\n",
      "          -8.7529e-03,  4.1492e-02, -8.7803e-03,  7.0481e-02,  1.7793e-02,\n",
      "          -2.1141e-02,  6.5175e-03,  1.5632e-03,  2.5032e-02,  2.8230e-02,\n",
      "           2.3916e-02, -7.0452e-02, -1.7932e-02, -2.5381e-02,  4.2562e-02,\n",
      "           2.7450e-02, -4.7772e-02, -3.2333e-02, -4.0896e-03, -4.0207e-03,\n",
      "          -4.2037e-02,  5.3446e-02,  2.3564e-02,  6.8701e-03,  1.8041e-02,\n",
      "           6.9712e-02, -5.2970e-02,  2.3856e-02, -5.7395e-03, -1.6758e-02,\n",
      "          -3.0645e-02, -2.9107e-02,  2.1276e-02,  2.5432e-02,  1.0314e-02,\n",
      "          -4.7962e-04,  7.3715e-03,  3.5543e-03, -7.6966e-03,  1.7230e-02,\n",
      "          -1.1371e-03, -2.8852e-02,  7.5418e-03,  4.6183e-02,  3.6580e-02,\n",
      "          -2.2852e-02,  6.1443e-02,  3.4492e-03,  3.0004e-02, -7.4623e-03,\n",
      "           4.4033e-03,  1.0829e-02,  1.6051e-02, -4.1036e-02,  2.3238e-02,\n",
      "          -3.4585e-02,  3.2387e-02,  1.3447e-02, -1.9362e-02,  4.0200e-02,\n",
      "           4.8450e-02, -4.6204e-02,  8.8417e-02,  5.7267e-03, -3.8831e-02,\n",
      "           8.9985e-03, -9.0882e-02, -4.8482e-03, -1.4015e-02, -2.7769e-02,\n",
      "          -1.7464e-02, -5.7530e-02, -9.4716e-03,  1.9217e-02, -3.3736e-02,\n",
      "          -5.6554e-04,  5.0469e-02, -2.1001e-02,  1.6228e-02, -3.5814e-02,\n",
      "          -5.7037e-02, -1.2007e-04,  2.3483e-02,  1.2294e-03, -5.1725e-02,\n",
      "           6.6239e-02, -5.9789e-03, -3.4196e-02,  5.9452e-03, -2.0804e-02,\n",
      "           4.7677e-03,  3.7544e-02, -3.1668e-02,  2.1770e-02, -7.5158e-02,\n",
      "           2.1978e-02, -1.8339e-02,  4.9580e-02, -8.5509e-03,  2.9390e-02,\n",
      "           1.9381e-02, -5.2912e-02,  3.2405e-02, -1.7687e-03,  5.6284e-02,\n",
      "          -5.7012e-02,  3.8839e-02, -1.1432e-03,  2.7869e-03,  5.3284e-02,\n",
      "          -1.3928e-02, -6.5063e-03,  2.4731e-02,  2.5755e-02,  7.3996e-03,\n",
      "           3.4334e-02,  2.2300e-02,  6.2718e-03,  1.0001e-02,  1.0598e-01,\n",
      "           3.1835e-02,  5.0918e-02, -2.0073e-02,  5.2506e-03, -1.7550e-03,\n",
      "           2.1398e-02, -2.8734e-02, -1.0445e-02, -2.8713e-02, -7.7132e-02,\n",
      "           3.7488e-02,  5.4164e-02, -3.2149e-02,  4.1199e-02, -3.3460e-02,\n",
      "          -2.2523e-02,  1.6080e-03, -7.2282e-02, -1.2428e-02,  8.3966e-04,\n",
      "          -7.8708e-03, -1.5342e-03, -5.5521e-03,  4.1092e-02,  2.1345e-02,\n",
      "          -1.3664e-02, -1.7419e-02,  5.2338e-02,  1.4823e-02,  6.8391e-03,\n",
      "           9.9064e-03, -5.6795e-02,  9.8324e-03, -3.3619e-02,  4.7443e-02,\n",
      "          -7.6062e-03,  4.2357e-02,  5.0715e-02,  2.7102e-02, -2.2447e-02,\n",
      "           1.1189e-02,  6.3305e-02, -2.2599e-02,  2.8311e-02, -1.4057e-02,\n",
      "           1.7859e-03, -6.0859e-02,  6.0365e-02, -3.3276e-02,  1.6918e-02,\n",
      "           8.3974e-04, -4.3824e-02, -2.9863e-02,  3.6289e-02,  1.4256e-02,\n",
      "          -2.7892e-02, -1.5463e-02, -1.1449e-02, -2.0448e-02, -2.9350e-02,\n",
      "          -1.4085e-02, -6.3169e-02,  7.3248e-03,  3.9531e-02,  1.9454e-04,\n",
      "          -4.9405e-02, -6.4485e-02,  1.1686e-02,  2.1004e-02, -2.0198e-02,\n",
      "          -4.4149e-02, -3.8430e-02, -1.6030e-02, -2.0061e-02,  1.1389e-02,\n",
      "           5.1444e-02,  1.3189e-02,  2.4759e-02,  1.4673e-02, -5.9853e-02,\n",
      "           3.7730e-02, -1.2409e-03, -8.6284e-02,  5.7533e-02, -2.1747e-02,\n",
      "           3.7380e-02, -2.0427e-02,  5.6882e-02, -1.5900e-02,  1.4311e-02,\n",
      "          -1.5156e-02,  4.7329e-02,  9.6079e-03, -1.4961e-02, -1.9332e-03,\n",
      "           1.1464e-02, -4.9704e-02, -7.1708e-04,  9.0052e-03,  3.0369e-02,\n",
      "           5.4014e-03,  4.9155e-02,  8.8150e-03,  1.5831e-02, -6.6712e-03,\n",
      "          -3.3089e-02,  2.9420e-02, -2.5117e-03, -6.7143e-02, -1.9013e-02,\n",
      "           2.6331e-03,  9.6434e-03,  2.9084e-02, -5.0055e-03, -2.8642e-02,\n",
      "          -5.9911e-03,  1.4491e-02,  2.2994e-02, -2.4911e-02,  7.5099e-02,\n",
      "          -4.9272e-02, -5.9490e-02,  1.5890e-02, -9.5513e-03,  2.1293e-02,\n",
      "           6.1938e-03,  1.2982e-02,  3.0727e-02, -8.2003e-02,  6.5940e-02,\n",
      "          -3.0080e-02,  5.1695e-03,  1.6942e-02,  2.3413e-02, -3.5945e-02,\n",
      "          -1.8058e-02,  1.1034e-02, -1.4360e-02,  3.8453e-02,  2.4900e-02,\n",
      "           5.1821e-03,  4.0660e-02, -3.0667e-02,  1.3839e-02, -8.0399e-03,\n",
      "           4.3721e-02,  1.5476e-02,  7.6362e-03, -4.5678e-02,  8.5963e-03,\n",
      "           1.9747e-02, -3.8481e-02,  1.2836e-02, -4.1417e-02,  4.0818e-02,\n",
      "           1.0621e-02, -5.8648e-02,  1.0653e-02, -6.6997e-02, -2.4318e-02,\n",
      "           1.1730e-02,  1.9378e-02, -4.7307e-02,  4.4770e-02,  2.4705e-02,\n",
      "          -2.5207e-02, -2.9969e-02,  2.0441e-02,  3.5483e-02, -3.8850e-02,\n",
      "          -1.4550e-02,  6.8107e-02, -4.9107e-02, -1.7501e-03,  3.6690e-02,\n",
      "           8.4390e-03, -9.3753e-03, -5.6812e-03,  8.4276e-03,  8.3104e-03,\n",
      "           8.9436e-03,  1.5479e-02, -5.6687e-02,  1.9967e-02,  2.5556e-02,\n",
      "           4.3470e-02, -3.8419e-02,  6.3181e-02, -2.6214e-02,  9.6805e-03,\n",
      "          -2.9858e-02, -6.0078e-03, -5.3840e-02, -3.3778e-02, -1.0965e-02,\n",
      "           3.1804e-02,  2.5219e-02,  1.7810e-02, -4.9463e-02,  2.6896e-02,\n",
      "           6.7376e-02,  3.4350e-02,  3.5189e-02, -3.5305e-02, -5.6920e-02,\n",
      "          -4.1445e-02, -6.9377e-02, -4.0498e-02, -3.2990e-02, -2.2673e-02,\n",
      "           2.1117e-02,  7.4611e-02, -2.4176e-02,  3.2777e-02,  1.0744e-02,\n",
      "          -2.7783e-02, -2.9297e-02,  9.8522e-03,  8.6632e-03,  7.5985e-03,\n",
      "           9.9425e-03, -3.0026e-02,  2.1212e-02,  7.5709e-03, -3.2565e-02,\n",
      "           8.1399e-03,  1.2156e-02,  1.8636e-03,  2.5982e-02, -2.3573e-02,\n",
      "           2.6175e-02,  3.1027e-03, -1.9415e-02, -1.9872e-03, -5.5959e-02,\n",
      "          -1.1606e-02,  5.1563e-02, -3.4179e-02, -4.9146e-04, -6.0009e-03,\n",
      "          -8.0469e-03,  2.1130e-03,  3.6591e-02,  8.7536e-03, -3.2160e-02,\n",
      "          -6.0318e-02, -4.8540e-03, -1.6502e-02,  5.3975e-02,  1.7482e-02,\n",
      "           6.5556e-03, -1.2996e-02,  5.0345e-02,  3.8434e-02, -5.6514e-02,\n",
      "           7.9373e-03,  1.4102e-02,  6.9685e-02,  2.3979e-03, -2.2682e-02,\n",
      "          -3.8285e-02, -1.8892e-02,  2.4296e-02, -1.7025e-02,  1.1833e-02,\n",
      "           3.1976e-02,  3.7428e-02, -6.2600e-03,  9.9117e-03, -2.0791e-02,\n",
      "          -3.2815e-03,  3.2559e-02, -1.3646e-02, -5.2462e-02, -2.2027e-02,\n",
      "           4.7465e-03,  2.2369e-04, -4.7241e-02,  1.2842e-02,  1.6590e-02,\n",
      "          -1.2751e-02,  9.2341e-03,  2.3428e-03,  1.3707e-02, -2.1391e-02,\n",
      "           6.6901e-02, -6.8096e-03, -2.1412e-02,  1.9411e-02, -2.3320e-02,\n",
      "           4.3773e-02, -4.4333e-02,  1.2111e-02, -6.2831e-02, -3.5379e-02,\n",
      "           7.1425e-02,  2.3015e-02, -5.6751e-02,  2.0213e-02,  5.2047e-02,\n",
      "          -1.7812e-02, -2.4718e-02,  1.3782e-02, -1.2046e-02, -1.8201e-02,\n",
      "          -5.1215e-02, -3.4115e-02, -8.2006e-02, -2.0630e-02,  3.6310e-03,\n",
      "           1.7396e-02,  6.0509e-02,  1.8038e-02, -3.2693e-02,  1.3055e-02,\n",
      "          -1.3184e-02,  3.3822e-02, -3.2756e-02, -1.0207e-02, -5.8339e-03,\n",
      "          -1.1183e-03, -5.2788e-02]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 2.0796e-02,  8.9657e-03, -6.4650e-03, -1.8630e-02, -5.7323e-03,\n",
      "           1.8417e-02,  1.7914e-02,  6.1629e-02,  5.3536e-02,  1.1334e-02,\n",
      "           1.7572e-02,  4.0279e-02, -7.2621e-02, -1.4879e-02,  4.1121e-02,\n",
      "           3.7028e-02,  4.4371e-02,  7.8964e-02, -7.4553e-03, -2.5165e-02,\n",
      "          -8.1933e-02, -4.0355e-02,  5.6867e-02,  3.4438e-02,  7.1217e-03,\n",
      "           4.1960e-02, -4.7407e-02,  2.2690e-02, -3.2619e-02, -4.2211e-02,\n",
      "          -7.9445e-02, -3.9048e-02, -1.5100e-02, -1.6916e-02, -3.0170e-02,\n",
      "           3.5362e-02,  1.7993e-02, -3.8807e-02,  6.7489e-03,  3.6690e-02,\n",
      "           2.0515e-02, -1.6652e-02, -2.1622e-02, -4.9308e-02,  4.8472e-02,\n",
      "           5.0284e-02,  4.5561e-05, -5.6428e-02, -1.5680e-02, -3.0394e-02,\n",
      "           1.3529e-02,  6.0318e-02, -7.9437e-02, -3.6272e-02,  1.2556e-02,\n",
      "          -2.5714e-02,  1.5133e-02,  3.6589e-02,  3.0724e-02, -4.3153e-02,\n",
      "          -3.6944e-02, -3.1468e-02, -5.2988e-02, -1.3803e-02,  3.5970e-02,\n",
      "          -2.1776e-02,  9.7697e-04,  1.0225e-02,  5.6987e-03, -6.2827e-03,\n",
      "          -8.7529e-03,  4.1492e-02, -8.7803e-03,  7.0481e-02,  1.7793e-02,\n",
      "          -2.1141e-02,  6.5175e-03,  1.5632e-03,  2.5032e-02,  2.8230e-02,\n",
      "           2.3916e-02, -7.0452e-02, -1.7932e-02, -2.5381e-02,  4.2562e-02,\n",
      "           2.7450e-02, -4.7772e-02, -3.2333e-02, -4.0896e-03, -4.0207e-03,\n",
      "          -4.2037e-02,  5.3446e-02,  2.3564e-02,  6.8701e-03,  1.8041e-02,\n",
      "           6.9712e-02, -5.2970e-02,  2.3856e-02, -5.7395e-03, -1.6758e-02,\n",
      "          -3.0645e-02, -2.9107e-02,  2.1276e-02,  2.5432e-02,  1.0314e-02,\n",
      "          -4.7962e-04,  7.3715e-03,  3.5543e-03, -7.6966e-03,  1.7230e-02,\n",
      "          -1.1371e-03, -2.8852e-02,  7.5418e-03,  4.6183e-02,  3.6580e-02,\n",
      "          -2.2852e-02,  6.1443e-02,  3.4492e-03,  3.0004e-02, -7.4623e-03,\n",
      "           4.4033e-03,  1.0829e-02,  1.6051e-02, -4.1036e-02,  2.3238e-02,\n",
      "          -3.4585e-02,  3.2387e-02,  1.3447e-02, -1.9362e-02,  4.0200e-02,\n",
      "           4.8450e-02, -4.6204e-02,  8.8417e-02,  5.7267e-03, -3.8831e-02,\n",
      "           8.9985e-03, -9.0882e-02, -4.8482e-03, -1.4015e-02, -2.7769e-02,\n",
      "          -1.7464e-02, -5.7530e-02, -9.4716e-03,  1.9217e-02, -3.3736e-02,\n",
      "          -5.6554e-04,  5.0469e-02, -2.1001e-02,  1.6228e-02, -3.5814e-02,\n",
      "          -5.7037e-02, -1.2007e-04,  2.3483e-02,  1.2294e-03, -5.1725e-02,\n",
      "           6.6239e-02, -5.9789e-03, -3.4196e-02,  5.9452e-03, -2.0804e-02,\n",
      "           4.7677e-03,  3.7544e-02, -3.1668e-02,  2.1770e-02, -7.5158e-02,\n",
      "           2.1978e-02, -1.8339e-02,  4.9580e-02, -8.5509e-03,  2.9390e-02,\n",
      "           1.9381e-02, -5.2912e-02,  3.2405e-02, -1.7687e-03,  5.6284e-02,\n",
      "          -5.7012e-02,  3.8839e-02, -1.1432e-03,  2.7869e-03,  5.3284e-02,\n",
      "          -1.3928e-02, -6.5063e-03,  2.4731e-02,  2.5755e-02,  7.3996e-03,\n",
      "           3.4334e-02,  2.2300e-02,  6.2718e-03,  1.0001e-02,  1.0598e-01,\n",
      "           3.1835e-02,  5.0918e-02, -2.0073e-02,  5.2506e-03, -1.7550e-03,\n",
      "           2.1398e-02, -2.8734e-02, -1.0445e-02, -2.8713e-02, -7.7132e-02,\n",
      "           3.7488e-02,  5.4164e-02, -3.2149e-02,  4.1199e-02, -3.3460e-02,\n",
      "          -2.2523e-02,  1.6080e-03, -7.2282e-02, -1.2428e-02,  8.3966e-04,\n",
      "          -7.8708e-03, -1.5342e-03, -5.5521e-03,  4.1092e-02,  2.1345e-02,\n",
      "          -1.3664e-02, -1.7419e-02,  5.2338e-02,  1.4823e-02,  6.8391e-03,\n",
      "           9.9064e-03, -5.6795e-02,  9.8324e-03, -3.3619e-02,  4.7443e-02,\n",
      "          -7.6062e-03,  4.2357e-02,  5.0715e-02,  2.7102e-02, -2.2447e-02,\n",
      "           1.1189e-02,  6.3305e-02, -2.2599e-02,  2.8311e-02, -1.4057e-02,\n",
      "           1.7859e-03, -6.0859e-02,  6.0365e-02, -3.3276e-02,  1.6918e-02,\n",
      "           8.3974e-04, -4.3824e-02, -2.9863e-02,  3.6289e-02,  1.4256e-02,\n",
      "          -2.7892e-02, -1.5463e-02, -1.1449e-02, -2.0448e-02, -2.9350e-02,\n",
      "          -1.4085e-02, -6.3169e-02,  7.3248e-03,  3.9531e-02,  1.9454e-04,\n",
      "          -4.9405e-02, -6.4485e-02,  1.1686e-02,  2.1004e-02, -2.0198e-02,\n",
      "          -4.4149e-02, -3.8430e-02, -1.6030e-02, -2.0061e-02,  1.1389e-02,\n",
      "           5.1444e-02,  1.3189e-02,  2.4759e-02,  1.4673e-02, -5.9853e-02,\n",
      "           3.7730e-02, -1.2409e-03, -8.6284e-02,  5.7533e-02, -2.1747e-02,\n",
      "           3.7380e-02, -2.0427e-02,  5.6882e-02, -1.5900e-02,  1.4311e-02,\n",
      "          -1.5156e-02,  4.7329e-02,  9.6079e-03, -1.4961e-02, -1.9332e-03,\n",
      "           1.1464e-02, -4.9704e-02, -7.1708e-04,  9.0052e-03,  3.0369e-02,\n",
      "           5.4014e-03,  4.9155e-02,  8.8150e-03,  1.5831e-02, -6.6712e-03,\n",
      "          -3.3089e-02,  2.9420e-02, -2.5117e-03, -6.7143e-02, -1.9013e-02,\n",
      "           2.6331e-03,  9.6434e-03,  2.9084e-02, -5.0055e-03, -2.8642e-02,\n",
      "          -5.9911e-03,  1.4491e-02,  2.2994e-02, -2.4911e-02,  7.5099e-02,\n",
      "          -4.9272e-02, -5.9490e-02,  1.5890e-02, -9.5513e-03,  2.1293e-02,\n",
      "           6.1938e-03,  1.2982e-02,  3.0727e-02, -8.2003e-02,  6.5940e-02,\n",
      "          -3.0080e-02,  5.1695e-03,  1.6942e-02,  2.3413e-02, -3.5945e-02,\n",
      "          -1.8058e-02,  1.1034e-02, -1.4360e-02,  3.8453e-02,  2.4900e-02,\n",
      "           5.1821e-03,  4.0660e-02, -3.0667e-02,  1.3839e-02, -8.0399e-03,\n",
      "           4.3721e-02,  1.5476e-02,  7.6362e-03, -4.5678e-02,  8.5963e-03,\n",
      "           1.9747e-02, -3.8481e-02,  1.2836e-02, -4.1417e-02,  4.0818e-02,\n",
      "           1.0621e-02, -5.8648e-02,  1.0653e-02, -6.6997e-02, -2.4318e-02,\n",
      "           1.1730e-02,  1.9378e-02, -4.7307e-02,  4.4770e-02,  2.4705e-02,\n",
      "          -2.5207e-02, -2.9969e-02,  2.0441e-02,  3.5483e-02, -3.8850e-02,\n",
      "          -1.4550e-02,  6.8107e-02, -4.9107e-02, -1.7501e-03,  3.6690e-02,\n",
      "           8.4390e-03, -9.3753e-03, -5.6812e-03,  8.4276e-03,  8.3104e-03,\n",
      "           8.9436e-03,  1.5479e-02, -5.6687e-02,  1.9967e-02,  2.5556e-02,\n",
      "           4.3470e-02, -3.8419e-02,  6.3181e-02, -2.6214e-02,  9.6805e-03,\n",
      "          -2.9858e-02, -6.0078e-03, -5.3840e-02, -3.3778e-02, -1.0965e-02,\n",
      "           3.1804e-02,  2.5219e-02,  1.7810e-02, -4.9463e-02,  2.6896e-02,\n",
      "           6.7376e-02,  3.4350e-02,  3.5189e-02, -3.5305e-02, -5.6920e-02,\n",
      "          -4.1445e-02, -6.9377e-02, -4.0498e-02, -3.2990e-02, -2.2673e-02,\n",
      "           2.1117e-02,  7.4611e-02, -2.4176e-02,  3.2777e-02,  1.0744e-02,\n",
      "          -2.7783e-02, -2.9297e-02,  9.8522e-03,  8.6632e-03,  7.5985e-03,\n",
      "           9.9425e-03, -3.0026e-02,  2.1212e-02,  7.5709e-03, -3.2565e-02,\n",
      "           8.1399e-03,  1.2156e-02,  1.8636e-03,  2.5982e-02, -2.3573e-02,\n",
      "           2.6175e-02,  3.1027e-03, -1.9415e-02, -1.9872e-03, -5.5959e-02,\n",
      "          -1.1606e-02,  5.1563e-02, -3.4179e-02, -4.9146e-04, -6.0009e-03,\n",
      "          -8.0469e-03,  2.1130e-03,  3.6591e-02,  8.7536e-03, -3.2160e-02,\n",
      "          -6.0318e-02, -4.8540e-03, -1.6502e-02,  5.3975e-02,  1.7482e-02,\n",
      "           6.5556e-03, -1.2996e-02,  5.0345e-02,  3.8434e-02, -5.6514e-02,\n",
      "           7.9373e-03,  1.4102e-02,  6.9685e-02,  2.3979e-03, -2.2682e-02,\n",
      "          -3.8285e-02, -1.8892e-02,  2.4296e-02, -1.7025e-02,  1.1833e-02,\n",
      "           3.1976e-02,  3.7428e-02, -6.2600e-03,  9.9117e-03, -2.0791e-02,\n",
      "          -3.2815e-03,  3.2559e-02, -1.3646e-02, -5.2462e-02, -2.2027e-02,\n",
      "           4.7465e-03,  2.2369e-04, -4.7241e-02,  1.2842e-02,  1.6590e-02,\n",
      "          -1.2751e-02,  9.2341e-03,  2.3428e-03,  1.3707e-02, -2.1391e-02,\n",
      "           6.6901e-02, -6.8096e-03, -2.1412e-02,  1.9411e-02, -2.3320e-02,\n",
      "           4.3773e-02, -4.4333e-02,  1.2111e-02, -6.2831e-02, -3.5379e-02,\n",
      "           7.1425e-02,  2.3015e-02, -5.6751e-02,  2.0213e-02,  5.2047e-02,\n",
      "          -1.7812e-02, -2.4718e-02,  1.3782e-02, -1.2046e-02, -1.8201e-02,\n",
      "          -5.1215e-02, -3.4115e-02, -8.2006e-02, -2.0630e-02,  3.6310e-03,\n",
      "           1.7396e-02,  6.0509e-02,  1.8038e-02, -3.2693e-02,  1.3055e-02,\n",
      "          -1.3184e-02,  3.3822e-02, -3.2756e-02, -1.0207e-02, -5.8339e-03,\n",
      "          -1.1183e-03, -5.2788e-02]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 3.6705e+00,  2.1179e+00,  1.8503e+01, -1.7406e+00, -4.8169e-01,\n",
      "          -4.3610e-01,  3.7892e+00, -6.7707e-02, -2.3028e+00,  8.2103e-01,\n",
      "          -1.3001e+00,  2.4550e+00, -6.9659e-01, -3.7807e-01,  7.6542e-01,\n",
      "           3.6130e+00,  3.0227e-01,  1.3407e+00, -1.3165e+00, -1.7036e+00,\n",
      "          -5.9434e-01, -4.8884e+00,  6.7927e-02,  1.2124e+01, -1.0976e+01,\n",
      "          -5.0156e-01, -7.1369e-01, -2.4217e+00, -5.6986e+00, -1.6589e+00,\n",
      "          -4.3818e+00,  5.6433e-01,  1.1091e+00, -9.7646e-01, -1.2315e+01,\n",
      "           4.7514e+00,  3.1331e-01, -1.3018e+00, -7.6156e+00,  4.2121e-01,\n",
      "           9.6475e-01, -2.5319e-02, -1.4073e+01, -1.9027e+00,  2.9702e-01,\n",
      "          -1.1044e-02,  5.4989e-01, -8.2460e+00, -9.7774e-03,  2.6074e+00,\n",
      "           1.3308e+00,  9.6321e-01,  3.9517e+00, -5.5414e-01, -5.4891e-01,\n",
      "          -6.6737e+00, -7.5787e-01, -7.7944e-01,  1.5741e+00,  7.3014e-01,\n",
      "          -3.8393e-01, -2.2494e+00,  1.0709e+00, -8.4740e-01,  2.3129e+00,\n",
      "           7.2191e-02, -1.9471e-01,  2.2269e+00,  4.7568e+00,  3.1670e-01,\n",
      "           3.8648e-02,  2.0364e-01,  6.1904e-01,  3.7974e-01, -7.7394e-01,\n",
      "          -1.8200e+00,  2.3912e-01,  1.5117e+01, -1.6853e+00,  3.0756e-01,\n",
      "           1.5185e+01, -3.4803e-01, -3.6363e+00, -9.2554e-01,  1.2780e+01,\n",
      "           1.4190e+00,  7.7116e-01,  5.5732e+00,  4.3910e-01, -2.3129e+00,\n",
      "          -1.3013e+00, -1.3374e+00,  1.7660e-01,  7.1933e-01,  2.1226e+00,\n",
      "          -1.0213e+01, -4.1157e-01,  2.3806e-01, -4.4242e-01,  1.1065e+01,\n",
      "          -6.3663e+00,  2.0582e+00,  5.9017e+00,  1.9569e+00,  6.2730e-02,\n",
      "          -8.7939e-01, -9.8444e-01,  1.6810e-01,  1.4461e+00,  1.0841e+00,\n",
      "          -2.6965e+00, -1.8690e+01,  1.1973e+00,  9.1354e-01,  1.1779e+00,\n",
      "          -3.8955e+00,  1.3585e+00, -3.4412e+00, -1.0514e+00,  4.9013e-01,\n",
      "           7.4232e-01,  2.1143e+00, -3.3308e-01,  9.1999e+00,  4.6493e+00,\n",
      "           4.1163e-01,  3.7550e+00,  9.2564e-01,  4.9696e-01, -3.6288e-01,\n",
      "           1.0406e+00, -1.7388e+01,  1.4522e+00,  4.4017e-01,  1.1470e+00,\n",
      "          -1.7200e+00, -2.3619e+00,  1.5177e+01,  2.4543e-02, -1.8191e+00,\n",
      "           3.9276e-01, -7.7900e+00,  7.3289e+00,  2.0592e+00, -2.2476e+00,\n",
      "           2.3298e+00,  2.3663e+00,  5.0632e-01, -1.0040e+00, -4.8893e+00,\n",
      "           8.6587e-01, -5.5883e-01,  1.9164e-01, -5.1179e-01, -9.4539e+00,\n",
      "          -1.3287e-02, -8.8228e-02,  1.6460e+00,  4.6672e-01, -2.7256e+00,\n",
      "           7.1531e+00,  5.2928e+00,  8.5496e-01, -8.4578e-01,  3.8133e-01,\n",
      "           8.4544e+00,  7.8432e-01,  2.2187e+00, -3.8151e+00, -1.3873e+01,\n",
      "           2.9931e-01, -9.9650e-01,  5.5743e-01,  5.4722e-01, -8.9515e-01,\n",
      "          -1.3789e+01,  9.7677e+00, -1.7339e+00,  1.3467e-01, -9.8712e-01,\n",
      "           1.4879e+00, -9.9842e-01, -5.6770e+00,  4.7625e-01, -1.0631e+01,\n",
      "           2.5187e+00, -5.2368e-01,  5.4551e-01, -1.9100e-01, -6.3923e-02,\n",
      "          -1.6010e-01, -2.4082e-01, -3.0625e+00, -3.3912e-01, -2.7982e-01,\n",
      "           1.8212e+00, -5.4515e-01,  2.6442e+00, -3.2046e+00,  2.8493e-01,\n",
      "           6.1883e-03, -2.8940e-01, -1.5000e+00,  1.0876e+00, -1.7964e+00,\n",
      "           5.3741e-01, -3.0641e+00, -2.2037e+01,  5.2961e-01,  1.4258e+00,\n",
      "           2.1971e+00,  3.0154e-01,  3.1719e+00, -2.2078e+00,  3.3618e-01,\n",
      "          -4.9907e-01, -3.1105e+00,  2.1307e+00,  9.9322e-01, -3.9447e+00,\n",
      "           6.8526e-01, -7.7265e+00,  2.2520e+00,  1.3123e-01, -9.1480e-01,\n",
      "          -3.6220e+00,  1.5681e+00, -1.3919e-01,  1.1874e+01,  1.5577e+00,\n",
      "          -5.0933e-01,  1.1616e+01,  6.7210e-01,  1.3766e+00, -4.3266e+00,\n",
      "          -4.2099e-02,  1.8167e-01,  5.4265e-02,  7.2218e-02,  5.4374e+00,\n",
      "          -4.2986e-01, -1.3583e+00,  1.1706e+00, -4.9720e+00, -1.0936e+00,\n",
      "           5.0532e-01,  3.8984e+00, -1.9703e-01, -1.8074e-01, -3.8753e-01,\n",
      "          -4.7511e-01,  4.2334e-01,  6.6969e-01,  2.7029e-01, -1.1667e+00,\n",
      "          -2.1461e+00, -2.8235e+00, -5.3502e-01,  5.0041e+00,  2.2414e+00,\n",
      "           7.0329e-01, -4.3903e-01,  3.1729e-01,  7.3986e-01,  7.4534e-01,\n",
      "          -5.5528e-01,  1.1185e-01,  7.9368e-01, -1.7582e+00, -1.1180e+01,\n",
      "           6.8813e-01, -1.1704e-01, -7.3485e+00,  7.0677e-01,  4.8297e-01,\n",
      "           1.8552e+00, -3.1049e-01,  1.8740e+00, -1.0555e+00, -1.0780e+00,\n",
      "          -6.6003e-01, -2.9287e-01,  3.3258e+00, -1.8075e+00,  8.2308e-01,\n",
      "           2.1632e+00, -2.2085e+00, -1.0285e+00,  3.0644e-01,  6.7242e-01,\n",
      "           1.5382e+00,  1.0158e+00,  3.0983e-01,  7.6873e-01,  2.3496e+00,\n",
      "          -1.1902e+00,  3.9733e-01,  2.9227e-01, -8.2538e-01, -4.8704e-01,\n",
      "           1.4386e-01,  1.5171e-01,  7.3068e-01, -4.9626e-02, -8.1048e-01,\n",
      "          -2.4130e-01, -8.3939e-01,  2.6207e+00, -2.3870e-01,  7.5798e-01,\n",
      "           5.0808e-01, -6.8273e-01,  1.8314e+00,  1.9720e+00,  9.0716e-02,\n",
      "          -6.5697e+00, -1.3700e-01, -3.5646e+00, -1.0465e+00,  1.4633e+00,\n",
      "          -8.3377e-01,  4.6351e-01, -1.4809e+00, -1.5679e-02, -1.7714e+00,\n",
      "          -1.3073e+00,  2.1007e+00, -1.6469e+01,  6.9632e-01, -4.6696e-01,\n",
      "           2.0082e-01,  1.5735e+00,  2.0045e-01, -9.3519e-01, -2.6529e+00,\n",
      "          -3.5769e-01,  1.1676e+00,  3.5640e+00, -5.3767e-01,  1.6278e+00,\n",
      "           4.7408e+00,  3.7825e+00,  1.0007e-02, -1.7993e+00, -8.7529e-01,\n",
      "           5.7561e-01, -4.5861e+00, -2.2887e+00, -1.4509e+00,  7.7934e-01,\n",
      "           2.6143e+00, -1.9371e+00,  1.2560e+00, -4.6657e+00,  2.3960e+00,\n",
      "          -2.4196e+00,  1.7887e+00, -8.2083e-01, -1.3288e-01,  3.8087e+00,\n",
      "           7.0573e-01,  6.7989e+00,  4.1704e-01,  9.9701e-01,  2.6437e-02,\n",
      "          -9.6202e-02, -2.9659e-01, -6.4639e-01,  3.7420e-01,  2.1695e+00,\n",
      "          -5.1464e-01,  2.2743e+00, -9.6499e-01, -1.6039e+00, -1.4881e+00,\n",
      "          -4.9423e-01, -2.5903e+00,  9.3460e-01,  1.4363e+00, -6.2466e-01,\n",
      "           2.1220e+00,  8.9211e-01, -6.2241e-01,  3.0668e-01,  1.8425e-01,\n",
      "          -7.3512e-01, -1.0114e+00, -1.1939e+00, -1.2015e+00, -5.1144e-01,\n",
      "           5.1007e-01, -5.0281e-01,  7.1126e-01,  8.9575e-01, -9.6631e-01,\n",
      "          -3.7619e-01,  3.6115e-01, -2.1349e+00, -8.4253e-01, -1.5671e-01,\n",
      "          -4.7856e+00,  1.8618e+00, -4.6966e+00,  2.2813e+00,  1.3595e+00,\n",
      "           1.2150e+01, -1.8015e+00,  1.2143e+00,  1.4067e+00,  1.0922e+00,\n",
      "          -5.4836e-02,  2.6286e+00,  1.6984e+00, -4.7249e-01, -3.3273e+00,\n",
      "          -5.1439e+00,  4.2066e+00,  1.3762e-01, -2.3863e-01,  5.4467e-01,\n",
      "           5.5462e+00,  1.1872e-01, -1.2780e+00,  1.7741e+00, -1.5421e+00,\n",
      "           2.1049e-01,  1.7788e-01, -1.7215e+00, -5.4087e-01, -4.2853e-01,\n",
      "           7.8156e+00,  1.1954e+00,  1.2447e+00,  7.5249e-01,  2.0240e-01,\n",
      "           9.6724e-01,  8.9452e-01,  9.0626e-01, -2.7323e-01, -8.4271e-02,\n",
      "          -5.9696e-01,  2.5226e+01,  3.9275e+00,  1.6029e-01, -2.1151e+00,\n",
      "           1.0880e+00, -1.5549e+00,  6.8548e+00,  1.7266e+00, -3.4420e-01,\n",
      "           1.1709e+00, -4.7032e-01, -7.3606e-01,  1.3923e+01, -4.1991e-01,\n",
      "          -1.4491e+00,  4.1485e+00,  2.6677e-02,  6.8319e-01, -1.6516e+00,\n",
      "           1.1535e-01,  6.1742e-01,  2.7749e+00, -1.0793e+00,  1.4721e+00,\n",
      "          -7.2320e-01,  2.1911e-02,  1.2880e+00,  3.0714e-01, -1.6629e+00,\n",
      "           5.7620e-02,  2.5856e-01,  6.7630e-01,  1.8486e+00, -1.7759e+00,\n",
      "          -1.1625e+00,  4.8390e+00, -6.2141e-01,  1.2870e+00,  6.8551e+00,\n",
      "           5.6850e-01,  3.3709e-01,  5.4936e-01, -3.0019e+00, -5.3273e-01,\n",
      "          -4.3449e-01, -3.1792e-01,  1.9377e+00,  1.2919e+00,  1.2902e+01,\n",
      "          -3.8880e-01, -1.2255e+01, -7.4779e-01,  5.1989e+00, -2.8150e-01,\n",
      "          -1.3919e+00, -2.2929e-01, -8.4142e+00,  3.5569e-01, -3.3396e-01,\n",
      "          -1.8058e+00, -5.2872e-01, -4.7899e-01, -1.4080e+00,  4.9041e-01,\n",
      "           8.1744e-01,  1.9667e+00, -1.1727e+00,  3.9287e-02,  3.6454e+00,\n",
      "           1.0865e+01, -5.5193e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 5.8289e+00,  9.1978e-02,  3.6421e+01, -8.9888e-01,  9.3105e-01,\n",
      "          -1.2310e+00,  1.0238e+01, -1.1979e+00, -5.1899e+00, -7.8316e-01,\n",
      "          -2.1267e+00,  3.7462e+00,  3.8164e-01, -1.4850e+00,  5.8492e-01,\n",
      "           5.0662e+00,  4.0784e-01,  3.5847e+00, -3.0934e+00, -1.0707e+00,\n",
      "          -1.4305e+00, -1.0532e+01, -3.4178e-01,  2.4944e+01, -1.9519e+01,\n",
      "          -3.0050e+00, -7.4854e-01, -6.3541e+00, -1.2236e+01, -3.7167e+00,\n",
      "          -7.5477e+00, -1.4796e+00,  3.8515e+00, -1.3467e+00, -2.3054e+01,\n",
      "           9.3457e+00,  2.5833e+00, -6.1392e-01, -1.3089e+01,  3.5042e-01,\n",
      "           1.3935e+00,  7.6138e-01, -2.5421e+01, -3.4357e+00,  1.0072e+00,\n",
      "           2.0188e-01,  1.4513e-01, -1.0373e+01,  1.7606e-01,  5.7912e+00,\n",
      "           1.6703e+00, -1.8228e+00,  8.4928e+00, -5.8028e-01,  8.2341e-01,\n",
      "          -1.5036e+01, -2.7718e+00,  1.4858e-01, -4.1465e-01,  1.1253e+00,\n",
      "          -7.7558e-01, -3.0799e+00,  2.6145e+00,  5.8373e-01,  2.1054e+00,\n",
      "           7.1290e-01,  4.1947e-01,  2.9241e+00,  9.9913e+00, -1.0167e-01,\n",
      "          -1.6410e+00, -5.7166e-01, -3.2547e-01, -7.6607e-01, -1.2359e+00,\n",
      "          -2.5998e+00, -2.3785e+00,  3.1141e+01, -3.0817e+00,  9.3745e-01,\n",
      "           3.0722e+01,  4.2858e-01, -8.5436e+00, -5.9753e-01,  2.0664e+01,\n",
      "           2.1506e+00,  1.1583e+00,  1.1717e+01,  2.3291e+00, -5.0913e+00,\n",
      "          -3.3354e+00, -4.2134e+00, -2.0379e-01,  1.8423e+00,  1.9073e+00,\n",
      "          -1.7206e+01, -1.3085e+00,  1.5865e+00, -7.8962e-02,  1.9466e+01,\n",
      "          -1.1987e+01,  3.1152e+00,  1.3619e+01,  2.7218e+00, -1.0979e+00,\n",
      "          -8.0823e-01, -2.0517e+00, -2.3723e-01,  8.6307e-01,  5.9748e+00,\n",
      "          -9.4767e+00, -3.5816e+01,  1.2131e+00,  1.8880e+00,  3.0341e+00,\n",
      "          -4.9925e+00, -9.0185e-01, -6.3488e+00, -3.9386e-01,  2.5374e+00,\n",
      "           1.9879e+00,  2.4958e+00, -2.4632e+00,  1.9697e+01,  6.8430e+00,\n",
      "          -1.3854e+00,  4.7844e+00,  1.2152e+00,  5.8745e-01, -4.9260e+00,\n",
      "           1.2203e+00, -3.2405e+01,  1.1487e+00, -3.3644e-01,  1.4951e+00,\n",
      "          -5.4483e+00, -4.0040e+00,  2.8928e+01,  6.2596e-01, -1.8585e+00,\n",
      "           8.6983e-01, -1.3781e+01,  1.2722e+01,  4.2203e+00, -8.9930e+00,\n",
      "           4.7108e+00,  3.6716e+00, -2.0147e-01, -1.8254e+00, -5.9570e+00,\n",
      "           1.3409e+00, -4.3907e-02,  6.4947e-01, -3.4650e+00, -1.5350e+01,\n",
      "          -1.7433e+00, -3.7322e-01,  2.8518e+00,  9.7306e-01, -7.2169e+00,\n",
      "           1.2607e+01,  1.0984e+01,  1.3568e+00, -1.6004e+00,  1.9259e+00,\n",
      "           1.6620e+01,  1.6095e+00,  2.0170e+00, -5.8228e+00, -3.0198e+01,\n",
      "          -2.6329e-01, -9.7957e-02, -1.0983e+00,  1.9597e+00, -5.8147e-01,\n",
      "          -2.5707e+01,  1.7741e+01, -1.9626e+00, -4.8899e-01, -4.8832e+00,\n",
      "           1.7655e+00, -2.0454e+00, -1.2566e+01, -4.3208e-01, -2.2579e+01,\n",
      "           1.7130e+00,  3.5743e-01,  2.1433e+00, -6.6391e-01, -2.8797e+00,\n",
      "          -1.8169e-01,  2.0334e+00, -4.5486e+00, -2.3379e-01, -4.0542e-01,\n",
      "           2.0986e+00,  8.4009e-01,  6.4807e+00, -3.6828e+00,  3.8295e-01,\n",
      "           6.0737e-01,  4.1855e-02, -1.6067e+00,  2.9124e+00, -5.3031e-01,\n",
      "          -1.6665e+00, -3.3439e+00, -4.0323e+01,  4.2430e-01,  1.9196e+00,\n",
      "           7.6326e+00,  1.1327e+00,  4.0224e+00, -5.4212e+00,  5.0977e-02,\n",
      "          -2.5404e+00, -4.2965e+00,  7.9892e-01,  1.2319e+00, -1.2912e+01,\n",
      "          -8.5811e-01, -1.3945e+01,  3.6200e+00,  6.7083e-01, -2.0053e-01,\n",
      "          -8.4600e+00,  1.1264e+00, -8.1357e-02,  2.3832e+01,  4.2475e+00,\n",
      "          -9.5977e-01,  2.2708e+01, -6.9782e-01,  3.6177e+00, -6.7344e+00,\n",
      "           4.1242e-01,  2.2673e+00,  7.6298e-01, -9.5098e-01,  1.0586e+01,\n",
      "          -1.3118e-01, -2.4463e-01,  2.3909e+00, -1.3530e+01, -6.8296e-01,\n",
      "           8.1934e-01,  8.2133e+00, -8.7598e-01,  5.0586e-01, -1.8440e+00,\n",
      "          -6.8559e-01,  1.2680e+00,  2.3595e-01,  1.5966e+00, -1.9523e+00,\n",
      "          -7.1876e+00, -4.5877e+00, -2.1065e+00,  7.1222e+00,  3.1783e+00,\n",
      "           7.9857e-01, -8.3412e-01,  1.6651e+00,  1.8646e+00,  2.4859e-01,\n",
      "           4.4075e-01,  1.0543e+00,  1.9283e+00, -3.0785e+00, -2.1278e+01,\n",
      "           8.2968e-01, -6.2111e-01, -1.3348e+01,  1.4621e+00, -1.0082e+00,\n",
      "           4.5299e+00, -1.9460e+00,  3.5062e+00, -2.7977e+00, -1.3908e+00,\n",
      "          -2.0903e+00, -8.7639e-01,  6.2706e+00, -3.6136e+00,  2.5027e+00,\n",
      "           1.0898e+00, -4.4918e+00, -8.7876e-01,  1.2885e+00, -2.1491e+00,\n",
      "           4.9233e+00,  1.4959e+00,  5.8763e-01,  8.3590e-01,  2.9395e+00,\n",
      "          -3.3580e+00, -8.9527e-01,  6.3157e-01, -8.7129e-01, -1.6297e+00,\n",
      "          -9.9413e-01,  9.9081e-01,  7.1629e-01,  1.2196e+00, -1.1461e-01,\n",
      "           1.5935e+00, -1.0830e+00,  2.1669e+00,  6.8920e-01, -3.6263e+00,\n",
      "           1.6709e+00, -1.7508e+00,  3.7821e+00,  2.6358e+00, -1.2014e+00,\n",
      "          -1.1582e+01,  4.0108e-01, -7.7061e+00, -8.6102e-02,  2.1096e+00,\n",
      "          -5.6367e-01,  1.4942e+00, -3.2694e+00,  7.3481e-01, -1.4348e+00,\n",
      "          -1.8283e+00,  2.3023e+00, -3.1387e+01,  2.5165e+00, -6.4513e-01,\n",
      "           1.0315e+00,  1.8840e+00, -1.4770e+00, -3.2593e+00, -4.3176e+00,\n",
      "           1.9191e-01,  2.0341e+00,  7.1077e+00, -1.9656e+00,  2.0601e+00,\n",
      "           1.0319e+01,  8.7686e+00,  4.1663e-01, -1.8236e+00, -1.0532e+00,\n",
      "          -3.7003e-01, -7.8131e+00, -6.4626e+00, -1.5369e+00,  5.2542e-01,\n",
      "           3.6007e+00, -3.2505e+00,  3.7462e+00, -9.1750e+00,  4.6593e+00,\n",
      "          -5.2739e+00,  2.8237e+00, -2.0101e+00,  9.7760e-01,  1.3778e+01,\n",
      "           1.1517e+00,  1.2287e+01, -1.2795e+00,  2.7728e+00, -4.7564e-01,\n",
      "          -2.7819e+00, -8.2770e-01, -5.9335e-01,  1.3440e+00,  3.8627e+00,\n",
      "          -2.3501e+00,  3.0850e+00, -1.7962e+00, -3.4622e+00,  3.4809e-01,\n",
      "          -1.4007e+00, -3.3477e+00,  1.1790e+00,  2.8861e+00, -6.8765e-01,\n",
      "           6.4213e+00,  1.8969e-01, -1.7010e+00,  8.2970e-01, -6.9813e-01,\n",
      "          -1.6600e+00, -1.5418e+00, -2.9868e-01, -2.4880e+00,  1.3736e-01,\n",
      "           1.0122e+00, -3.1332e-01,  3.5009e-01,  2.6721e+00, -2.6508e+00,\n",
      "           3.6521e+00, -2.5820e-01, -5.8474e+00, -1.1887e+00, -7.1479e-02,\n",
      "          -1.3400e+01,  5.6966e+00, -1.0570e+01,  4.4808e+00,  2.8481e+00,\n",
      "           2.5098e+01, -2.7170e+00,  2.0200e+00,  6.5420e-01,  3.5122e+00,\n",
      "           9.8307e-02,  3.4839e+00,  4.3519e+00, -9.6617e-01, -7.4402e+00,\n",
      "          -1.0572e+01,  7.2742e+00,  6.2237e-01,  1.4524e+00, -5.3415e-01,\n",
      "           7.7275e+00,  9.1217e-01, -1.3011e+00,  2.8113e+00, -2.1518e+00,\n",
      "           6.7734e-01,  1.1479e+00, -1.0001e+00, -1.6083e+00,  5.0868e-02,\n",
      "           1.2776e+01,  5.3453e-01,  8.1920e-01,  1.9828e+00, -1.1483e+00,\n",
      "           5.5303e+00,  2.5908e+00,  2.1558e-01, -3.8337e+00,  1.2176e+00,\n",
      "          -3.6531e+00,  5.0589e+01,  6.6431e+00, -2.4412e-01, -5.8154e+00,\n",
      "           2.5962e+00, -5.2236e+00,  1.3580e+01,  7.7768e-01, -6.7056e-01,\n",
      "           3.3493e+00, -1.5097e+00, -1.6644e+00,  2.7290e+01, -2.2441e+00,\n",
      "          -5.8781e-01,  7.3594e+00, -1.4886e+00,  3.1747e+00, -1.1360e+00,\n",
      "           1.5511e+00,  1.1347e+00,  4.5626e+00, -2.7048e+00,  3.0759e+00,\n",
      "          -1.9209e-01, -5.6576e-02,  1.7047e+00, -3.9745e-01, -2.9383e+00,\n",
      "          -7.6144e-01,  1.8289e+00, -1.6213e+00,  3.1530e+00, -6.1776e+00,\n",
      "          -3.7080e-01,  8.3174e+00, -1.8408e+00,  2.4891e+00,  1.4974e+01,\n",
      "           1.2336e+00, -7.1713e-01,  2.1506e+00, -3.9947e+00, -1.4899e+00,\n",
      "           1.3502e+00, -3.3831e+00,  3.1907e+00,  1.0715e+00,  2.2544e+01,\n",
      "          -1.1078e+00, -2.0686e+01,  1.1541e-01,  9.8367e+00, -3.9334e+00,\n",
      "          -3.0503e+00, -1.5372e+00, -1.6168e+01, -6.4499e-01, -3.1410e-01,\n",
      "          -2.8852e+00,  6.0536e-01, -1.0289e+00, -2.1544e+00, -3.5690e-01,\n",
      "          -1.8069e-01,  9.7036e-05, -1.5374e+00, -1.0092e+00,  4.5872e+00,\n",
      "           2.3077e+01,  4.5953e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 8.2739e+00,  1.4340e+00,  5.4243e+01, -1.7168e+00,  6.3909e-01,\n",
      "          -1.6336e+00,  1.7308e+01, -1.1022e+00, -5.1669e+00, -9.7198e-01,\n",
      "          -2.6602e+00,  5.4893e+00, -4.8092e-01, -2.0729e+00, -4.1660e-01,\n",
      "           4.9830e+00, -4.2818e-01,  3.2154e+00, -2.9782e+00, -1.9317e+00,\n",
      "          -2.7980e+00, -1.4173e+01,  1.4677e+00,  3.8613e+01, -3.2131e+01,\n",
      "          -6.6042e+00,  1.3579e+00, -1.0469e+01, -2.1027e+01, -7.0584e+00,\n",
      "          -8.5546e+00, -3.4539e+00,  8.2066e+00, -3.5020e+00, -3.6200e+01,\n",
      "           1.2290e+01,  3.0850e+00,  8.6980e-01, -2.0719e+01, -1.3244e+00,\n",
      "           2.0109e+00,  1.3111e+00, -3.6193e+01, -2.5100e+00,  2.0194e+00,\n",
      "           9.6436e-01,  1.2370e+00, -1.1781e+01,  1.4478e+00,  8.9314e+00,\n",
      "           2.1471e+00, -2.2713e+00,  1.7992e+01,  4.9320e-01,  1.5726e+00,\n",
      "          -2.3390e+01, -2.9313e+00,  1.8597e+00, -7.8498e-01, -1.8677e-01,\n",
      "           3.9471e-01, -2.2343e+00,  2.6818e+00,  2.4594e+00,  2.1263e+00,\n",
      "           8.6310e-01,  1.0594e+00, -5.6448e-01,  1.3062e+01, -4.3720e-01,\n",
      "          -7.2374e-01, -1.5985e+00, -1.4874e-01, -4.3438e-01, -3.3720e-01,\n",
      "          -1.0840e+00, -3.8540e+00,  4.4705e+01, -4.3877e+00,  6.8141e-01,\n",
      "           4.7591e+01, -1.0870e+00, -1.0403e+01,  4.1549e-01,  2.9249e+01,\n",
      "           2.9799e+00,  1.9938e-01,  1.7986e+01,  2.1296e+00, -7.7979e+00,\n",
      "          -1.1862e+00, -7.8458e+00, -4.0328e-02,  1.9320e+00,  1.9524e+00,\n",
      "          -2.8050e+01, -2.1599e+00,  3.6854e+00,  1.4609e+00,  2.8810e+01,\n",
      "          -1.5449e+01,  3.8879e+00,  1.9117e+01,  3.8990e+00, -3.1437e+00,\n",
      "          -1.7538e+00, -2.0563e+00,  1.1765e+00,  2.5420e+00,  8.8568e+00,\n",
      "          -1.9982e+01, -5.4972e+01,  2.7047e+00,  1.3890e+00,  3.0006e+00,\n",
      "          -4.1824e+00, -1.7535e+00, -6.9454e+00, -8.9514e-01,  6.2726e-01,\n",
      "           3.4249e+00,  2.3008e+00, -2.7066e+00,  2.7723e+01,  7.0520e+00,\n",
      "          -3.2340e-01,  5.7096e+00,  3.9871e+00,  5.7574e-01, -9.6983e+00,\n",
      "           1.9183e+00, -4.7921e+01,  6.5370e-01, -1.0855e+00,  4.8737e-01,\n",
      "          -1.2011e+01, -2.4185e+00,  4.5436e+01,  2.9439e-01, -2.8523e+00,\n",
      "           1.4375e+00, -1.8810e+01,  1.7291e+01,  6.5951e+00, -1.4686e+01,\n",
      "           4.5074e+00,  3.2510e+00, -1.0642e+00, -1.8555e+00, -6.3886e+00,\n",
      "           3.3303e+00, -5.8025e-01,  1.3481e+00, -4.7421e+00, -2.3605e+01,\n",
      "          -1.9723e+00, -2.5609e+00,  2.8677e+00, -1.3869e+00, -9.3259e+00,\n",
      "           1.6667e+01,  1.8540e+01, -6.1886e-01, -2.6899e+00,  1.0892e+00,\n",
      "           2.8702e+01,  2.1312e+00,  3.3688e+00, -6.3370e+00, -4.5702e+01,\n",
      "          -3.0399e-01, -5.3603e-01, -2.2975e+00,  1.3512e+00, -1.2707e+00,\n",
      "          -3.6508e+01,  2.5082e+01, -5.7835e-01,  1.6283e-01, -7.2010e+00,\n",
      "           1.4060e+00, -2.3177e+00, -2.0590e+01, -3.5519e+00, -3.8551e+01,\n",
      "           2.3330e+00, -3.3267e+00,  2.7598e+00, -2.6533e+00, -7.9214e+00,\n",
      "           5.5425e-02,  7.1727e-01, -4.7336e+00, -3.9914e-01, -2.3005e-01,\n",
      "           1.4305e+00,  5.2034e-01,  1.0346e+01, -3.3932e+00, -1.3785e+00,\n",
      "           7.1929e-01, -1.7652e+00, -1.9311e+00,  3.2781e+00, -7.5222e-01,\n",
      "          -1.1030e+00, -2.4662e+00, -5.9401e+01, -3.2088e-01,  5.3907e+00,\n",
      "           1.1997e+01,  2.2296e+00,  4.0866e+00, -1.0510e+01, -2.7721e+00,\n",
      "          -3.6171e+00, -3.6495e+00,  3.0312e-01,  1.5062e+00, -2.0786e+01,\n",
      "          -1.5873e+00, -1.7479e+01,  5.9433e+00, -4.0990e-01,  9.0237e-01,\n",
      "          -1.2408e+01,  8.4725e-01, -2.3054e+00,  3.8626e+01,  7.2860e+00,\n",
      "          -1.8153e+00,  3.5533e+01, -1.3019e+00,  3.8618e+00, -1.1417e+01,\n",
      "           2.4074e+00,  4.4612e+00,  6.4713e-01, -2.0650e-01,  1.4665e+01,\n",
      "           2.5433e+00, -1.5375e+00,  6.0679e-01, -2.2256e+01, -6.0400e-02,\n",
      "           9.5727e-01,  8.9650e+00, -1.6546e+00,  4.6923e-01, -1.9376e+00,\n",
      "          -5.0554e-01, -3.5741e-01,  2.2821e+00,  1.0452e+00, -2.6886e+00,\n",
      "          -1.2739e+01, -3.7224e+00, -3.0668e-01,  9.4582e+00,  4.3507e+00,\n",
      "           1.6242e+00, -3.7306e+00,  1.6538e+00,  2.4335e+00,  1.6202e-01,\n",
      "           5.1009e-01,  1.5380e+00,  5.0315e+00, -3.5458e+00, -3.0998e+01,\n",
      "           4.6258e-01, -9.8729e-01, -1.9797e+01,  4.3096e+00, -3.2197e+00,\n",
      "           1.0798e+01, -3.1562e+00,  5.9323e+00, -3.1002e+00, -9.2742e-01,\n",
      "           1.3199e+00, -1.9962e+00,  1.1123e+01, -1.9796e+00,  2.2852e+00,\n",
      "          -1.0162e+00, -4.6247e+00, -1.8438e-01, -5.1518e-01, -2.2602e+00,\n",
      "           7.9330e+00,  9.1187e-01,  2.0133e-01,  1.5626e+00,  2.5031e+00,\n",
      "          -2.3674e+00, -1.8326e+00,  1.5191e+00, -7.3636e-01, -3.7538e-01,\n",
      "          -1.1133e+00,  6.2274e-01,  1.8109e-02, -5.8106e-01, -1.0352e+00,\n",
      "           2.6079e+00, -2.5373e+00,  2.2188e+00,  6.1230e-01, -7.3736e+00,\n",
      "           3.9522e+00, -2.2125e+00,  4.8560e+00,  4.2978e+00, -2.0943e-01,\n",
      "          -1.8716e+01,  2.6524e+00, -1.2791e+01,  1.6871e-01,  1.6275e+00,\n",
      "          -2.0333e+00,  5.7267e+00, -8.7825e-01,  1.0301e+00, -2.2883e+00,\n",
      "          -2.9899e+00,  2.7251e+00, -4.7030e+01,  2.9296e+00, -5.3886e-02,\n",
      "           1.0015e+00,  1.7672e+00, -2.6390e+00, -3.1320e+00, -4.7173e+00,\n",
      "           8.1332e-02,  1.1196e+00,  1.0812e+01, -1.7855e+00,  1.4503e+00,\n",
      "           1.6877e+01,  1.4350e+01,  1.0402e+00, -1.6286e+00, -1.8663e+00,\n",
      "           5.6114e-01, -1.3810e+01, -9.1833e+00, -3.7296e+00,  6.1696e-01,\n",
      "           7.6502e+00, -3.9768e+00,  5.5541e+00, -1.5709e+01,  5.6051e+00,\n",
      "          -7.5517e+00,  4.2243e+00, -8.6553e-01,  1.9039e+00,  2.3984e+01,\n",
      "          -7.9162e-01,  1.6194e+01, -2.3770e-01,  6.1646e+00,  1.0057e+00,\n",
      "          -5.6215e+00, -1.3581e+00, -1.4518e+00,  3.7820e+00,  4.8361e+00,\n",
      "          -1.7513e+00,  6.4756e+00, -2.0040e+00, -9.5086e+00, -9.5845e-01,\n",
      "          -1.1006e+00, -4.4516e+00,  2.2671e+00,  3.0428e+00,  3.2225e-01,\n",
      "           8.8212e+00,  5.4905e-01, -9.1867e-02,  3.5931e-01, -2.0730e-01,\n",
      "          -2.6110e+00, -3.1036e+00, -1.1683e+00, -4.3973e+00, -1.8315e-01,\n",
      "           2.4890e+00, -1.1203e+00,  1.6302e+00,  2.6446e+00, -4.9403e+00,\n",
      "           1.8599e+00,  2.0742e-01, -8.1457e+00, -1.1080e+00, -6.7728e-01,\n",
      "          -1.9691e+01,  8.3297e+00, -1.6423e+01,  5.0124e+00,  6.0623e+00,\n",
      "           4.0084e+01, -5.3296e+00,  2.3441e-01,  1.1132e+00,  3.4666e+00,\n",
      "           5.5756e-01,  2.7855e+00,  3.2905e+00, -1.6663e+00, -1.1142e+01,\n",
      "          -1.5734e+01,  9.0488e+00,  4.8436e-01,  1.4828e+00, -2.4243e+00,\n",
      "           8.3475e+00,  2.7835e+00,  1.4580e+00,  3.5040e+00, -2.7386e+00,\n",
      "           2.1753e-01,  2.7079e+00, -1.5204e+00, -1.6248e+00,  1.6398e+00,\n",
      "           1.8596e+01, -9.3577e-01,  2.6598e+00,  9.1540e-01, -1.2653e-02,\n",
      "           8.4889e+00,  3.8793e+00, -1.9944e-01, -7.2541e+00, -4.5264e-01,\n",
      "          -3.7911e+00,  7.9770e+01,  5.4773e+00, -1.6822e+00, -1.0465e+01,\n",
      "           7.0326e+00, -6.5886e+00,  1.9336e+01, -4.0275e-01, -5.3348e-01,\n",
      "           4.5121e+00, -1.9578e+00, -2.0499e+00,  4.3957e+01, -5.9647e-01,\n",
      "          -5.7320e-01,  1.1034e+01, -5.0269e+00,  1.6190e+00, -1.5329e+00,\n",
      "           2.4243e+00,  3.1773e+00,  5.7637e+00, -4.1694e+00,  4.0867e+00,\n",
      "           1.9361e+00,  2.3858e+00, -1.9745e+00, -1.0827e+00, -3.3865e+00,\n",
      "           9.4858e-01,  2.0167e+00, -4.9543e+00,  2.8267e+00, -1.2656e+01,\n",
      "          -1.0677e+00,  1.2218e+01, -3.0477e+00,  1.3388e+00,  2.3436e+01,\n",
      "          -1.5023e-01, -2.5508e+00,  3.3025e+00, -3.6703e+00, -1.6149e+00,\n",
      "           3.2344e+00, -7.4960e+00,  3.0547e+00,  1.6980e-01,  3.1963e+01,\n",
      "          -2.3837e+00, -3.0802e+01,  1.7620e+00,  1.6968e+01, -1.0054e+01,\n",
      "          -2.0185e+00, -2.4807e+00, -2.2541e+01,  6.1159e-01,  5.5997e-01,\n",
      "          -2.8088e+00,  1.1823e+00, -1.4881e-01, -2.0930e-01, -8.1090e-01,\n",
      "          -1.9704e-01,  4.6265e-02, -1.0170e+00, -1.8048e+00,  4.5064e+00,\n",
      "           3.8109e+01,  4.1723e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.0166e+01,  2.2605e-01,  7.0581e+01, -2.1083e+00,  1.1799e+00,\n",
      "          -1.1100e+00,  2.4082e+01, -1.8795e+00, -4.3317e+00,  9.8694e-01,\n",
      "          -3.5964e+00,  5.9503e+00,  1.1298e+00, -2.9395e+00, -9.4965e-01,\n",
      "           3.4848e+00, -9.3098e-01,  3.9472e+00, -3.2246e+00, -2.1051e+00,\n",
      "          -3.6341e+00, -1.5770e+01,  6.6995e-01,  5.0566e+01, -4.2690e+01,\n",
      "          -1.0526e+01,  2.4507e+00, -1.4854e+01, -2.6902e+01, -5.0469e+00,\n",
      "          -1.3124e+01, -4.9442e+00,  1.1380e+01, -5.8109e+00, -4.9158e+01,\n",
      "           1.7160e+01,  2.1696e+00, -8.9612e-02, -2.4511e+01, -4.0079e+00,\n",
      "           1.9268e+00, -1.1291e+00, -4.8683e+01, -2.8750e+00,  1.0015e+00,\n",
      "           1.7626e+00,  3.2967e+00, -1.2285e+01,  1.9046e+00,  1.0925e+01,\n",
      "           3.0959e+00, -2.2375e+00,  2.6386e+01,  2.6636e-01,  4.1396e+00,\n",
      "          -3.1472e+01, -1.8535e+00,  2.1739e+00, -1.4493e+00, -9.0094e-01,\n",
      "           1.9603e+00, -2.4775e+00,  3.4992e+00,  3.7633e+00,  1.0155e+00,\n",
      "           2.3311e-01,  1.0836e+00, -2.0888e+00,  1.8074e+01, -2.0142e-01,\n",
      "          -3.1739e+00, -2.0707e+00, -2.9728e-01, -2.0941e-01, -1.3689e+00,\n",
      "          -2.3606e+00, -7.6729e+00,  5.8008e+01, -4.5696e+00,  1.8636e+00,\n",
      "           6.1795e+01, -1.1440e+00, -1.4094e+01, -5.0451e-01,  3.3987e+01,\n",
      "           4.8140e+00, -1.0924e+00,  2.4030e+01,  2.3142e+00, -9.1277e+00,\n",
      "          -3.1145e-01, -1.2410e+01,  8.3113e-01,  1.8571e+00,  2.8435e+00,\n",
      "          -3.8231e+01, -2.6757e+00,  5.2271e+00,  3.1122e+00,  3.7679e+01,\n",
      "          -1.6370e+01,  2.9225e+00,  2.6805e+01,  4.4557e+00, -7.3122e+00,\n",
      "          -4.1543e+00, -4.9099e+00,  2.0224e+00,  6.5126e-01,  1.0899e+01,\n",
      "          -3.0298e+01, -7.2935e+01,  1.0322e+00,  2.9055e+00,  3.3781e+00,\n",
      "          -3.8441e+00, -2.2967e+00, -8.8668e+00,  1.9500e-01,  2.4401e+00,\n",
      "           1.8744e+00,  3.7596e+00, -4.6709e+00,  3.7591e+01,  6.8494e+00,\n",
      "          -1.4658e+00,  5.2535e+00,  5.0860e+00,  1.3751e-01, -1.0682e+01,\n",
      "           3.2754e+00, -6.2760e+01,  7.1837e-01, -7.4450e-01, -1.1837e+00,\n",
      "          -1.9374e+01,  9.2412e-02,  5.9506e+01,  5.2331e-01, -4.7886e+00,\n",
      "           1.6847e+00, -2.5288e+01,  2.0482e+01,  9.5787e+00, -2.2787e+01,\n",
      "           3.2204e+00,  4.1740e+00,  6.3460e-02, -2.9908e+00, -6.0471e+00,\n",
      "           6.9009e+00,  7.6096e-01,  6.2510e-01, -4.4530e+00, -2.8237e+01,\n",
      "          -1.8325e+00, -5.6689e-01,  2.2518e+00, -2.8715e+00, -1.2860e+01,\n",
      "           1.9934e+01,  2.2953e+01, -1.1537e+00, -4.2295e+00,  1.3343e-01,\n",
      "           3.8986e+01,  1.2144e+00,  2.3483e+00, -7.2150e+00, -6.0439e+01,\n",
      "          -1.1599e+00, -1.0028e+00, -3.3702e+00, -6.6976e-02, -4.3077e+00,\n",
      "          -4.9425e+01,  3.1645e+01,  9.2884e-01, -8.8861e-01, -1.0725e+01,\n",
      "           4.0726e+00, -2.9435e-01, -2.7961e+01, -6.3445e+00, -5.1853e+01,\n",
      "           1.7182e+00, -3.8364e+00,  2.2197e+00, -3.4106e+00, -1.1703e+01,\n",
      "           8.2340e-01, -8.8091e-01, -6.6364e+00, -9.4448e-01, -1.5293e+00,\n",
      "          -2.6391e-01,  3.0595e-02,  1.5294e+01, -4.4006e+00, -2.2418e+00,\n",
      "          -5.7843e-01, -2.2844e+00, -3.1312e+00,  4.3380e+00,  1.0116e+00,\n",
      "           4.3888e-01, -2.6804e+00, -7.5590e+01,  1.0230e+00,  6.4683e+00,\n",
      "           1.5768e+01,  1.6013e-01,  5.1729e+00, -1.4655e+01, -4.7053e+00,\n",
      "          -5.2722e+00, -4.0104e+00,  1.7877e+00,  8.6540e-01, -2.7092e+01,\n",
      "          -2.7376e+00, -2.0728e+01,  7.6584e+00,  4.5685e-01,  1.1443e+00,\n",
      "          -1.4205e+01,  5.2922e-01, -4.8478e+00,  5.1794e+01,  9.9874e+00,\n",
      "          -3.4961e+00,  4.7289e+01, -4.2055e+00,  3.9983e+00, -1.6100e+01,\n",
      "           3.4797e+00,  7.8793e+00, -2.4872e-01, -6.4873e-01,  2.0569e+01,\n",
      "           2.3743e+00, -2.6542e+00, -3.1918e-01, -3.1696e+01, -9.8475e-02,\n",
      "           5.4515e-01,  1.0686e+01, -6.3288e-01,  1.2565e+00, -5.6115e-01,\n",
      "           1.2982e+00, -1.5242e+00,  1.3191e+00,  7.9290e-01, -5.9011e+00,\n",
      "          -1.6108e+01, -3.4290e+00, -3.6110e-01,  1.3248e+01,  4.8670e+00,\n",
      "           1.8544e+00, -5.6814e+00,  2.6666e+00,  7.7332e-01, -7.9210e-01,\n",
      "           5.2993e-01,  6.2892e-01,  4.9542e+00, -2.0962e+00, -3.8751e+01,\n",
      "           2.2650e-01, -1.0046e+00, -2.6996e+01,  6.8572e+00, -2.6005e+00,\n",
      "           1.4276e+01, -3.1882e+00,  9.7690e+00, -5.0641e+00, -6.2487e-01,\n",
      "           3.7977e+00, -1.1581e+00,  1.6494e+01, -2.4700e+00,  2.1639e+00,\n",
      "          -7.7550e-02, -4.2975e+00, -2.3087e+00, -1.3499e+00, -2.8018e+00,\n",
      "           9.3956e+00, -1.5314e+00,  1.3338e+00,  3.2421e-01,  2.3720e+00,\n",
      "          -3.4393e+00, -1.2634e+00, -5.0673e-02,  8.2577e-01, -8.4423e-01,\n",
      "          -4.5800e-01,  2.6742e-01, -9.2653e-01, -3.6894e-01, -1.2516e+00,\n",
      "           2.1412e+00, -1.2093e+00,  3.5687e+00,  5.4875e-01, -1.0993e+01,\n",
      "           2.6862e+00, -2.9942e+00,  3.4278e+00,  4.0287e+00,  2.8800e-01,\n",
      "          -2.6804e+01,  1.3084e+00, -1.5031e+01,  1.3649e+00,  1.2211e+00,\n",
      "          -2.4545e+00,  9.0817e+00, -1.1649e+00, -1.0134e+00, -1.2588e+00,\n",
      "          -4.9447e+00,  3.1622e+00, -6.1187e+01,  5.9705e+00, -8.7958e-01,\n",
      "           3.3470e+00,  7.6825e-01, -2.0003e+00, -5.1947e+00, -4.5422e+00,\n",
      "           9.8000e-01,  8.0671e-01,  1.5065e+01, -4.3847e+00,  5.8178e-01,\n",
      "           2.2934e+01,  2.3079e+01,  2.0676e+00, -1.9129e+00, -2.0273e+00,\n",
      "           2.3152e+00, -1.5646e+01, -1.1452e+01, -3.6193e+00,  6.0244e-02,\n",
      "           9.0143e+00, -8.9178e+00,  7.1972e+00, -2.0861e+01,  5.0134e+00,\n",
      "          -9.9351e+00,  5.0409e+00, -1.3792e+00,  2.7572e+00,  3.3224e+01,\n",
      "          -1.0089e+00,  2.1323e+01,  1.5033e+00,  4.4635e+00,  2.6897e+00,\n",
      "          -6.8949e+00, -8.4604e-01, -1.8420e+00,  4.0198e+00,  5.8356e+00,\n",
      "          -8.8069e-01,  1.0606e+01, -3.2957e+00, -1.1414e+01, -1.8508e+00,\n",
      "          -1.0967e+00, -3.4220e+00,  1.4733e+00,  5.8557e+00,  6.4907e-01,\n",
      "           1.2872e+01,  9.1936e-02,  8.0709e-02,  8.0735e-01,  3.1354e-01,\n",
      "          -2.6445e+00, -4.7198e+00, -2.9019e-01, -7.0142e+00, -8.8959e-01,\n",
      "           2.7699e+00, -1.1302e-01,  1.9985e+00,  3.4091e+00, -3.6918e+00,\n",
      "           3.7654e+00,  4.1825e-01, -1.3432e+01, -2.6945e+00, -2.1212e+00,\n",
      "          -2.6690e+01,  1.1785e+01, -1.9217e+01,  5.4515e+00,  1.1090e+01,\n",
      "           5.4268e+01, -5.6212e+00,  1.3041e+00,  7.0635e-01,  4.3793e+00,\n",
      "           1.1763e+00,  2.3527e+00,  3.2904e+00, -2.6711e+00, -1.6626e+01,\n",
      "          -2.0018e+01,  1.6211e+01, -6.2339e-01,  2.1334e+00, -1.1840e+00,\n",
      "           6.3787e+00,  2.5797e+00,  1.3175e+00,  3.4897e+00, -3.0642e+00,\n",
      "           1.5575e+00,  1.9598e+00, -1.2729e+00, -1.4525e+00,  1.4283e+00,\n",
      "           2.5069e+01,  2.2332e-01,  1.7125e+00, -1.0132e+00, -3.3310e+00,\n",
      "           1.1464e+01,  5.9497e+00, -2.3816e-01, -8.7690e+00,  2.2322e+00,\n",
      "          -7.0839e+00,  1.0610e+02,  6.4196e+00, -2.1637e+00, -1.3700e+01,\n",
      "           1.1009e+01, -8.7849e+00,  2.6024e+01, -9.6006e-01, -2.0620e+00,\n",
      "           5.6693e+00, -3.3366e+00, -2.1734e+00,  6.0909e+01, -2.0218e+00,\n",
      "          -8.1096e-01,  1.5555e+01, -8.9573e+00,  2.8125e+00, -2.3309e+00,\n",
      "           2.7903e+00,  3.5633e+00,  6.9627e+00, -2.6780e+00,  3.5852e+00,\n",
      "           7.9304e-01,  3.6927e+00, -2.2582e+00, -1.6267e+00, -1.0835e+00,\n",
      "           5.6585e-01,  2.1872e+00, -6.5842e+00,  1.4030e+00, -1.9020e+01,\n",
      "          -1.0289e+00,  1.4660e+01, -3.4011e+00,  1.9360e+00,  3.3290e+01,\n",
      "           2.7060e-01, -4.7036e+00,  3.8372e+00, -2.3651e+00, -3.0984e+00,\n",
      "           2.3745e+00, -1.2972e+01,  3.5950e+00,  1.2583e+00,  4.4514e+01,\n",
      "          -3.1099e+00, -3.8137e+01,  1.8673e+00,  2.2345e+01, -1.7871e+01,\n",
      "          -2.1767e+00, -3.2502e+00, -2.8921e+01,  1.8233e+00,  2.4154e-01,\n",
      "          -2.7933e+00,  5.9886e-01, -9.2902e-01,  2.5160e-02, -2.9263e+00,\n",
      "           5.5193e-01, -1.7050e-01,  3.1765e-01, -1.6096e+00,  4.7331e+00,\n",
      "           5.1677e+01, -5.7830e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.1628e+01, -2.0176e-01,  8.7344e+01, -2.1557e+00,  1.3373e-01,\n",
      "          -3.8573e+00,  3.4915e+01, -3.1054e+00, -3.3357e+00,  1.5759e+00,\n",
      "          -5.0999e+00,  5.2619e+00,  3.3641e+00, -3.9206e+00, -1.4381e-01,\n",
      "           2.1112e+00,  1.2483e+00,  3.4412e+00, -6.6062e+00, -2.8079e+00,\n",
      "          -4.4510e+00, -1.9044e+01,  1.1663e+00,  6.3931e+01, -5.3948e+01,\n",
      "          -1.6668e+01,  3.6594e+00, -1.8291e+01, -3.5196e+01, -3.4232e+00,\n",
      "          -1.8671e+01, -5.9000e+00,  1.3435e+01, -1.0117e+01, -6.1543e+01,\n",
      "           2.0273e+01,  4.0013e+00,  2.8121e+00, -3.0618e+01, -2.6925e+00,\n",
      "           1.9614e+00, -3.6877e+00, -5.8800e+01, -4.6721e+00, -1.0738e-01,\n",
      "           2.7204e+00,  5.5047e+00, -1.1578e+01,  1.9480e+00,  1.0846e+01,\n",
      "           6.1390e+00, -1.0467e+00,  3.4999e+01, -5.7526e-01,  6.0821e+00,\n",
      "          -3.8629e+01, -5.6311e+00,  3.4682e+00, -1.2735e+00, -6.0099e-01,\n",
      "           2.1843e+00, -3.7931e+00,  4.1998e+00,  6.2632e+00,  1.0441e+00,\n",
      "           1.0277e+00,  9.8961e-01, -1.8048e+00,  2.3059e+01,  5.1033e-01,\n",
      "          -3.2717e+00, -1.3995e+00,  1.5810e+00, -6.5212e-01,  7.2961e-02,\n",
      "          -1.4821e+00, -7.9921e+00,  7.1475e+01, -4.4723e+00,  2.9265e+00,\n",
      "           7.5108e+01, -2.1839e+00, -1.8217e+01, -2.6000e-01,  4.2195e+01,\n",
      "           4.3053e+00, -4.6159e-01,  3.2473e+01,  2.4123e+00, -1.2908e+01,\n",
      "           7.2847e-02, -1.6490e+01,  1.5372e-01,  2.3983e+00, -1.1983e+00,\n",
      "          -4.8138e+01, -2.1427e+00,  9.3979e+00,  3.6202e+00,  4.7512e+01,\n",
      "          -2.0091e+01,  4.5681e+00,  3.6599e+01,  1.7267e+00, -1.1942e+01,\n",
      "          -3.0585e+00, -7.0467e+00,  1.6461e+00, -1.6376e+00,  1.4263e+01,\n",
      "          -4.0494e+01, -8.7726e+01,  2.1696e+00,  1.9366e+00,  4.2976e+00,\n",
      "          -4.3401e+00, -1.5321e+00, -9.1037e+00, -3.4639e-01,  1.1786e+00,\n",
      "           3.8695e-01,  4.4968e+00, -7.7129e+00,  4.7298e+01,  5.0689e+00,\n",
      "          -1.7006e-01,  5.5714e+00,  5.3081e+00, -2.0580e+00, -1.3556e+01,\n",
      "           4.8112e+00, -7.4507e+01,  9.1801e-02, -7.2026e-01, -3.1551e+00,\n",
      "          -2.6992e+01,  2.2636e+00,  7.4518e+01,  2.9528e+00, -5.3029e+00,\n",
      "           1.8976e+00, -3.1090e+01,  2.4327e+01,  1.0760e+01, -3.0934e+01,\n",
      "           5.3021e+00,  3.8408e+00, -2.8832e+00, -5.4523e+00, -9.3375e+00,\n",
      "           1.0947e+01,  8.6354e-02,  5.8576e-01, -7.3190e+00, -3.0927e+01,\n",
      "          -2.8008e-01, -1.1265e+00,  1.9807e+00, -3.9823e+00, -1.8578e+01,\n",
      "           2.7163e+01,  2.8765e+01,  1.1220e+00, -2.6385e+00,  1.6342e+00,\n",
      "           5.0778e+01,  1.2048e+00,  2.9185e+00, -1.0189e+01, -7.8935e+01,\n",
      "          -1.3854e+00,  1.5874e-01, -3.9203e+00, -1.0312e+00, -6.5865e+00,\n",
      "          -6.1184e+01,  3.8454e+01,  3.8145e+00, -5.8642e-01, -1.4914e+01,\n",
      "           3.1859e+00, -2.4871e+00, -3.7429e+01, -9.0664e+00, -6.3194e+01,\n",
      "           3.7776e-01, -4.9737e+00,  2.1948e+00, -3.2518e+00, -1.8247e+01,\n",
      "          -6.0667e-03, -2.3115e-01, -8.5991e+00, -2.0333e+00, -4.3556e+00,\n",
      "           2.2990e-01, -1.0921e+00,  1.7385e+01, -3.2585e+00, -5.7164e+00,\n",
      "          -2.1456e+00, -1.7783e+00, -2.6621e+00,  5.4694e+00,  1.3106e+00,\n",
      "          -9.2826e-01, -1.6981e+00, -9.1752e+01,  5.5140e-01,  7.4345e+00,\n",
      "           2.1172e+01, -1.5284e+00,  6.8329e+00, -1.8104e+01, -3.6809e+00,\n",
      "          -8.0412e+00, -3.8372e+00,  2.7823e+00,  3.9658e-02, -3.6220e+01,\n",
      "          -1.6402e+00, -2.5954e+01,  1.0183e+01,  2.1493e+00,  2.8460e+00,\n",
      "          -1.6203e+01, -1.7211e+00, -6.3206e+00,  6.4972e+01,  1.6539e+01,\n",
      "          -4.4566e+00,  6.1085e+01, -6.0754e+00,  3.5398e+00, -2.0617e+01,\n",
      "           4.7906e+00,  1.1975e+01,  8.9088e-01, -1.3604e+00,  2.7553e+01,\n",
      "           3.9524e+00, -2.3212e+00,  4.2735e-01, -4.2909e+01,  1.3606e+00,\n",
      "          -2.8226e-01,  1.7377e+01,  8.7082e-01, -8.4179e-02, -2.2137e+00,\n",
      "          -5.4204e-02, -1.2300e+00,  1.7713e+00, -2.1906e-01, -8.4733e+00,\n",
      "          -1.9468e+01, -3.1306e+00,  9.2092e-01,  1.4140e+01,  5.8444e+00,\n",
      "           2.1892e-01, -9.9680e+00,  4.3107e+00,  2.7002e+00,  5.9906e-01,\n",
      "          -3.0907e-01,  8.2068e-01,  6.7507e+00, -2.0261e+00, -4.8077e+01,\n",
      "           1.2649e-02,  7.8820e-01, -3.3335e+01,  7.9539e+00, -2.5098e+00,\n",
      "           1.6856e+01, -3.9823e+00,  1.0101e+01, -3.9869e+00, -1.4494e+00,\n",
      "           3.4072e+00, -1.2339e+00,  1.9474e+01, -2.5133e+00,  7.0747e-01,\n",
      "           1.1874e+00, -2.6677e+00, -2.5233e+00, -1.7627e+00, -1.4762e+00,\n",
      "           1.2985e+01, -2.8285e+00,  6.5376e-01,  3.7185e-01,  2.1623e+00,\n",
      "          -2.7524e+00, -1.6245e+00, -8.8136e-01,  3.7214e+00, -1.3157e+00,\n",
      "          -1.7854e+00, -7.4730e-01, -2.2196e+00,  2.8755e-01, -6.1658e-01,\n",
      "           2.9252e+00, -1.8136e+00,  1.9319e+00,  1.0562e+00, -1.4888e+01,\n",
      "           2.7254e+00, -3.6786e+00,  5.0623e+00,  4.1826e+00,  1.6017e+00,\n",
      "          -3.2595e+01,  3.2210e+00, -1.9427e+01,  3.1997e+00,  4.3615e-01,\n",
      "          -1.2588e+00,  1.3958e+01, -1.5703e+00, -1.1485e+00, -1.7135e+00,\n",
      "          -8.3478e+00,  1.2361e-01, -7.6222e+01,  5.0322e+00, -1.3447e+00,\n",
      "           4.0301e+00, -1.6213e-01, -3.5131e+00, -4.0659e+00, -2.8712e+00,\n",
      "           9.8237e-01, -3.1404e-03,  1.9880e+01, -3.4755e+00, -2.0723e+00,\n",
      "           2.8145e+01,  3.1665e+01,  5.6272e-02, -5.7553e-01, -5.7171e-01,\n",
      "           1.6325e+00, -2.2174e+01, -1.6394e+01, -5.0967e+00,  8.6139e-02,\n",
      "           1.2402e+01, -9.7926e+00,  7.1924e+00, -2.9595e+01,  5.4727e+00,\n",
      "          -1.2629e+01,  5.0743e+00, -2.0887e+00,  3.7677e+00,  4.6860e+01,\n",
      "          -1.7192e+00,  2.3961e+01,  3.9367e-01,  6.5199e+00,  2.6360e+00,\n",
      "          -1.0234e+01, -2.3785e+00, -2.0477e+00,  2.2848e+00,  6.4758e+00,\n",
      "          -8.9095e-02,  1.5506e+01, -3.9432e+00, -1.6394e+01, -2.6905e+00,\n",
      "          -1.4138e+00, -2.9587e+00,  1.2055e+00,  7.7889e+00, -4.2024e-01,\n",
      "           1.4559e+01, -2.5047e+00,  9.3682e-01,  1.9444e+00, -1.0781e+00,\n",
      "          -2.0476e+00, -4.4616e+00,  6.5631e-01, -1.0646e+01,  3.4378e-01,\n",
      "           3.8505e+00,  1.7275e+00,  2.3127e+00,  4.3838e+00, -4.6658e+00,\n",
      "           4.6664e+00,  5.1831e-01, -1.4641e+01, -3.4356e+00, -2.5257e+00,\n",
      "          -3.5290e+01,  1.3736e+01, -2.3431e+01,  5.3108e+00,  1.4247e+01,\n",
      "           6.8138e+01, -6.8528e+00,  1.3534e+00,  1.1716e+00,  3.6718e+00,\n",
      "           4.9845e-01,  1.8812e+00,  5.0274e+00, -3.0349e+00, -2.3598e+01,\n",
      "          -2.3074e+01,  2.1190e+01, -4.2298e+00,  1.8758e+00, -3.8100e+00,\n",
      "           8.2611e+00,  3.3011e+00, -3.7980e-01,  4.6199e+00, -3.6126e+00,\n",
      "           1.9509e-01,  3.7116e-01, -1.5542e+00, -5.1386e+00,  3.8634e+00,\n",
      "           3.1957e+01,  9.2956e-01,  5.0468e+00, -2.0243e+00, -4.9147e+00,\n",
      "           1.4543e+01,  1.0598e+01, -6.1025e-01, -9.3422e+00,  1.4653e+00,\n",
      "          -1.0303e+01,  1.3114e+02,  6.2995e+00, -2.4351e+00, -1.8331e+01,\n",
      "           1.1159e+01, -1.0897e+01,  3.4121e+01, -1.4508e+00, -2.6590e+00,\n",
      "           5.0627e+00, -1.5287e+00, -1.8258e+00,  7.6753e+01, -3.0115e+00,\n",
      "          -1.9014e+00,  2.0919e+01, -1.0048e+01,  3.1560e+00, -3.9355e+00,\n",
      "           5.3605e+00,  5.9073e+00,  7.6635e+00, -6.1934e-01,  5.4325e+00,\n",
      "           1.6218e+00,  3.1927e+00,  1.3112e+00, -3.8196e-01, -1.4106e+00,\n",
      "           4.7796e-01,  1.7730e-01, -7.6183e+00,  1.2944e-01, -2.6479e+01,\n",
      "          -1.4636e+00,  1.8399e+01, -5.1675e+00,  1.0043e+00,  4.4948e+01,\n",
      "          -1.4469e+00, -5.6491e+00,  4.3613e+00, -1.4015e+00, -3.3803e+00,\n",
      "           3.3093e+00, -1.8927e+01,  3.3760e+00,  2.9802e+00,  5.3925e+01,\n",
      "          -2.9668e+00, -4.2997e+01,  2.4289e+00,  2.5387e+01, -2.2400e+01,\n",
      "          -1.6582e+00, -4.0520e+00, -3.4226e+01,  1.3285e+00, -9.4073e-01,\n",
      "          -1.6515e+00, -2.0812e-01, -3.7842e+00, -1.0853e+00, -6.3493e+00,\n",
      "           4.5390e-01,  3.3011e-01, -7.1964e-01, -1.5313e+00,  5.3739e+00,\n",
      "           6.4611e+01, -2.1004e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.3829e+01,  1.4052e-01,  1.0234e+02, -3.4925e+00,  2.2527e+00,\n",
      "          -3.7522e+00,  4.4937e+01, -2.2794e+00, -5.3070e+00,  2.6650e+00,\n",
      "          -7.6648e+00,  6.4965e+00,  5.2094e+00, -3.1158e+00,  1.0509e+00,\n",
      "           2.5605e+00,  1.5782e+00,  3.7122e+00, -7.8987e+00, -1.8541e+00,\n",
      "          -3.8760e+00, -2.1166e+01,  2.0479e+00,  7.4846e+01, -6.4311e+01,\n",
      "          -2.1644e+01,  3.0440e+00, -2.1016e+01, -4.2095e+01, -3.8998e+00,\n",
      "          -2.2562e+01, -8.2685e+00,  1.5189e+01, -1.5894e+01, -7.1929e+01,\n",
      "           2.3408e+01,  2.8941e+00,  4.0653e-01, -3.7153e+01, -3.8534e-01,\n",
      "           8.0023e-01, -2.6411e+00, -6.9614e+01, -4.6348e+00, -2.2827e-01,\n",
      "           4.2431e+00,  6.1994e+00, -1.0161e+01,  2.7077e+00,  1.4550e+01,\n",
      "           1.0075e+01, -2.5867e+00,  4.3691e+01,  2.0025e-01,  7.3226e+00,\n",
      "          -4.5778e+01, -7.4804e+00,  2.9413e+00, -3.8987e+00, -2.0695e+00,\n",
      "           1.9399e+00, -3.4945e+00,  6.3207e+00,  8.3308e+00,  3.0615e+00,\n",
      "           6.3383e-01,  2.1440e+00, -3.5122e+00,  2.8600e+01,  2.8915e-01,\n",
      "          -3.4895e+00, -2.4193e+00,  2.8113e+00, -6.6867e-01,  1.3370e+00,\n",
      "          -1.1642e+00, -9.2524e+00,  8.3063e+01, -4.7081e+00,  4.8216e+00,\n",
      "           8.7850e+01, -2.8790e+00, -2.4757e+01, -1.2788e+00,  5.0652e+01,\n",
      "           4.9322e+00, -1.1857e+00,  4.0048e+01,  3.6917e+00, -1.5861e+01,\n",
      "           1.3300e+00, -2.1183e+01,  3.4726e+00,  2.7984e+00, -1.1385e+00,\n",
      "          -5.5467e+01, -1.5700e+00,  1.1991e+01,  4.6707e+00,  5.6867e+01,\n",
      "          -2.0718e+01,  4.4941e+00,  4.6485e+01,  4.0593e+00, -1.5284e+01,\n",
      "          -2.6197e+00, -8.4741e+00,  3.7515e+00, -5.4536e-01,  1.8006e+01,\n",
      "          -5.0563e+01, -1.0488e+02,  4.6391e+00,  1.5441e+00,  2.9231e+00,\n",
      "          -5.7248e+00, -1.3535e+00, -1.0195e+01, -1.2483e+00,  9.7828e-01,\n",
      "          -4.9319e-01,  6.2115e+00, -1.1994e+01,  5.5206e+01,  5.0399e+00,\n",
      "          -5.8576e-01,  4.6264e+00,  7.5054e+00, -1.3419e+00, -1.7631e+01,\n",
      "           4.6894e+00, -8.5874e+01, -1.1844e+00, -2.2015e+00, -2.6428e+00,\n",
      "          -3.2982e+01,  5.9903e+00,  9.1094e+01,  5.0982e+00, -7.0557e+00,\n",
      "           2.4558e+00, -3.8037e+01,  2.8214e+01,  1.1646e+01, -3.7009e+01,\n",
      "           4.5112e+00,  3.8513e+00, -3.1339e+00, -5.1131e+00, -9.2983e+00,\n",
      "           1.4439e+01, -3.2518e-01,  3.1004e+00, -6.8677e+00, -3.5448e+01,\n",
      "          -1.4315e+00,  4.9025e-01,  4.6865e+00, -5.0853e+00, -2.2468e+01,\n",
      "           3.3606e+01,  3.4610e+01,  8.1410e-01, -3.5533e+00,  1.4723e+00,\n",
      "           6.1356e+01,  9.3356e-01,  2.7059e+00, -1.1389e+01, -9.6469e+01,\n",
      "           1.5445e+00,  2.8854e+00, -5.1891e+00,  1.1032e-01, -1.0941e+01,\n",
      "          -7.0455e+01,  4.3656e+01,  4.3114e+00, -6.7073e-01, -1.7578e+01,\n",
      "           1.5978e+00, -4.1471e-01, -4.4781e+01, -1.1512e+01, -7.8260e+01,\n",
      "          -1.7203e+00, -4.9169e+00,  2.7166e+00, -2.6765e+00, -2.2334e+01,\n",
      "          -2.4826e-01, -1.5421e-01, -9.3965e+00, -9.3104e-01, -5.8524e+00,\n",
      "          -1.1176e+00, -1.9429e+00,  2.0392e+01, -2.3357e+00, -6.5508e+00,\n",
      "          -1.7642e+00, -9.7548e-01, -3.2870e+00,  6.7538e+00,  2.1563e+00,\n",
      "          -2.7138e+00, -1.5894e+00, -1.0741e+02, -6.0661e-01,  9.6174e+00,\n",
      "           2.7022e+01, -1.8492e+00,  1.1089e+01, -1.9582e+01, -5.1817e+00,\n",
      "          -8.1041e+00, -6.4006e+00,  1.5659e+00, -3.6777e-02, -4.5606e+01,\n",
      "          -4.4811e+00, -3.0718e+01,  1.3488e+01,  1.2045e+00,  4.3620e+00,\n",
      "          -1.8937e+01, -1.3715e+00, -7.9294e+00,  7.7943e+01,  1.9986e+01,\n",
      "          -3.2772e+00,  7.1736e+01, -7.2434e+00,  6.0139e+00, -2.5861e+01,\n",
      "           6.6683e+00,  1.1612e+01,  1.4892e+00, -2.6080e+00,  3.4128e+01,\n",
      "           2.4073e+00, -1.7254e+00,  9.9987e-01, -5.5214e+01,  2.9942e+00,\n",
      "          -1.6542e+00,  1.8330e+01,  2.6009e+00,  4.7740e-03, -2.8579e+00,\n",
      "           4.5097e-01, -2.2698e+00,  1.9773e+00, -7.1159e-01, -8.7241e+00,\n",
      "          -2.4636e+01, -2.8281e+00,  1.7853e+00,  1.4412e+01,  4.6990e+00,\n",
      "          -1.7297e+00, -1.2587e+01,  7.2792e+00,  3.8873e+00,  4.0965e-01,\n",
      "          -1.1640e+00, -2.3965e-02,  9.2597e+00, -1.3112e+00, -5.8495e+01,\n",
      "          -4.0553e-01,  3.4140e-01, -3.6081e+01,  9.6998e+00, -2.2422e+00,\n",
      "           2.3879e+01, -3.4257e+00,  1.0035e+01, -4.4979e+00, -3.7292e+00,\n",
      "           1.7029e+00, -5.2349e-02,  2.4734e+01, -3.9849e+00, -1.7913e-01,\n",
      "           1.1279e+00, -1.8772e+00, -6.4584e+00, -2.3764e+00,  1.0938e+00,\n",
      "           1.4308e+01, -3.7726e+00,  1.2098e+00,  2.7534e-01,  1.5118e+00,\n",
      "          -2.7864e+00, -1.8882e+00, -8.7378e-01,  5.7999e+00, -2.1401e-01,\n",
      "          -1.2037e+00, -1.5949e+00, -6.7714e-01, -1.5309e+00, -8.3680e-01,\n",
      "           3.4975e-01,  1.2380e-01,  5.6665e-01, -9.2447e-01, -1.9149e+01,\n",
      "           2.3129e+00, -4.5004e+00,  4.6931e+00,  5.9537e+00,  2.5359e+00,\n",
      "          -3.7176e+01,  1.0120e+00, -2.5426e+01,  3.7139e+00, -1.1334e-01,\n",
      "          -1.2507e+00,  1.6962e+01, -1.4277e+00, -1.8284e+00, -2.7810e+00,\n",
      "          -1.2414e+01, -3.3012e+00, -9.1978e+01,  4.5224e+00, -3.4256e+00,\n",
      "           6.7398e+00,  2.5258e-01,  1.4340e-01, -3.8066e+00, -1.7811e+00,\n",
      "           1.1298e+00,  8.7276e-01,  2.3233e+01, -1.6816e+00, -3.1678e+00,\n",
      "           3.2788e+01,  4.0029e+01, -1.1735e+00, -1.3702e+00,  5.0776e-01,\n",
      "           2.2354e+00, -2.6726e+01, -1.9470e+01, -7.6651e+00,  1.0422e-01,\n",
      "           1.5922e+01, -1.1289e+01,  9.2741e+00, -3.7297e+01,  6.4882e+00,\n",
      "          -1.4836e+01,  2.4930e+00, -2.4754e+00,  2.4492e+00,  5.8811e+01,\n",
      "          -1.0331e+00,  2.8308e+01, -1.1944e+00,  7.5156e+00,  3.5152e+00,\n",
      "          -1.2066e+01, -3.0163e+00, -1.5406e+00,  2.1259e+00,  5.6558e+00,\n",
      "           9.4580e-01,  1.7623e+01, -6.0647e+00, -2.0667e+01, -3.2100e+00,\n",
      "          -2.8341e+00, -2.3611e+00,  1.9673e+00,  9.7347e+00,  1.1730e+00,\n",
      "           2.0016e+01, -4.3793e+00,  5.3824e-01,  2.5877e+00, -3.1173e+00,\n",
      "          -1.0757e+00, -4.0409e+00, -1.6252e+00, -1.7001e+01,  1.8437e-01,\n",
      "           4.3270e+00,  2.9055e+00,  3.2761e+00,  4.3264e+00, -6.2237e+00,\n",
      "           5.9306e+00,  3.9297e-01, -1.6963e+01, -5.8134e+00, -3.7625e+00,\n",
      "          -4.3006e+01,  1.3364e+01, -2.6674e+01,  6.6324e+00,  1.9656e+01,\n",
      "           8.2137e+01, -9.1444e+00,  3.9928e+00, -2.3585e+00,  3.9197e+00,\n",
      "           1.6133e+00,  3.4423e+00,  2.9245e+00, -4.4128e+00, -3.1289e+01,\n",
      "          -2.5642e+01,  2.8548e+01, -5.4316e+00,  2.4606e+00, -6.6974e+00,\n",
      "           1.0758e+01,  3.4886e+00, -2.1488e+00,  4.3175e+00, -5.5178e+00,\n",
      "           3.2742e-01,  2.7619e+00, -2.0152e+00, -4.0970e+00,  3.6389e+00,\n",
      "           3.7277e+01,  5.9187e-01,  1.0139e+01, -1.6442e+00, -5.5617e+00,\n",
      "           1.8047e+01,  1.4699e+01,  8.2468e-02, -7.6424e+00,  1.4735e+00,\n",
      "          -1.4298e+01,  1.5789e+02,  5.0527e+00, -8.7307e-01, -2.1751e+01,\n",
      "           1.2665e+01, -1.5026e+01,  4.1357e+01, -1.8195e+00, -3.6726e+00,\n",
      "           3.5700e+00, -7.5568e-01, -3.7994e+00,  9.1786e+01, -2.8216e+00,\n",
      "          -8.9916e-01,  2.4961e+01, -1.1334e+01,  1.4282e+00, -3.3691e+00,\n",
      "           9.2845e+00,  6.4816e+00,  8.2656e+00, -1.5160e-01,  3.6485e+00,\n",
      "           1.2358e+00,  1.9608e+00, -2.7682e-01,  1.3471e+00, -2.7018e+00,\n",
      "           1.7955e-01, -5.2926e-01, -1.1068e+01, -2.2313e+00, -3.5309e+01,\n",
      "          -3.2757e-01,  2.2097e+01, -4.9165e+00,  1.0284e+00,  5.6146e+01,\n",
      "          -3.9060e+00, -5.2808e+00,  5.6284e+00, -2.8240e+00, -7.2981e+00,\n",
      "           4.3839e+00, -2.2753e+01,  5.2003e+00,  3.6293e+00,  6.2362e+01,\n",
      "          -2.2097e+00, -4.8125e+01,  2.8501e+00,  3.1021e+01, -2.7330e+01,\n",
      "          -1.9694e+00, -5.0942e+00, -4.0526e+01, -2.3357e-02, -1.0909e+00,\n",
      "          -2.6562e+00, -2.4771e+00, -4.7353e+00, -3.5757e-01, -7.6606e+00,\n",
      "           1.0633e+00,  3.1346e-01, -3.3652e-01, -1.7054e+00,  5.1333e+00,\n",
      "           7.6003e+01,  7.2494e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.5490e+01, -1.6150e+00,  1.1852e+02, -4.0030e+00,  2.3569e+00,\n",
      "          -5.1553e+00,  5.3847e+01, -2.7091e+00, -2.2375e+00,  3.2705e+00,\n",
      "          -9.5145e+00,  7.5366e+00,  9.6729e+00, -4.9072e+00,  7.1286e-01,\n",
      "           3.1231e+00,  3.3216e+00,  3.6496e+00, -6.3186e+00, -1.7110e+00,\n",
      "          -3.5154e+00, -2.1016e+01,  4.4294e+00,  8.5602e+01, -7.7465e+01,\n",
      "          -2.4881e+01,  4.4120e+00, -2.6310e+01, -5.0078e+01, -2.5626e+00,\n",
      "          -2.6424e+01, -8.7843e+00,  1.9102e+01, -1.9108e+01, -8.2195e+01,\n",
      "           2.5336e+01,  7.7659e-01,  1.9266e-01, -4.3584e+01, -9.4923e-01,\n",
      "           2.3955e+00, -2.2541e+00, -8.0450e+01, -6.5788e+00, -1.4014e+00,\n",
      "           5.3951e+00,  7.3221e+00, -9.6501e+00,  1.4121e+00,  1.8713e+01,\n",
      "           1.2285e+01, -3.4644e+00,  4.9674e+01, -1.4927e+00,  1.0583e+01,\n",
      "          -5.1199e+01, -8.5096e+00,  7.5884e-01, -4.0292e+00, -1.9337e+00,\n",
      "           2.4611e+00, -9.8761e-01,  7.1741e+00,  1.1568e+01,  5.5367e+00,\n",
      "           1.5012e+00,  2.3680e+00, -2.1710e+00,  3.4666e+01,  2.2631e+00,\n",
      "          -5.5772e+00, -1.5635e+00,  4.3303e+00, -1.0193e+00,  3.6159e+00,\n",
      "          -1.5326e+00, -9.3121e+00,  9.5027e+01, -2.8201e+00,  5.8978e+00,\n",
      "           1.0179e+02, -2.5788e+00, -2.9470e+01, -9.6204e-01,  5.9179e+01,\n",
      "           6.3086e+00, -2.3140e+00,  4.7608e+01,  4.9703e+00, -1.9988e+01,\n",
      "           1.2647e+00, -2.4946e+01,  5.0883e+00,  1.6040e+00,  2.8884e-02,\n",
      "          -6.3706e+01, -1.1834e+00,  1.6488e+01,  4.0712e+00,  6.5531e+01,\n",
      "          -2.5700e+01,  4.5648e+00,  5.2719e+01,  4.4818e+00, -1.8854e+01,\n",
      "          -4.5560e+00, -9.3027e+00,  2.8458e+00,  9.0860e-01,  1.9766e+01,\n",
      "          -6.0989e+01, -1.2019e+02,  6.2053e+00,  4.2055e-01,  1.8581e+00,\n",
      "          -4.4913e+00, -1.0593e+00, -1.0598e+01, -1.0286e+00, -4.5323e-01,\n",
      "          -4.5624e-01,  8.1567e+00, -1.5561e+01,  6.6383e+01,  3.2409e+00,\n",
      "          -1.2245e+00,  3.6699e+00,  8.4190e+00, -1.5367e+00, -2.1731e+01,\n",
      "           6.2496e+00, -9.6549e+01, -2.5169e+00, -2.8270e+00, -2.7713e+00,\n",
      "          -3.7521e+01,  1.0445e+01,  1.0382e+02,  6.0723e+00, -6.6633e+00,\n",
      "           3.4191e-01, -4.5840e+01,  3.1089e+01,  1.5716e+01, -4.3431e+01,\n",
      "           5.9334e+00,  2.8943e+00, -2.8112e+00, -4.8919e+00, -1.0919e+01,\n",
      "           1.9391e+01, -1.0425e+00,  3.9554e+00, -4.6055e+00, -3.8619e+01,\n",
      "          -1.8134e+00,  1.6804e+00,  2.8311e+00, -4.8736e+00, -2.7548e+01,\n",
      "           3.7070e+01,  4.2443e+01,  1.7442e+00, -3.9637e+00,  2.3159e+00,\n",
      "           7.2766e+01,  1.7374e+00,  2.8744e+00, -1.4094e+01, -1.1558e+02,\n",
      "           1.3656e+00,  2.3648e+00, -6.7360e+00,  8.4245e-01, -1.4207e+01,\n",
      "          -8.1341e+01,  5.0199e+01,  4.7893e+00, -2.2261e+00, -2.1078e+01,\n",
      "           6.0359e-01, -1.2800e+00, -5.2392e+01, -1.5950e+01, -9.0362e+01,\n",
      "          -4.7176e+00, -2.9203e+00,  3.4387e+00, -3.7659e+00, -2.5743e+01,\n",
      "          -6.2383e-01, -5.3009e-01, -7.7642e+00, -9.2120e-01, -7.2869e+00,\n",
      "          -1.4330e+00, -2.1518e+00,  2.6299e+01, -8.3394e-01, -9.2263e+00,\n",
      "          -2.3124e+00,  7.6443e-02, -4.3486e+00,  6.1459e+00,  9.5714e-01,\n",
      "          -3.9302e+00, -1.8894e+00, -1.2213e+02, -1.4946e+00,  1.0240e+01,\n",
      "           3.2691e+01, -1.7933e+00,  1.3990e+01, -2.1314e+01, -7.4408e+00,\n",
      "          -9.6814e+00, -8.6527e+00,  3.1329e+00,  2.4156e-01, -5.3766e+01,\n",
      "          -6.3960e+00, -3.5016e+01,  1.5507e+01,  3.1246e+00,  5.9365e+00,\n",
      "          -1.8109e+01, -1.6521e+00, -7.6203e+00,  9.2424e+01,  2.2087e+01,\n",
      "          -4.7479e+00,  8.2857e+01, -9.4698e+00,  7.8590e+00, -2.9492e+01,\n",
      "           8.5931e+00,  1.5329e+01,  1.7580e+00, -3.2005e+00,  3.9263e+01,\n",
      "           3.5547e+00,  1.6361e-02,  9.3249e-02, -6.3210e+01,  2.0068e+00,\n",
      "          -2.6217e+00,  2.2940e+01,  3.5653e+00,  1.8018e+00, -4.9367e+00,\n",
      "          -1.2510e+00, -4.6220e+00,  1.3432e+00,  7.8086e-02, -1.0678e+01,\n",
      "          -3.2489e+01, -4.0162e+00,  1.5506e+00,  1.6600e+01,  4.9380e+00,\n",
      "          -2.8145e+00, -1.5058e+01,  8.8301e+00,  4.0953e+00,  1.4993e+00,\n",
      "          -1.4453e+00,  6.0286e-01,  9.4963e+00, -1.3833e+00, -6.5967e+01,\n",
      "          -7.5969e-01,  1.0799e+00, -4.1033e+01,  1.1343e+01, -3.1288e+00,\n",
      "           2.9155e+01, -3.8755e+00,  1.0972e+01, -4.4968e+00, -4.9070e+00,\n",
      "           1.5652e+00,  2.1403e-01,  3.0028e+01, -4.7929e+00,  7.4524e-01,\n",
      "           1.4542e+00, -2.1335e+00, -9.2678e+00, -4.8203e-01, -6.2674e-01,\n",
      "           1.6458e+01, -7.1581e+00,  2.0560e+00,  1.2922e+00,  2.7129e+00,\n",
      "          -2.9516e+00, -4.0984e+00, -2.1135e-01,  8.0774e+00,  2.4515e+00,\n",
      "          -3.7917e-01, -2.2429e+00,  6.0087e-02, -5.9811e-01, -3.1613e-01,\n",
      "           3.3152e-01,  1.7190e+00, -4.9996e-01,  1.0435e+00, -2.3156e+01,\n",
      "           5.2841e+00, -4.3209e+00,  5.7244e+00,  5.3335e+00,  1.3689e+00,\n",
      "          -4.4723e+01,  3.4746e+00, -3.0064e+01,  4.4769e+00,  2.7866e-01,\n",
      "          -2.0904e+00,  2.1021e+01, -1.0782e+00, -1.0696e+00, -4.0830e+00,\n",
      "          -1.6203e+01, -5.2160e+00, -1.0530e+02,  4.2777e+00, -2.9112e+00,\n",
      "           7.7944e+00, -6.9630e-01,  1.0755e+00, -3.4435e+00, -1.1403e+00,\n",
      "           5.2650e-01,  2.5036e+00,  2.6909e+01, -2.6182e+00, -3.7498e+00,\n",
      "           3.7650e+01,  4.7265e+01, -1.4584e+00,  5.8776e-02,  1.0733e+00,\n",
      "           3.6346e-01, -3.1030e+01, -2.3104e+01, -1.0129e+01, -7.8089e-01,\n",
      "           2.0133e+01, -1.2282e+01,  1.0450e+01, -4.2442e+01,  6.2395e+00,\n",
      "          -1.8087e+01,  3.3419e+00, -2.6846e+00,  2.6250e+00,  7.0737e+01,\n",
      "          -3.9902e-01,  3.2394e+01,  5.2824e-01,  6.3648e+00,  3.1576e+00,\n",
      "          -1.6158e+01, -2.8560e+00, -1.0589e+00,  1.8682e+00,  6.5508e+00,\n",
      "          -7.8602e-01,  2.1060e+01, -5.5158e+00, -2.8026e+01, -2.6123e+00,\n",
      "          -4.4120e+00, -5.9256e-01,  1.8616e+00,  1.2137e+01,  2.4926e+00,\n",
      "           2.1328e+01, -4.3218e+00,  1.2276e+00,  4.4152e-01, -3.6604e+00,\n",
      "          -1.9345e+00, -4.0238e+00, -2.0672e+00, -2.2198e+01,  2.8668e+00,\n",
      "           3.5625e+00,  6.5837e+00,  7.5079e-01,  6.2908e+00, -6.0769e+00,\n",
      "           6.0651e+00,  3.9810e-01, -1.8692e+01, -6.9643e+00, -5.9361e+00,\n",
      "          -5.1546e+01,  1.5788e+01, -2.9649e+01,  6.4205e+00,  2.4359e+01,\n",
      "           9.4715e+01, -1.0013e+01,  3.1610e+00,  8.7242e-01,  2.4486e+00,\n",
      "           2.2365e+00,  4.5786e+00,  1.7045e+00, -4.5628e+00, -3.7713e+01,\n",
      "          -2.8598e+01,  3.3717e+01, -6.5226e+00,  3.9605e+00, -7.4722e+00,\n",
      "           1.4428e+01,  2.2114e+00, -2.4506e+00,  4.7385e+00, -7.5928e+00,\n",
      "           4.5145e-01,  1.1495e+00, -1.7059e+00, -5.2614e+00,  4.4984e+00,\n",
      "           4.3342e+01,  1.1315e+00,  1.4768e+01, -1.8976e+00, -7.1434e+00,\n",
      "           2.2988e+01,  1.8212e+01, -4.0113e-01, -8.1495e+00,  2.5328e+00,\n",
      "          -1.7460e+01,  1.8260e+02,  6.5494e+00, -2.2076e+00, -2.3174e+01,\n",
      "           1.4986e+01, -1.7620e+01,  4.8407e+01, -3.3250e+00, -5.9817e+00,\n",
      "           2.9941e+00, -1.3565e+00, -4.9776e+00,  1.0782e+02, -2.7929e+00,\n",
      "          -8.0462e-01,  3.0460e+01, -1.3662e+01,  5.9712e-01, -2.3583e+00,\n",
      "           1.1710e+01,  5.0239e+00,  7.1194e+00, -1.2489e-01,  2.5982e+00,\n",
      "           1.2270e+00,  2.4559e+00,  4.4929e-01,  3.5196e+00, -3.1769e+00,\n",
      "          -2.4939e-01, -1.8375e-01, -1.4040e+01, -1.0271e+00, -4.2847e+01,\n",
      "           1.5985e+00,  2.3933e+01, -3.9084e+00,  6.7497e-01,  6.7177e+01,\n",
      "          -4.2915e+00, -4.9730e+00,  6.4794e+00, -1.8958e+00, -9.4368e+00,\n",
      "           4.1296e+00, -2.7439e+01,  6.2885e+00,  3.5840e+00,  7.0140e+01,\n",
      "          -2.8399e+00, -5.3515e+01,  2.2525e+00,  3.8730e+01, -3.2828e+01,\n",
      "          -2.9920e+00, -5.0412e+00, -4.5618e+01,  3.1657e+00, -8.8606e-01,\n",
      "          -1.1562e+00, -2.4954e+00, -3.8240e+00, -6.4464e-01, -8.8818e+00,\n",
      "          -1.8815e-01,  2.1992e+00, -1.0085e+00, -2.4174e+00,  4.6907e+00,\n",
      "           8.8506e+01,  1.0515e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.6839e+01, -8.3015e-01,  1.3545e+02, -3.4158e+00,  3.1422e+00,\n",
      "          -8.3208e+00,  6.3287e+01, -2.7161e+00, -7.9279e-01,  4.5019e+00,\n",
      "          -1.1209e+01,  7.3426e+00,  1.3141e+01, -4.0062e+00,  1.5931e+00,\n",
      "           1.2472e+00,  5.2581e+00,  4.4894e+00, -7.1933e+00, -3.5085e+00,\n",
      "          -2.6910e+00, -2.3245e+01,  8.1685e+00,  9.4901e+01, -8.8657e+01,\n",
      "          -2.9808e+01,  3.7334e+00, -3.2525e+01, -5.7439e+01, -3.2177e+00,\n",
      "          -2.9826e+01, -8.9314e+00,  2.3448e+01, -2.1528e+01, -9.5142e+01,\n",
      "           2.9367e+01, -1.4965e+00,  3.7525e-01, -4.8939e+01, -9.8131e-01,\n",
      "           2.0423e+00, -2.2622e+00, -8.8998e+01, -8.1762e+00, -2.2650e+00,\n",
      "           5.2392e+00,  8.7836e+00, -8.6528e+00,  1.3171e+00,  2.1738e+01,\n",
      "           1.5558e+01, -9.1973e-01,  5.5475e+01, -2.5212e+00,  1.2534e+01,\n",
      "          -5.8845e+01, -1.0403e+01, -2.5846e-01, -3.6050e+00, -4.1798e+00,\n",
      "           1.2664e+00, -1.1412e+00,  7.4126e+00,  1.3649e+01,  6.1249e+00,\n",
      "           1.1873e+00,  2.4518e+00, -3.4388e+00,  3.9513e+01,  3.5872e+00,\n",
      "          -6.2481e+00, -2.4762e+00,  4.8067e+00, -1.8856e+00,  2.8709e+00,\n",
      "          -1.1578e+00, -1.1824e+01,  1.0717e+02, -2.0933e+00,  6.1081e+00,\n",
      "           1.1402e+02, -1.3935e+00, -3.4080e+01, -1.5352e+00,  6.7001e+01,\n",
      "           8.0492e+00, -3.8951e+00,  5.5498e+01,  3.3653e+00, -2.5992e+01,\n",
      "           2.3996e+00, -3.0349e+01,  3.4119e+00,  2.2789e+00,  1.5489e-01,\n",
      "          -7.4728e+01, -8.1766e-01,  2.0476e+01,  3.9922e+00,  7.2742e+01,\n",
      "          -2.7259e+01,  4.7950e+00,  6.1988e+01,  3.0562e+00, -2.3519e+01,\n",
      "          -5.6477e+00, -9.5551e+00,  2.0774e+00,  3.8390e-01,  2.1842e+01,\n",
      "          -7.2142e+01, -1.3545e+02,  7.4857e+00, -1.8458e-01,  3.0017e+00,\n",
      "          -5.0780e+00,  1.6308e+00, -1.0914e+01, -1.3251e+00,  1.1656e+00,\n",
      "          -1.3431e+00,  9.9827e+00, -1.7178e+01,  7.5296e+01,  3.4397e+00,\n",
      "          -9.9434e-01,  7.5018e+00,  8.7502e+00, -1.9380e-01, -2.5639e+01,\n",
      "           7.2576e+00, -1.0894e+02, -1.7436e+00, -4.3718e+00, -4.2348e+00,\n",
      "          -4.2760e+01,  1.3563e+01,  1.2052e+02,  7.2648e+00, -7.0119e+00,\n",
      "           4.0565e-01, -5.4384e+01,  3.6811e+01,  1.7310e+01, -5.1209e+01,\n",
      "           6.6559e+00,  3.8808e+00, -4.8193e+00, -6.5555e+00, -1.0889e+01,\n",
      "           2.3297e+01, -1.0321e-01,  3.2806e+00, -3.1219e+00, -4.1882e+01,\n",
      "          -2.2313e+00,  3.6087e+00,  2.3243e+00, -7.2030e+00, -3.2967e+01,\n",
      "           4.3208e+01,  4.9394e+01,  3.8889e+00, -3.5991e+00,  2.3696e+00,\n",
      "           8.3491e+01,  5.0374e+00,  3.7737e+00, -1.6222e+01, -1.3172e+02,\n",
      "           3.1633e+00,  1.4066e+00, -6.6563e+00, -2.7723e-01, -1.5998e+01,\n",
      "          -9.0484e+01,  5.5279e+01,  5.5326e+00, -3.0009e+00, -2.6828e+01,\n",
      "           9.0174e-01, -2.0792e+00, -6.0884e+01, -1.9619e+01, -1.0194e+02,\n",
      "          -8.9495e+00, -8.1640e-01,  5.1718e+00, -4.0835e+00, -2.9938e+01,\n",
      "           7.0142e-01, -6.2964e-01, -4.4238e+00, -3.0638e+00, -7.9932e+00,\n",
      "           1.6642e+00, -3.2748e+00,  3.2788e+01,  2.6554e-01, -1.2425e+01,\n",
      "          -4.6370e+00, -3.6367e-01, -5.1118e+00,  6.4281e+00, -1.7250e-01,\n",
      "          -6.1015e+00, -3.2464e+00, -1.3795e+02, -1.1083e+00,  1.0583e+01,\n",
      "           3.7763e+01, -2.6628e+00,  1.6342e+01, -2.5274e+01, -9.2877e+00,\n",
      "          -1.1434e+01, -8.9891e+00,  1.3511e+00, -1.9949e-01, -6.1307e+01,\n",
      "          -6.3916e+00, -4.0575e+01,  1.5527e+01,  5.0011e+00,  7.5790e+00,\n",
      "          -1.9854e+01, -1.9314e+00, -8.1580e+00,  1.0524e+02,  2.4193e+01,\n",
      "          -4.3364e+00,  9.4223e+01, -1.2226e+01,  1.0335e+01, -3.2255e+01,\n",
      "           1.0054e+01,  1.7480e+01,  1.8202e+00, -4.2812e+00,  4.3289e+01,\n",
      "           4.2038e+00,  1.4333e-01,  7.0769e-01, -7.4190e+01,  3.5795e+00,\n",
      "          -2.6150e+00,  2.7062e+01,  3.2280e+00,  5.7381e-01, -6.2708e+00,\n",
      "          -3.8956e+00, -6.1958e+00,  1.5629e+00, -6.6024e-01, -1.2343e+01,\n",
      "          -3.8347e+01, -2.8004e+00,  2.7193e+00,  1.8386e+01,  5.2120e+00,\n",
      "          -2.7612e+00, -1.9182e+01,  1.0191e+01,  5.8116e+00,  2.7896e+00,\n",
      "          -1.8638e+00,  1.3442e+00,  8.4046e+00, -2.0693e+00, -7.3256e+01,\n",
      "          -1.8743e+00, -1.2073e+00, -4.7507e+01,  1.3363e+01, -5.0610e+00,\n",
      "           3.3886e+01, -4.0681e+00,  1.4435e+01, -2.9472e+00, -4.9707e+00,\n",
      "           2.1599e+00,  3.7558e-01,  3.6493e+01, -4.7557e+00,  3.9958e+00,\n",
      "           8.8249e-01, -1.6246e+00, -1.1030e+01, -2.7579e+00, -2.9092e-02,\n",
      "           2.0297e+01, -9.2546e+00,  3.5968e+00,  8.0391e-01,  1.4379e+00,\n",
      "          -1.5709e+00, -5.4369e+00, -8.2556e-01,  8.5784e+00,  1.7152e+00,\n",
      "          -3.2563e+00, -2.4263e+00, -9.3781e-01, -2.0803e-01, -9.6791e-01,\n",
      "           2.2957e-01,  3.2504e+00, -1.7766e+00,  2.1076e+00, -2.7981e+01,\n",
      "           4.1808e+00, -6.5152e+00,  5.3275e+00,  4.7783e+00, -1.8224e-01,\n",
      "          -5.0282e+01,  4.8790e+00, -3.4297e+01,  5.7417e+00,  4.5004e-01,\n",
      "          -3.6626e+00,  2.5196e+01, -1.9262e+00, -3.4916e-01, -3.2570e+00,\n",
      "          -1.8615e+01, -5.6477e+00, -1.2135e+02,  4.2106e+00, -4.0907e+00,\n",
      "           8.2132e+00, -1.8034e+00, -2.7655e-01, -5.7825e+00,  1.1121e+00,\n",
      "          -4.7199e-01,  1.5984e+00,  3.0027e+01, -3.2229e+00, -7.2360e+00,\n",
      "           3.9585e+01,  5.5078e+01, -2.2357e+00, -4.7030e-02,  1.0380e+00,\n",
      "          -1.6782e+00, -3.6128e+01, -2.4571e+01, -1.0658e+01, -1.1029e+00,\n",
      "           2.5824e+01, -1.4513e+01,  1.4529e+01, -4.8911e+01,  5.0056e+00,\n",
      "          -2.1715e+01,  2.5900e+00, -4.3497e+00,  6.4734e+00,  8.4233e+01,\n",
      "          -3.4821e-02,  3.8657e+01,  1.2529e-01,  9.2371e+00,  3.5186e+00,\n",
      "          -2.0407e+01, -1.7325e+00, -1.4780e+00,  3.5679e+00,  6.5801e+00,\n",
      "          -1.3518e+00,  2.5697e+01, -4.3886e+00, -3.3588e+01, -3.7954e+00,\n",
      "          -4.0550e+00, -6.9017e-01,  2.8510e+00,  1.3325e+01,  1.4628e+00,\n",
      "           2.4199e+01, -5.1002e+00,  2.1751e+00,  1.8118e+00, -5.5459e+00,\n",
      "          -3.1047e+00, -5.4287e+00, -3.0751e+00, -2.4208e+01,  4.0791e+00,\n",
      "           2.9719e+00,  6.9569e+00, -9.8021e-01,  8.3062e+00, -5.5051e+00,\n",
      "           8.2509e+00,  1.1340e+00, -2.1963e+01, -7.7285e+00, -9.0021e+00,\n",
      "          -5.9192e+01,  1.6738e+01, -3.4800e+01,  8.4318e+00,  3.0424e+01,\n",
      "           1.1104e+02, -1.4689e+01,  3.3473e+00,  2.5761e-01, -1.1602e-01,\n",
      "           2.4120e+00,  4.3832e+00, -8.1219e-01, -4.6697e+00, -4.3570e+01,\n",
      "          -3.2609e+01,  3.9069e+01, -7.5202e+00,  5.3644e+00, -8.0486e+00,\n",
      "           1.4616e+01,  9.9261e-01, -4.7028e+00,  2.9619e+00, -8.7337e+00,\n",
      "          -1.3233e+00,  2.6908e+00, -2.7228e+00, -3.8866e+00,  3.8487e+00,\n",
      "           4.7536e+01,  2.9310e+00,  1.9272e+01, -3.0115e+00, -9.6522e+00,\n",
      "           2.9845e+01,  2.2436e+01,  2.4396e+00, -9.6007e+00,  3.1237e+00,\n",
      "          -2.1322e+01,  2.0754e+02,  7.7067e+00, -2.7947e+00, -2.9004e+01,\n",
      "           1.7432e+01, -2.1310e+01,  5.5886e+01, -6.2128e+00, -5.6730e+00,\n",
      "           4.3649e+00, -2.0636e+00, -4.2461e+00,  1.2167e+02, -2.8438e+00,\n",
      "          -1.5341e+00,  3.6942e+01, -1.4774e+01,  8.1339e-01, -5.5296e-01,\n",
      "           1.4664e+01,  4.1119e+00,  7.2542e+00,  2.6462e+00,  4.4379e+00,\n",
      "           3.2784e-01,  9.0664e-01, -1.7158e+00,  5.1352e+00, -2.2545e+00,\n",
      "           1.9637e+00,  8.1641e-01, -1.7846e+01, -3.0947e+00, -5.1159e+01,\n",
      "           8.1736e-01,  2.8075e+01, -5.5409e+00,  1.6976e-01,  7.8991e+01,\n",
      "          -5.6611e+00, -6.6515e+00,  5.1696e+00, -1.6955e+00, -9.7333e+00,\n",
      "           5.5029e+00, -2.9080e+01,  7.5927e+00,  5.2101e+00,  7.8180e+01,\n",
      "          -4.4557e+00, -5.7534e+01,  1.6786e+00,  4.3331e+01, -3.6506e+01,\n",
      "          -2.0804e+00, -5.5959e+00, -5.1555e+01,  5.5631e+00,  9.0594e-01,\n",
      "          -2.5535e+00, -2.6501e+00, -2.8669e+00, -1.5639e+00, -1.2091e+01,\n",
      "          -9.7332e-01,  2.4999e+00, -1.8458e+00, -1.5122e+00,  5.1844e+00,\n",
      "           1.0072e+02,  1.4972e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 1.9905e+01, -2.0851e-01,  1.4697e+02, -5.2002e+00,  9.5297e-01,\n",
      "          -8.7296e+00,  7.1699e+01, -1.9946e+00,  7.9645e-02,  5.1540e+00,\n",
      "          -1.1827e+01,  7.2012e+00,  1.4520e+01, -3.5305e+00,  3.1154e-02,\n",
      "           7.5110e-01,  5.7382e+00,  4.6453e+00, -8.7896e+00, -4.3676e+00,\n",
      "          -3.7696e+00, -2.6769e+01,  8.7511e+00,  1.0593e+02, -9.9111e+01,\n",
      "          -3.4636e+01,  6.0475e+00, -3.6909e+01, -6.2919e+01, -3.1777e+00,\n",
      "          -3.2505e+01, -1.1681e+01,  2.7837e+01, -2.5518e+01, -1.0575e+02,\n",
      "           3.4788e+01, -3.0035e+00, -1.5479e+00, -5.4390e+01,  1.7775e+00,\n",
      "           4.1396e+00, -3.0670e+00, -9.7820e+01, -6.0346e+00, -3.2688e+00,\n",
      "           4.0330e+00,  9.3397e+00, -8.4651e+00,  1.0512e+00,  2.2683e+01,\n",
      "           1.8073e+01,  9.5340e-01,  6.4371e+01, -3.0012e+00,  1.3508e+01,\n",
      "          -6.4799e+01, -1.1640e+01, -1.9309e+00, -5.3433e+00, -4.5255e+00,\n",
      "           1.5032e+00, -5.4375e-01,  6.7389e+00,  1.5261e+01,  7.3261e+00,\n",
      "           4.2107e-02,  2.2216e+00, -3.3319e+00,  4.5270e+01,  3.4029e+00,\n",
      "          -6.7886e+00, -2.8051e+00,  5.7636e+00, -2.5295e+00,  4.3985e+00,\n",
      "          -3.5967e+00, -1.5925e+01,  1.2064e+02, -8.5652e-01,  6.4889e+00,\n",
      "           1.2590e+02, -2.2532e+00, -3.7496e+01,  6.8720e-01,  7.4793e+01,\n",
      "           8.7305e+00, -4.8792e+00,  6.3223e+01,  3.9227e+00, -3.0403e+01,\n",
      "           8.0281e-01, -3.3718e+01,  3.3614e+00,  1.4935e+00, -3.8139e+00,\n",
      "          -8.4654e+01,  1.9980e+00,  2.5929e+01,  4.6895e+00,  8.1002e+01,\n",
      "          -2.9793e+01,  5.1412e+00,  7.1229e+01,  1.9742e+00, -2.9310e+01,\n",
      "          -6.0642e+00, -1.0655e+01,  2.0151e+00,  3.7897e-01,  2.5828e+01,\n",
      "          -8.1561e+01, -1.5176e+02,  7.8878e+00,  4.4636e-01,  5.0323e+00,\n",
      "          -5.5056e+00,  2.5796e+00, -1.2393e+01, -2.1281e+00,  2.2913e+00,\n",
      "          -1.3884e+00,  1.0065e+01, -2.1443e+01,  8.6400e+01,  1.1788e+00,\n",
      "          -8.4297e-01,  6.0102e+00,  1.1511e+01, -5.2823e-01, -2.7474e+01,\n",
      "           5.7033e+00, -1.2055e+02, -1.7884e+00, -5.2236e+00, -4.3100e+00,\n",
      "          -4.7698e+01,  1.8330e+01,  1.3476e+02,  8.1164e+00, -6.4851e+00,\n",
      "           9.6829e-01, -6.3864e+01,  4.2416e+01,  2.2928e+01, -5.6935e+01,\n",
      "           5.2607e+00,  4.5818e+00, -6.9496e+00, -9.1142e+00, -9.5215e+00,\n",
      "           2.7579e+01,  3.1106e-01,  3.6488e+00, -8.6204e-01, -4.5242e+01,\n",
      "           2.6755e-03,  3.8077e+00,  2.8575e+00, -9.2777e+00, -3.5874e+01,\n",
      "           4.8518e+01,  5.2960e+01,  4.4971e+00, -4.1561e+00,  2.5416e+00,\n",
      "           9.5134e+01,  3.9578e+00,  2.1682e+00, -1.9217e+01, -1.4892e+02,\n",
      "           5.1153e+00,  2.0280e+00, -8.8121e+00,  1.0351e+00, -1.9093e+01,\n",
      "          -9.9373e+01,  6.1948e+01,  7.5254e+00, -2.0389e+00, -2.8071e+01,\n",
      "           8.0501e-02, -5.6822e-01, -6.9679e+01, -2.4761e+01, -1.1647e+02,\n",
      "          -1.2923e+01, -3.0816e-01,  6.3220e+00, -3.8045e+00, -3.3659e+01,\n",
      "          -1.4424e-01, -1.8507e+00, -6.6257e+00, -4.2633e+00, -6.9163e+00,\n",
      "           1.8277e+00, -5.8631e+00,  3.5976e+01,  2.0394e+00, -1.4644e+01,\n",
      "          -3.6929e+00,  1.5890e-01, -4.6036e+00,  7.8278e+00, -6.3717e-01,\n",
      "          -8.1704e+00, -1.5399e+00, -1.5268e+02, -1.9020e+00,  1.4244e+01,\n",
      "           4.3570e+01, -1.3693e+00,  1.9226e+01, -2.9866e+01, -8.8729e+00,\n",
      "          -1.3273e+01, -8.8766e+00,  5.6996e-01,  2.0160e-01, -7.1243e+01,\n",
      "          -6.3104e+00, -4.4796e+01,  1.6653e+01,  6.5858e+00,  9.1024e+00,\n",
      "          -2.1664e+01, -2.1429e+00, -9.7394e+00,  1.1866e+02,  3.0345e+01,\n",
      "          -4.9061e+00,  1.0317e+02, -1.6581e+01,  1.1606e+01, -3.9927e+01,\n",
      "           7.8335e+00,  1.8908e+01,  1.4453e+00, -3.5622e+00,  4.8200e+01,\n",
      "           4.0084e+00,  6.6292e-01,  7.1322e-01, -8.3168e+01,  3.5991e+00,\n",
      "          -1.1795e+00,  2.9868e+01,  2.9750e+00,  5.4430e-01, -9.0092e+00,\n",
      "          -4.7702e+00, -6.8193e+00,  2.2760e+00, -3.2668e-01, -1.4505e+01,\n",
      "          -4.5546e+01, -3.5067e+00,  2.1745e+00,  2.0900e+01,  1.3210e+00,\n",
      "          -2.6275e+00, -2.3291e+01,  1.1045e+01,  8.1665e+00,  3.4997e+00,\n",
      "          -4.5309e+00,  1.7931e+00,  7.7133e+00, -3.2033e+00, -7.9101e+01,\n",
      "           6.6927e-01,  8.0905e-01, -5.2742e+01,  1.5702e+01, -5.3698e+00,\n",
      "           3.9637e+01, -5.0404e+00,  1.5345e+01, -4.2530e+00, -4.6302e+00,\n",
      "           2.5784e-01,  1.2545e+00,  4.1676e+01, -2.7780e+00,  4.0205e+00,\n",
      "           1.4282e+00,  4.3357e-01, -1.2186e+01, -3.2984e+00, -9.2816e-01,\n",
      "           2.1418e+01, -1.2143e+01,  6.1286e+00,  6.5151e-01,  1.0580e+00,\n",
      "          -2.6469e+00, -6.2328e+00, -8.7847e-01,  1.0554e+01,  2.3795e+00,\n",
      "          -3.0755e+00, -8.9298e-01, -1.2775e+00,  2.3111e+00,  2.3892e-02,\n",
      "           3.3387e-01,  1.9626e+00, -3.1759e+00,  1.2027e+00, -3.3182e+01,\n",
      "           5.5500e+00, -6.6253e+00,  3.8696e+00,  6.4799e+00, -4.8772e-01,\n",
      "          -5.7555e+01,  6.0010e+00, -3.8390e+01,  5.4073e+00,  6.1761e-01,\n",
      "          -2.7095e+00,  3.0889e+01, -2.6818e+00, -3.9216e-01, -2.8321e+00,\n",
      "          -2.1395e+01, -9.1122e+00, -1.3418e+02,  4.4037e+00, -6.1771e+00,\n",
      "           7.9233e+00, -2.0646e+00,  8.4701e-01, -5.3539e+00,  2.8058e+00,\n",
      "          -1.5735e+00,  3.4304e+00,  3.1156e+01, -3.3017e+00, -6.3945e+00,\n",
      "           4.4797e+01,  6.3569e+01, -1.8965e+00, -1.1172e+00,  6.7608e-01,\n",
      "          -2.7906e+00, -4.0936e+01, -2.9344e+01, -1.3481e+01, -3.6207e-01,\n",
      "           3.0888e+01, -1.5297e+01,  1.6846e+01, -5.5277e+01,  6.8202e+00,\n",
      "          -2.4817e+01,  2.5513e+00, -6.9642e+00,  7.8702e+00,  9.5273e+01,\n",
      "          -3.3776e-01,  4.5795e+01,  1.0919e+00,  1.0187e+01,  4.3812e+00,\n",
      "          -2.5016e+01, -2.6353e+00, -2.3183e+00,  4.0336e+00,  5.2470e+00,\n",
      "          -1.1507e-01,  3.0558e+01, -3.4181e+00, -3.7383e+01, -3.6542e+00,\n",
      "          -4.9516e+00, -1.7869e+00,  1.6394e+00,  1.6632e+01,  2.7718e+00,\n",
      "           2.7064e+01, -6.5835e+00,  1.5801e+00,  1.8898e+00, -7.5753e+00,\n",
      "          -3.9450e+00, -6.5584e+00, -1.4217e+00, -2.7764e+01,  2.0457e+00,\n",
      "           2.0148e+00,  4.6268e+00, -2.4582e+00,  8.6532e+00, -5.9487e+00,\n",
      "           1.2133e+01, -4.9377e-01, -2.6022e+01, -1.0210e+01, -9.6328e+00,\n",
      "          -6.6484e+01,  1.7551e+01, -3.8771e+01,  9.2643e+00,  3.4338e+01,\n",
      "           1.2261e+02, -1.8608e+01,  4.3156e+00,  4.4279e-01, -1.3604e+00,\n",
      "           1.5939e+00,  2.4746e+00, -3.9471e-01, -4.3602e+00, -5.1770e+01,\n",
      "          -3.5030e+01,  4.3415e+01, -9.5726e+00,  6.9446e+00, -8.4816e+00,\n",
      "           1.6205e+01,  9.7529e-01, -5.8337e+00,  3.2532e+00, -9.9710e+00,\n",
      "          -7.6979e-01,  1.6596e+00, -2.5930e+00, -2.4741e+00,  3.3076e+00,\n",
      "           5.3430e+01,  2.3851e+00,  2.5381e+01, -5.8951e+00, -1.1494e+01,\n",
      "           3.5304e+01,  2.5766e+01,  2.8169e+00, -1.0972e+01,  2.9476e+00,\n",
      "          -2.1400e+01,  2.3269e+02,  8.4396e+00, -4.7260e+00, -3.4517e+01,\n",
      "           1.9870e+01, -2.4047e+01,  6.4050e+01, -6.9142e+00, -6.1260e+00,\n",
      "           6.6591e+00, -2.4696e+00, -4.6234e+00,  1.3559e+02, -4.7092e+00,\n",
      "          -2.6161e+00,  4.1624e+01, -1.6548e+01,  2.0379e+00, -1.7692e+00,\n",
      "           2.0413e+01,  2.4208e+00,  6.1396e+00,  3.9713e+00,  4.9193e+00,\n",
      "           8.7902e-01,  5.9272e-01, -2.2753e-01,  5.3398e+00, -8.8503e-01,\n",
      "           2.2647e+00, -8.9064e-01, -2.1390e+01, -1.3394e+00, -5.7834e+01,\n",
      "          -1.3916e+00,  3.2407e+01, -6.6318e+00, -1.6123e-01,  8.8699e+01,\n",
      "          -7.0571e+00, -5.4159e+00,  5.2838e+00, -3.7958e-01, -1.0697e+01,\n",
      "           6.9461e+00, -3.3874e+01,  8.3343e+00,  6.3100e+00,  8.8778e+01,\n",
      "          -4.1533e+00, -6.2930e+01,  2.8645e+00,  4.9268e+01, -4.3195e+01,\n",
      "          -1.7434e+00, -4.7038e+00, -5.9749e+01,  6.2678e+00, -3.0054e-01,\n",
      "          -3.8371e+00, -3.1048e+00, -3.4126e+00, -1.6157e+00, -1.5479e+01,\n",
      "          -1.2642e+00,  3.6791e+00, -7.8925e-01,  1.1136e+00,  6.2089e+00,\n",
      "           1.1455e+02,  3.5591e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 2.2488e+01, -3.0188e-01,  1.6244e+02, -5.3297e+00,  2.1529e+00,\n",
      "          -1.2979e+01,  8.2626e+01, -2.8419e+00, -1.7410e+00,  4.6903e+00,\n",
      "          -1.2073e+01,  6.8864e+00,  1.5392e+01, -3.9923e+00, -2.4971e+00,\n",
      "          -1.3548e+00,  7.2989e+00,  4.7681e+00, -9.1415e+00, -3.5631e+00,\n",
      "          -4.0778e+00, -2.9169e+01,  8.7567e+00,  1.1679e+02, -1.1116e+02,\n",
      "          -3.9711e+01,  8.2016e+00, -4.0911e+01, -7.0866e+01, -2.8485e+00,\n",
      "          -3.6009e+01, -1.2716e+01,  3.1303e+01, -2.9807e+01, -1.1788e+02,\n",
      "           3.7231e+01, -5.9583e+00,  7.0670e-01, -6.1778e+01,  4.4345e-01,\n",
      "           5.4673e+00, -2.7545e+00, -1.0731e+02, -8.2374e+00, -4.5580e+00,\n",
      "           5.9327e+00,  1.0941e+01, -7.7141e+00,  1.3156e+00,  2.5837e+01,\n",
      "           1.9630e+01,  2.9977e-02,  7.2189e+01, -2.0889e+00,  1.6501e+01,\n",
      "          -7.2796e+01, -1.0941e+01, -1.7800e+00, -6.2828e+00, -5.4968e+00,\n",
      "           3.3570e+00,  7.6122e-01,  7.9607e+00,  1.9747e+01,  7.6210e+00,\n",
      "           5.7483e-01,  3.5639e+00, -1.8843e+00,  4.9143e+01,  5.3166e+00,\n",
      "          -9.7244e+00, -3.9338e+00,  7.3702e+00, -2.1071e+00,  4.5636e+00,\n",
      "          -2.7374e+00, -2.0112e+01,  1.3351e+02, -1.3948e+00,  8.5508e+00,\n",
      "           1.3806e+02, -3.2508e+00, -4.0695e+01,  1.9231e+00,  8.3152e+01,\n",
      "           1.0615e+01, -4.6545e+00,  7.0151e+01,  3.3635e+00, -3.5763e+01,\n",
      "           1.0204e+00, -3.6440e+01,  5.0968e+00,  8.7956e-01, -5.6092e+00,\n",
      "          -9.3504e+01,  2.8214e+00,  3.1438e+01,  4.4471e+00,  9.1276e+01,\n",
      "          -3.2471e+01,  4.9530e+00,  7.9444e+01,  8.5818e-01, -3.3447e+01,\n",
      "          -6.0733e+00, -1.3923e+01,  2.5058e+00, -2.7263e+00,  2.6551e+01,\n",
      "          -9.2532e+01, -1.6635e+02,  9.8441e+00, -3.3243e-01,  4.5421e+00,\n",
      "          -6.3220e+00,  2.5329e+00, -1.2718e+01, -4.1926e-02,  3.3720e+00,\n",
      "          -1.2524e+00,  1.1014e+01, -2.5508e+01,  9.5770e+01,  5.0028e-01,\n",
      "           7.7667e-01,  3.0855e+00,  1.2885e+01, -1.4742e+00, -3.0582e+01,\n",
      "           6.6383e+00, -1.3409e+02, -3.6125e+00, -4.9331e+00, -5.1908e+00,\n",
      "          -5.4402e+01,  2.1389e+01,  1.5114e+02,  9.4770e+00, -8.8147e+00,\n",
      "          -2.6660e+00, -7.1519e+01,  4.9804e+01,  2.7489e+01, -6.3585e+01,\n",
      "           4.9304e+00,  3.0388e+00, -7.1945e+00, -1.1646e+01, -9.5764e+00,\n",
      "           3.1497e+01,  2.8347e+00,  3.5366e+00, -1.3092e+00, -4.8716e+01,\n",
      "           1.1660e+00,  5.9077e+00,  3.6479e+00, -1.1850e+01, -4.1077e+01,\n",
      "           5.5237e+01,  5.8344e+01,  3.9827e+00, -4.5672e+00,  2.7650e+00,\n",
      "           1.0721e+02,  2.5421e+00, -1.1872e+00, -2.2217e+01, -1.6372e+02,\n",
      "           6.0620e+00,  1.5385e+00, -8.7360e+00,  1.2786e+00, -2.3254e+01,\n",
      "          -1.0755e+02,  6.8660e+01,  9.2337e+00, -1.9633e+00, -2.9926e+01,\n",
      "          -6.2433e-01, -8.6822e-01, -7.6485e+01, -2.8765e+01, -1.2899e+02,\n",
      "          -1.2548e+01, -4.5800e-01,  7.5742e+00, -3.9390e+00, -3.9166e+01,\n",
      "           5.4586e-01, -3.1299e+00, -8.5767e+00, -5.1154e+00, -6.4553e+00,\n",
      "           2.8616e+00, -6.4564e+00,  3.9499e+01,  2.3822e+00, -1.6799e+01,\n",
      "          -4.8975e+00, -1.1868e+00, -7.2558e+00,  1.0309e+01, -2.0528e+00,\n",
      "          -1.0207e+01, -1.4091e+00, -1.6621e+02, -3.6167e+00,  1.4882e+01,\n",
      "           5.1645e+01, -2.7728e+00,  2.4421e+01, -3.2360e+01, -9.6857e+00,\n",
      "          -1.5154e+01, -1.0562e+01,  1.5598e+00,  2.1502e-01, -7.9565e+01,\n",
      "          -4.4178e+00, -4.9705e+01,  1.7544e+01,  1.2091e+01,  1.0454e+01,\n",
      "          -2.4216e+01, -3.4639e+00, -9.6221e+00,  1.3192e+02,  3.4686e+01,\n",
      "          -4.4681e+00,  1.1530e+02, -2.0182e+01,  1.3467e+01, -4.1903e+01,\n",
      "           1.0211e+01,  2.1624e+01,  2.9646e+00, -4.9136e+00,  5.2088e+01,\n",
      "           4.0145e+00,  2.7826e+00,  8.3106e-01, -9.1725e+01,  7.2499e+00,\n",
      "           8.1363e-01,  3.5545e+01,  1.4566e+00,  2.3588e+00, -7.1738e+00,\n",
      "          -1.9692e+00, -1.1336e+01,  2.7609e+00, -9.1071e-01, -1.5404e+01,\n",
      "          -4.8929e+01, -5.0504e+00,  1.3583e+00,  2.2455e+01,  3.5761e+00,\n",
      "          -3.6033e+00, -2.9206e+01,  1.2164e+01,  1.0457e+01,  3.5428e+00,\n",
      "          -6.7825e+00,  1.3013e+00,  9.5955e+00, -3.4915e+00, -8.4164e+01,\n",
      "           5.1578e-01,  2.9035e+00, -5.8912e+01,  1.7400e+01, -6.6301e+00,\n",
      "           4.4539e+01, -4.6084e+00,  2.1077e+01, -3.9727e+00, -4.4989e+00,\n",
      "          -2.1922e-01,  2.6668e+00,  4.8474e+01, -3.2430e+00,  4.4073e+00,\n",
      "           2.8765e+00,  1.9366e+00, -1.5498e+01, -1.3797e+00, -1.6524e+00,\n",
      "           2.4936e+01, -1.5219e+01,  6.5024e+00,  4.1382e-01, -4.7698e-01,\n",
      "          -3.8917e+00, -8.0475e+00,  1.1436e+00,  1.4647e+01,  2.3500e+00,\n",
      "          -2.4851e+00, -2.0481e+00, -3.9243e-01,  2.5929e+00, -7.9084e-01,\n",
      "           6.9461e-01,  3.3097e+00, -6.2312e+00,  2.5775e+00, -3.8742e+01,\n",
      "           4.4139e+00, -9.2692e+00,  1.6362e+00,  8.1019e+00,  2.5526e-02,\n",
      "          -6.3530e+01,  6.4883e+00, -4.3802e+01,  5.6980e+00,  8.6814e-01,\n",
      "          -2.5487e+00,  3.3697e+01, -5.6610e+00, -1.9218e+00, -3.0494e+00,\n",
      "          -2.6597e+01, -1.0472e+01, -1.4944e+02,  4.9338e+00, -8.9335e+00,\n",
      "           6.5329e+00, -2.9070e+00,  5.2050e-01, -7.4038e+00,  2.9408e+00,\n",
      "           1.1169e+00,  2.5081e+00,  3.3708e+01, -4.0156e+00, -6.1882e+00,\n",
      "           5.1185e+01,  7.0479e+01, -6.1101e-02, -8.8298e-01,  3.9299e+00,\n",
      "          -5.2166e+00, -4.6590e+01, -3.3738e+01, -1.5813e+01, -1.9378e+00,\n",
      "           3.6167e+01, -1.8463e+01,  1.8762e+01, -6.1840e+01,  7.8143e+00,\n",
      "          -2.8514e+01,  5.1908e-01, -7.7901e+00,  9.3992e+00,  1.0901e+02,\n",
      "           6.1235e-01,  5.1478e+01,  1.9410e+00,  1.1749e+01,  3.6038e+00,\n",
      "          -2.9882e+01, -2.0031e+00, -4.7416e+00,  5.6912e+00,  4.7714e+00,\n",
      "          -1.7679e-02,  3.4447e+01, -5.4778e+00, -4.3169e+01, -2.6602e+00,\n",
      "          -5.5010e+00, -2.3499e+00,  1.3783e+00,  1.8639e+01,  4.1786e+00,\n",
      "           2.7942e+01, -7.6665e+00,  2.3417e+00,  3.4971e+00, -1.0557e+01,\n",
      "          -5.1683e+00, -4.5881e+00, -5.2615e-01, -3.1657e+01,  1.8990e+00,\n",
      "           1.9093e+00,  3.6018e+00, -3.0128e+00,  8.0964e+00, -6.2640e+00,\n",
      "           1.1095e+01, -2.8532e+00, -2.9739e+01, -1.1691e+01, -1.2697e+01,\n",
      "          -7.3362e+01,  1.9645e+01, -4.3997e+01,  1.1895e+01,  3.8896e+01,\n",
      "           1.3519e+02, -2.2511e+01,  3.9735e+00,  5.6661e-01, -3.4645e+00,\n",
      "           3.0113e+00,  2.3942e+00, -2.2365e+00, -2.9708e+00, -5.9832e+01,\n",
      "          -4.0103e+01,  4.8402e+01, -9.2992e+00,  8.4624e+00, -8.3615e+00,\n",
      "           1.6897e+01,  2.4546e+00, -7.9836e+00,  4.1798e+00, -1.2152e+01,\n",
      "          -1.0251e+00,  2.6210e+00, -2.0668e+00, -3.4161e+00,  4.0133e+00,\n",
      "           5.9276e+01,  9.7784e-01,  2.8792e+01, -7.1403e+00, -1.2921e+01,\n",
      "           4.1278e+01,  2.8818e+01,  1.1029e+00, -1.2532e+01,  2.4786e+00,\n",
      "          -2.3033e+01,  2.5684e+02,  9.6365e+00, -4.6279e+00, -3.8422e+01,\n",
      "           2.1945e+01, -2.9395e+01,  7.1947e+01, -1.0155e+01, -6.1909e+00,\n",
      "           6.5008e+00, -1.6665e+00, -5.4199e+00,  1.4959e+02, -6.9273e+00,\n",
      "          -4.1395e+00,  4.7362e+01, -2.0309e+01,  2.0783e+00, -3.2178e+00,\n",
      "           2.2560e+01,  2.5367e+00,  2.4228e+00,  4.1877e+00,  2.8184e+00,\n",
      "          -1.0055e-01, -5.6521e-01,  3.2909e+00,  5.1619e+00,  1.4624e-01,\n",
      "           1.3408e+00, -7.2092e-01, -2.5138e+01, -2.4401e+00, -6.7022e+01,\n",
      "          -6.6621e-01,  3.3076e+01, -4.2793e+00,  6.6145e-01,  1.0111e+02,\n",
      "          -7.3353e+00, -6.5147e+00,  5.3547e+00, -1.6567e+00, -1.1392e+01,\n",
      "           7.8534e+00, -3.7631e+01,  9.4729e+00,  8.2595e+00,  9.7958e+01,\n",
      "          -4.8069e+00, -6.6892e+01,  5.2369e+00,  5.3111e+01, -4.9731e+01,\n",
      "          -2.7707e+00, -6.6395e+00, -6.5457e+01,  6.3224e+00,  8.6472e-02,\n",
      "          -5.7515e+00, -2.0501e+00, -4.7486e+00,  2.6916e-01, -1.9458e+01,\n",
      "          -4.6694e+00,  3.9703e+00, -2.5561e+00,  4.5591e+00,  5.9286e+00,\n",
      "           1.2562e+02, -1.8692e+00]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 2.2427e+01,  5.9391e-01,  1.7765e+02, -3.8225e+00,  2.1690e-01,\n",
      "          -1.7260e+01,  9.2338e+01, -4.5738e+00, -1.6134e+00,  5.5955e+00,\n",
      "          -1.5694e+01,  6.6054e+00,  1.7287e+01, -3.8310e+00, -3.0131e+00,\n",
      "          -1.1685e+00,  8.1556e+00,  3.1383e+00, -1.2462e+01, -2.4279e+00,\n",
      "          -3.6664e+00, -3.2865e+01,  1.0619e+01,  1.2689e+02, -1.2404e+02,\n",
      "          -4.3080e+01,  8.5186e+00, -4.6239e+01, -7.8332e+01, -4.0056e+00,\n",
      "          -4.2035e+01, -1.3459e+01,  3.7513e+01, -3.4860e+01, -1.3069e+02,\n",
      "           4.1248e+01, -1.1939e+01,  1.6149e+00, -6.7946e+01,  8.3456e-01,\n",
      "           5.5887e+00, -4.9792e-01, -1.1816e+02, -1.0666e+01, -6.5828e+00,\n",
      "           7.6602e+00,  1.4519e+01, -8.0358e+00,  1.1214e-01,  3.1154e+01,\n",
      "           2.1984e+01, -4.1836e-01,  8.0410e+01, -3.0809e+00,  2.0580e+01,\n",
      "          -8.0858e+01, -1.1504e+01, -2.0223e+00, -8.3932e+00, -4.8038e+00,\n",
      "           4.2186e+00,  3.6765e+00,  8.4393e+00,  2.3172e+01,  8.7636e+00,\n",
      "          -2.3035e-01,  1.2617e+00, -3.4497e+00,  5.4173e+01,  4.8473e+00,\n",
      "          -1.2040e+01, -3.9849e+00,  8.1970e+00, -2.2365e+00,  7.3483e+00,\n",
      "          -5.7864e+00, -2.3439e+01,  1.4426e+02, -6.7120e-01,  8.9405e+00,\n",
      "           1.5273e+02, -4.1950e-01, -4.4727e+01,  2.9131e+00,  9.3678e+01,\n",
      "           1.0151e+01, -3.3775e+00,  7.9207e+01,  1.8368e+00, -4.1844e+01,\n",
      "          -2.3112e-01, -4.2193e+01,  5.8890e+00, -7.1860e-01, -4.9650e+00,\n",
      "          -1.0084e+02,  2.9145e+00,  3.7187e+01,  4.6550e+00,  1.0012e+02,\n",
      "          -3.6860e+01,  5.4623e+00,  8.8937e+01,  5.4732e-01, -3.7574e+01,\n",
      "          -5.3847e+00, -1.5504e+01,  4.2990e+00, -6.3058e+00,  2.9346e+01,\n",
      "          -1.0132e+02, -1.8274e+02,  9.3508e+00, -8.0935e-01,  5.5653e+00,\n",
      "          -4.9936e+00,  5.0137e+00, -1.5018e+01,  3.1141e-01, -1.1127e-01,\n",
      "           4.1384e-01,  1.2730e+01, -2.7395e+01,  1.0410e+02,  6.9274e-02,\n",
      "           8.7677e-01,  2.3701e+00,  1.5251e+01, -3.3055e+00, -3.6341e+01,\n",
      "           5.6124e+00, -1.4680e+02, -1.9716e+00, -5.8929e+00, -3.9344e+00,\n",
      "          -6.0785e+01,  2.5561e+01,  1.6867e+02,  1.1861e+01, -1.0390e+01,\n",
      "          -3.8433e+00, -8.0008e+01,  5.5675e+01,  3.2300e+01, -7.2489e+01,\n",
      "           5.0248e+00,  1.5802e+00, -8.2761e+00, -1.6140e+01, -8.7477e+00,\n",
      "           3.7111e+01,  3.7207e+00,  4.6598e+00,  1.0313e+00, -5.3679e+01,\n",
      "          -9.8830e-01,  6.8196e+00,  6.3501e+00, -1.3859e+01, -4.3680e+01,\n",
      "           6.2171e+01,  6.5421e+01,  4.0885e+00, -4.2551e+00,  3.0008e+00,\n",
      "           1.1974e+02, -5.4393e-01, -5.0411e+00, -2.4972e+01, -1.8022e+02,\n",
      "           6.5085e+00,  2.2449e+00, -8.5893e+00, -1.1155e-01, -2.8920e+01,\n",
      "          -1.1730e+02,  7.7457e+01,  1.3378e+01, -2.6134e+00, -3.4625e+01,\n",
      "          -1.2888e+00,  1.2053e+00, -8.6580e+01, -3.6201e+01, -1.4155e+02,\n",
      "          -1.5613e+01,  6.4538e-01,  7.6675e+00, -4.3420e+00, -4.2550e+01,\n",
      "           1.7913e+00, -4.9824e+00, -9.9506e+00, -5.5774e+00, -6.6296e+00,\n",
      "           4.9156e+00, -7.4771e+00,  4.1537e+01,  5.0835e+00, -1.8401e+01,\n",
      "          -3.0680e+00, -3.5259e+00, -6.5079e+00,  1.0765e+01, -1.4377e+00,\n",
      "          -1.2843e+01, -2.1992e+00, -1.8264e+02, -3.0396e+00,  1.6916e+01,\n",
      "           5.7211e+01, -4.4447e+00,  2.8238e+01, -3.5162e+01, -1.2667e+01,\n",
      "          -1.6080e+01, -1.0413e+01, -1.0741e+00, -5.3804e-01, -9.0614e+01,\n",
      "          -2.6413e+00, -5.4448e+01,  2.1514e+01,  1.4919e+01,  1.1425e+01,\n",
      "          -2.7361e+01, -3.6684e+00, -8.7034e+00,  1.4600e+02,  3.8713e+01,\n",
      "          -4.7786e+00,  1.2520e+02, -2.2522e+01,  1.7252e+01, -4.7319e+01,\n",
      "           1.2657e+01,  2.3187e+01,  5.2381e+00, -8.4340e+00,  5.5409e+01,\n",
      "           5.6463e+00,  5.4859e+00,  1.9497e+00, -9.8865e+01,  1.2633e+01,\n",
      "          -1.1050e+00,  3.8639e+01,  1.7700e+00,  2.5851e+00, -7.6939e+00,\n",
      "          -1.4076e+00, -1.3969e+01,  3.3745e+00, -2.7336e+00, -1.8085e+01,\n",
      "          -5.5664e+01, -5.6474e+00,  2.0470e+00,  2.4335e+01,  6.4127e+00,\n",
      "          -5.6161e+00, -3.5143e+01,  1.3626e+01,  1.1067e+01,  3.5292e+00,\n",
      "          -8.3449e+00,  5.7959e-01,  1.0652e+01, -2.1832e+00, -9.4385e+01,\n",
      "          -2.4475e-01,  5.4253e+00, -6.4908e+01,  2.0262e+01, -8.3124e+00,\n",
      "           5.1084e+01, -4.6991e+00,  2.4205e+01, -5.2221e-01, -2.8166e+00,\n",
      "          -8.2627e-01,  4.0523e+00,  5.5081e+01, -2.6622e+00,  5.0946e+00,\n",
      "           1.5108e+00,  2.2974e+00, -1.9918e+01, -3.7347e+00,  4.6320e-01,\n",
      "           2.7818e+01, -1.6375e+01,  6.6023e+00,  1.1189e+00,  3.8934e-01,\n",
      "          -2.7144e+00, -7.6010e+00,  1.2415e+00,  1.8959e+01,  1.9779e+00,\n",
      "          -7.6466e-01, -3.5554e+00, -2.8963e+00,  1.2446e+00,  9.8285e-01,\n",
      "           1.0577e+00,  6.5805e+00, -6.7339e+00,  2.4440e+00, -4.5097e+01,\n",
      "           4.1966e+00, -9.6532e+00,  1.7214e+00,  7.4129e+00,  3.4149e+00,\n",
      "          -6.9279e+01,  5.0929e+00, -5.1407e+01,  6.8550e+00, -3.0145e-01,\n",
      "          -2.3666e+00,  3.6838e+01, -2.6398e+00, -1.1988e+00, -6.9722e+00,\n",
      "          -3.0748e+01, -1.3215e+01, -1.6198e+02,  4.2074e+00, -9.0427e+00,\n",
      "           8.5807e+00, -4.5633e+00,  3.3156e+00, -6.0826e+00,  3.9221e+00,\n",
      "          -2.1869e+00,  3.2557e+00,  3.6302e+01, -4.2041e+00, -8.3366e+00,\n",
      "           5.6131e+01,  8.0186e+01,  1.0719e+00, -2.1087e+00,  3.5224e+00,\n",
      "          -7.7777e+00, -5.1172e+01, -3.9701e+01, -1.8914e+01, -3.8626e+00,\n",
      "           4.3644e+01, -2.1483e+01,  2.2687e+01, -6.7043e+01,  1.0143e+01,\n",
      "          -3.3297e+01, -2.4071e+00, -9.1862e+00,  9.1868e+00,  1.2283e+02,\n",
      "          -5.6405e-01,  5.6537e+01,  3.5234e+00,  1.2844e+01,  4.2716e+00,\n",
      "          -3.5859e+01, -3.9899e+00, -5.0369e+00,  6.8305e+00,  9.2542e+00,\n",
      "           1.3561e+00,  4.0523e+01, -5.4792e+00, -4.6999e+01, -2.9607e+00,\n",
      "          -5.2712e+00, -2.6235e+00,  3.6507e-01,  2.1974e+01,  4.7347e+00,\n",
      "           2.8798e+01, -6.7737e+00,  2.5191e+00,  2.9191e+00, -1.1469e+01,\n",
      "          -6.0765e+00, -5.0183e+00,  1.9280e+00, -3.7527e+01,  4.6110e-01,\n",
      "           2.3695e+00,  2.1113e+00, -2.8859e+00,  8.8287e+00, -9.0416e+00,\n",
      "           1.3340e+01, -5.0049e+00, -3.5398e+01, -1.3086e+01, -1.6706e+01,\n",
      "          -8.0713e+01,  2.2413e+01, -5.1658e+01,  1.2355e+01,  4.6986e+01,\n",
      "           1.4968e+02, -2.5222e+01,  3.6572e+00, -1.8343e+00, -2.5690e+00,\n",
      "           3.5365e+00,  2.1376e+00, -5.2954e+00, -2.6691e+00, -6.7719e+01,\n",
      "          -4.4685e+01,  5.6007e+01, -1.3263e+01,  9.3205e+00, -7.6086e+00,\n",
      "           2.0272e+01,  3.9787e+00, -7.4923e+00,  3.4350e+00, -1.4542e+01,\n",
      "           1.3976e+00,  1.6472e+00, -2.5721e+00, -5.8237e+00,  3.3603e+00,\n",
      "           6.7567e+01,  5.8564e-01,  3.2811e+01, -1.0074e+01, -1.5934e+01,\n",
      "           4.6372e+01,  3.4468e+01,  2.9964e+00, -1.2341e+01,  1.9546e+00,\n",
      "          -2.4948e+01,  2.7877e+02,  1.0302e+01, -4.3625e+00, -4.0525e+01,\n",
      "           2.2418e+01, -3.2385e+01,  7.9970e+01, -1.3566e+01, -5.4665e+00,\n",
      "           7.1501e+00, -5.0277e+00, -8.0255e+00,  1.6761e+02, -6.0490e+00,\n",
      "          -3.0685e+00,  5.3639e+01, -2.1702e+01,  3.4333e+00, -1.0194e+00,\n",
      "           2.6789e+01,  2.6696e+00,  2.1160e+00,  6.1052e+00,  2.8699e+00,\n",
      "          -1.5263e+00, -6.6795e-01,  4.9111e+00,  4.8552e+00,  2.7872e+00,\n",
      "          -8.7014e-01,  1.2899e+00, -3.2250e+01, -4.2667e+00, -7.5157e+01,\n",
      "          -2.1146e+00,  3.6524e+01, -4.8707e+00,  2.8185e-01,  1.1474e+02,\n",
      "          -7.4315e+00, -7.4358e+00,  4.6228e+00, -3.1172e+00, -1.2271e+01,\n",
      "           7.9624e+00, -4.3390e+01,  1.0122e+01,  1.1133e+01,  1.0788e+02,\n",
      "          -4.4956e+00, -7.3925e+01,  7.3171e+00,  5.6592e+01, -6.0043e+01,\n",
      "          -4.1934e+00, -6.7185e+00, -7.2690e+01,  5.1634e+00, -2.8607e-01,\n",
      "          -9.7887e+00, -1.3739e+00, -5.4050e+00, -9.8577e-01, -2.0412e+01,\n",
      "          -7.0645e+00,  2.5650e+00, -5.5089e+00,  4.8287e+00,  5.7242e+00,\n",
      "           1.3739e+02, -3.2883e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 2.2973e+01, -1.6617e+00,  1.9076e+02, -1.5217e+00, -6.4552e-01,\n",
      "          -2.1508e+01,  1.0199e+02, -4.6195e+00, -3.6821e+00,  7.0489e+00,\n",
      "          -1.9298e+01,  6.4928e+00,  2.1445e+01, -4.2452e+00, -3.1614e+00,\n",
      "          -1.4382e+00,  1.0595e+01, -3.7267e-03, -1.3148e+01, -3.9570e+00,\n",
      "          -3.6975e+00, -3.5721e+01,  1.4355e+01,  1.3778e+02, -1.3576e+02,\n",
      "          -4.7453e+01,  9.6274e+00, -5.2671e+01, -8.7502e+01, -5.1066e+00,\n",
      "          -4.6719e+01, -1.3899e+01,  4.2749e+01, -3.9398e+01, -1.4228e+02,\n",
      "           4.4859e+01, -1.5491e+01,  2.1540e+00, -7.5986e+01,  1.1302e+00,\n",
      "           7.4363e+00,  4.7999e-01, -1.2958e+02, -1.1342e+01, -9.8480e+00,\n",
      "           9.8299e+00,  1.6891e+01, -9.3052e+00, -2.7602e+00,  3.5637e+01,\n",
      "           2.5143e+01,  2.4288e+00,  9.0401e+01, -5.9273e+00,  2.4459e+01,\n",
      "          -9.0583e+01, -1.5312e+01, -7.1028e-01, -6.6709e+00, -5.7357e+00,\n",
      "           6.3125e+00,  3.4115e+00,  7.3144e+00,  2.8398e+01,  9.5454e+00,\n",
      "           1.4346e+00, -1.1253e+00, -3.4315e+00,  5.9874e+01,  4.6064e+00,\n",
      "          -1.4239e+01, -3.8031e+00,  1.1000e+01, -2.2466e+00,  6.7495e+00,\n",
      "          -8.6733e+00, -2.7866e+01,  1.5718e+02, -1.5180e+00,  9.1298e+00,\n",
      "           1.6432e+02,  1.3077e+00, -4.8957e+01,  3.3756e+00,  1.0065e+02,\n",
      "           1.1868e+01, -3.9137e+00,  8.5393e+01, -1.2540e+00, -4.7143e+01,\n",
      "           2.1523e-01, -4.6540e+01,  4.8898e+00, -1.7039e+00, -3.4636e+00,\n",
      "          -1.0810e+02,  5.2828e+00,  4.3578e+01,  4.3341e+00,  1.1168e+02,\n",
      "          -3.8822e+01,  7.7767e+00,  9.9220e+01, -1.2031e+00, -4.2484e+01,\n",
      "          -6.1998e+00, -2.1152e+01,  5.9244e+00, -7.9349e+00,  3.3998e+01,\n",
      "          -1.1220e+02, -1.9969e+02,  9.1711e+00,  1.3046e+00,  7.5681e+00,\n",
      "          -2.8972e+00,  6.8200e+00, -1.7002e+01,  1.8188e+00,  1.8649e-01,\n",
      "           1.1856e+00,  1.1782e+01, -3.2179e+01,  1.1403e+02,  1.3099e+00,\n",
      "           2.4273e+00,  1.5722e+00,  1.9810e+01, -4.1151e+00, -4.1525e+01,\n",
      "           6.7623e+00, -1.5982e+02, -2.0586e+00, -7.3588e+00, -5.1601e+00,\n",
      "          -6.8832e+01,  2.7950e+01,  1.8189e+02,  1.7203e+01, -1.0662e+01,\n",
      "          -7.1977e+00, -8.9225e+01,  6.2783e+01,  3.7159e+01, -7.8979e+01,\n",
      "           6.5597e+00,  2.2199e+00, -9.4072e+00, -1.7646e+01, -8.9095e+00,\n",
      "           4.2293e+01,  2.6395e+00,  5.3428e+00,  3.4318e-01, -5.8004e+01,\n",
      "           1.7119e+00,  7.4122e+00,  5.0061e+00, -1.7640e+01, -4.8216e+01,\n",
      "           6.9065e+01,  7.0633e+01,  3.6177e+00, -4.2720e+00,  3.2934e+00,\n",
      "           1.3033e+02, -1.6869e+00, -7.7265e+00, -2.7974e+01, -1.9733e+02,\n",
      "           7.3851e+00,  3.9095e+00, -1.1142e+01,  1.3551e-01, -3.2595e+01,\n",
      "          -1.2626e+02,  8.7696e+01,  1.6425e+01, -2.9821e+00, -3.8208e+01,\n",
      "          -1.5190e-01,  2.0092e+00, -9.6739e+01, -4.2933e+01, -1.5273e+02,\n",
      "          -1.7576e+01,  1.1039e+00,  6.6944e+00, -2.8113e+00, -4.7966e+01,\n",
      "           2.5296e+00, -4.3544e+00, -1.0286e+01, -6.3697e+00, -5.8329e+00,\n",
      "           6.5135e+00, -8.4664e+00,  4.5015e+01,  6.5587e+00, -1.8718e+01,\n",
      "          -3.5883e+00, -6.9196e+00, -9.1319e+00,  1.3144e+01, -1.0673e+00,\n",
      "          -1.4036e+01, -2.5119e+00, -1.9841e+02, -1.4463e+00,  1.7949e+01,\n",
      "           6.4301e+01, -3.6047e+00,  3.3074e+01, -4.0070e+01, -1.3976e+01,\n",
      "          -1.8297e+01, -1.0065e+01, -2.9349e+00, -2.2116e+00, -9.7411e+01,\n",
      "          -2.2863e+00, -5.6869e+01,  2.4544e+01,  1.6039e+01,  1.4308e+01,\n",
      "          -2.6757e+01, -4.4380e+00, -8.9740e+00,  1.5850e+02,  4.1510e+01,\n",
      "          -5.7442e+00,  1.3552e+02, -2.5275e+01,  1.9911e+01, -5.5000e+01,\n",
      "           1.4508e+01,  2.4388e+01,  6.3424e+00, -9.8646e+00,  5.8470e+01,\n",
      "           5.4078e+00,  4.3927e+00,  6.2505e-01, -1.0954e+02,  1.5337e+01,\n",
      "          -3.1640e+00,  4.2697e+01,  4.0066e+00,  3.9399e+00, -8.4674e+00,\n",
      "          -2.2122e+00, -1.5567e+01,  3.2258e+00, -1.7167e+00, -2.0170e+01,\n",
      "          -6.1855e+01, -5.8073e+00,  2.3239e+00,  2.6942e+01,  7.3535e+00,\n",
      "          -5.1521e+00, -4.1666e+01,  1.5174e+01,  1.3911e+01,  5.3566e+00,\n",
      "          -8.9491e+00, -4.0984e+00,  1.1828e+01, -9.5069e-01, -1.0327e+02,\n",
      "           1.5459e+00,  7.1520e+00, -7.0232e+01,  2.2881e+01, -9.4401e+00,\n",
      "           5.7646e+01, -5.4247e+00,  2.6044e+01,  1.6536e-01, -1.6539e+00,\n",
      "           7.0873e-01,  4.1398e+00,  6.1172e+01, -1.7686e+00,  6.4341e+00,\n",
      "           4.7652e-01,  4.3913e+00, -2.7107e+01, -2.1822e+00,  9.6707e-01,\n",
      "           3.1223e+01, -1.8163e+01,  9.0407e+00, -8.4190e-01,  7.8362e-01,\n",
      "          -2.6567e+00, -1.0500e+01,  3.6363e+00,  2.5281e+01,  2.2620e+00,\n",
      "          -1.3791e+00, -2.4622e+00, -4.9646e+00,  3.0374e-01,  2.5177e+00,\n",
      "           8.8645e-01,  9.2687e+00, -7.8057e+00,  6.9925e-01, -5.3455e+01,\n",
      "           1.9671e+00, -7.0817e+00,  3.6238e+00,  7.2259e+00,  6.0524e+00,\n",
      "          -7.6181e+01,  8.0457e+00, -5.8365e+01,  6.6230e+00, -1.0288e+00,\n",
      "          -3.9986e+00,  4.0784e+01, -3.6788e+00, -3.3886e+00, -7.4363e+00,\n",
      "          -3.3594e+01, -1.5353e+01, -1.7693e+02,  5.5548e+00, -9.8163e+00,\n",
      "           9.5274e+00, -6.0066e+00,  3.7701e+00, -7.2876e+00,  2.6783e+00,\n",
      "          -4.4253e+00,  3.4542e+00,  3.8370e+01, -6.5130e+00, -8.9383e+00,\n",
      "           6.3230e+01,  9.2010e+01,  1.4396e+00, -1.8869e+00,  5.7989e+00,\n",
      "          -9.2119e+00, -5.9880e+01, -4.3143e+01, -1.9419e+01, -3.6916e+00,\n",
      "           5.0549e+01, -2.4067e+01,  2.8231e+01, -7.4156e+01,  1.2673e+01,\n",
      "          -3.6402e+01, -2.4117e+00, -1.0220e+01,  9.0528e+00,  1.3526e+02,\n",
      "          -5.3121e-02,  6.1566e+01,  4.0210e+00,  1.2894e+01,  3.9652e+00,\n",
      "          -4.0170e+01, -7.1304e-01, -8.6164e+00,  7.3035e+00,  1.1365e+01,\n",
      "           3.1590e+00,  4.4940e+01, -5.0646e+00, -5.1779e+01, -2.1094e+00,\n",
      "          -3.5231e+00, -2.1512e+00,  3.2689e+00,  2.7280e+01,  5.6845e+00,\n",
      "           3.0820e+01, -6.0635e+00,  5.7745e+00,  4.1696e+00, -1.1843e+01,\n",
      "          -8.5817e+00, -4.9616e+00,  4.3272e+00, -4.3415e+01,  2.4350e+00,\n",
      "           2.3160e+00,  3.8304e+00, -7.0728e+00,  1.1137e+01, -1.1315e+01,\n",
      "           1.6521e+01, -5.2437e+00, -4.0664e+01, -1.3207e+01, -2.0904e+01,\n",
      "          -8.6726e+01,  2.6222e+01, -5.9675e+01,  1.5064e+01,  5.2862e+01,\n",
      "           1.6337e+02, -3.1588e+01,  3.7650e+00, -2.7675e+00, -4.5372e+00,\n",
      "           6.6855e+00,  2.9740e+00, -8.4907e+00, -1.3229e+00, -7.6417e+01,\n",
      "          -4.9157e+01,  6.1699e+01, -1.5876e+01,  1.3480e+01, -8.5519e+00,\n",
      "           2.1136e+01,  5.3506e+00, -8.1935e+00,  4.2668e+00, -1.7651e+01,\n",
      "           2.7410e+00,  3.7080e+00, -1.6736e+00, -6.0668e+00,  4.4565e+00,\n",
      "           7.2384e+01,  2.5722e+00,  3.9201e+01, -1.1018e+01, -1.6585e+01,\n",
      "           5.2079e+01,  3.7111e+01,  3.9118e+00, -1.5202e+01,  4.0466e+00,\n",
      "          -2.7450e+01,  3.0248e+02,  1.0447e+01, -7.1809e+00, -4.4676e+01,\n",
      "           2.4393e+01, -3.4010e+01,  8.7394e+01, -1.7762e+01, -7.6099e+00,\n",
      "           7.6372e+00, -8.2845e+00, -8.8559e+00,  1.8439e+02, -5.9656e+00,\n",
      "          -3.2470e+00,  6.3226e+01, -2.4479e+01,  4.8232e+00,  1.4274e+00,\n",
      "           2.7956e+01,  1.7080e+00,  2.3565e+00,  7.3396e+00,  2.8845e+00,\n",
      "          -5.3483e+00, -6.6079e-01,  6.1064e+00,  1.0011e+01,  5.2266e+00,\n",
      "          -8.8405e-01,  1.9520e+00, -3.5726e+01, -4.0166e+00, -8.4041e+01,\n",
      "           5.8563e-03,  3.9875e+01, -4.1206e+00, -6.2601e-01,  1.2623e+02,\n",
      "          -6.4557e+00, -6.5011e+00,  3.5361e+00, -2.9215e+00, -1.3961e+01,\n",
      "           1.0544e+01, -5.0324e+01,  1.2810e+01,  1.4226e+01,  1.1350e+02,\n",
      "          -6.8586e+00, -8.1598e+01,  5.9406e+00,  6.1098e+01, -6.6344e+01,\n",
      "          -6.4150e+00, -6.9574e+00, -8.0065e+01,  4.0349e+00,  3.3991e-01,\n",
      "          -1.2401e+01, -3.4613e+00, -6.3475e+00,  6.1303e-01, -2.3034e+01,\n",
      "          -7.2322e+00,  6.1614e-01, -5.2008e+00,  7.1388e+00,  6.0734e+00,\n",
      "           1.4888e+02, -3.8180e-01]]], device='cuda:0', grad_fn=<AddBackward0>), tensor([[[ 5.3623e-01, -3.9132e-02,  4.4602e+00, -4.5059e-02, -1.6556e-02,\n",
      "          -4.7299e-01,  2.3046e+00, -8.8910e-02, -6.8069e-02,  1.2829e-01,\n",
      "          -4.2404e-01,  1.3068e-01,  4.8174e-01, -8.6659e-02, -5.7795e-02,\n",
      "          -2.2291e-02,  2.0673e-01, -6.6895e-04, -2.7177e-01, -8.3129e-02,\n",
      "          -7.6659e-02, -7.9197e-01,  3.2055e-01,  3.0956e+00, -3.0907e+00,\n",
      "          -1.0409e+00,  2.1181e-01, -1.1749e+00, -1.9782e+00, -9.8334e-02,\n",
      "          -1.0659e+00, -3.1159e-01,  9.4573e-01, -8.7635e-01, -3.1680e+00,\n",
      "           1.0189e+00, -3.3223e-01,  5.3798e-02, -1.7126e+00,  2.4504e-02,\n",
      "           1.6899e-01, -8.8434e-04, -2.9816e+00, -2.4230e-01, -2.0892e-01,\n",
      "           2.2997e-01,  3.7729e-01, -1.8332e-01, -5.6631e-02,  8.0736e-01,\n",
      "           5.5529e-01,  4.5825e-02,  2.0314e+00, -1.1547e-01,  5.3175e-01,\n",
      "          -2.0132e+00, -3.2587e-01, -1.6552e-02, -1.3172e-01, -1.0053e-01,\n",
      "           1.3619e-01,  7.2152e-02,  1.6184e-01,  6.3988e-01,  2.0708e-01,\n",
      "           2.6715e-02, -2.1589e-02, -6.1522e-02,  1.3337e+00,  1.0122e-01,\n",
      "          -3.0986e-01, -5.7142e-02,  2.4963e-01, -3.6666e-02,  1.4415e-01,\n",
      "          -1.7262e-01, -6.0707e-01,  3.5843e+00, -3.1078e-02,  1.9710e-01,\n",
      "           3.7820e+00,  3.0804e-02, -1.0859e+00,  6.7672e-02,  2.2256e+00,\n",
      "           2.5815e-01, -7.4824e-02,  1.9273e+00, -1.2486e-02, -1.0455e+00,\n",
      "           2.3754e-02, -1.0269e+00,  1.0917e-01, -2.9300e-02, -7.2362e-02,\n",
      "          -2.4216e+00,  1.1137e-01,  1.0024e+00,  9.9795e-02,  2.5177e+00,\n",
      "          -8.4808e-01,  1.6013e-01,  2.2175e+00, -1.0859e-02, -9.4745e-01,\n",
      "          -1.2664e-01, -4.5622e-01,  1.3774e-01, -1.5998e-01,  7.6888e-01,\n",
      "          -2.5150e+00, -4.5324e+00,  1.9839e-01,  3.9229e-02,  1.7505e-01,\n",
      "          -7.1246e-02,  1.3825e-01, -3.6396e-01,  3.2707e-02,  2.0990e-02,\n",
      "           3.2827e-02,  2.4584e-01, -7.1410e-01,  2.5881e+00,  4.1290e-02,\n",
      "           4.8739e-02,  4.4527e-02,  4.4220e-01, -8.1728e-02, -9.5926e-01,\n",
      "           1.4150e-01, -3.6501e+00, -3.5731e-02, -1.5647e-01, -1.0959e-01,\n",
      "          -1.5131e+00,  6.4338e-01,  4.2484e+00,  3.8043e-01, -2.0966e-01,\n",
      "          -1.4667e-01, -1.9938e+00,  1.4109e+00,  8.5129e-01, -1.7449e+00,\n",
      "           1.3039e-01,  5.5877e-02, -2.0393e-01, -3.9878e-01, -1.6720e-01,\n",
      "           9.6526e-01,  5.4391e-02,  1.1752e-01,  1.0614e-02, -1.2630e+00,\n",
      "           2.5900e-02,  1.6221e-01,  1.1049e-01, -3.8761e-01, -1.0744e+00,\n",
      "           1.5831e+00,  1.6064e+00,  8.8728e-02, -1.1382e-01,  6.6143e-02,\n",
      "           2.9541e+00, -2.6718e-02, -1.4409e-01, -6.2182e-01, -4.5267e+00,\n",
      "           1.5807e-01,  8.3162e-02, -2.4648e-01, -6.3515e-03, -7.3700e-01,\n",
      "          -2.8772e+00,  1.9879e+00,  3.6067e-01, -7.0874e-02, -8.4139e-01,\n",
      "           2.8253e-03,  4.0750e-02, -2.1608e+00, -9.6642e-01, -3.4615e+00,\n",
      "          -4.0061e-01,  1.0136e-02,  1.3646e-01, -5.5137e-02, -1.0587e+00,\n",
      "           6.4333e-02, -8.8817e-02, -2.2287e-01, -1.3621e-01, -1.2750e-01,\n",
      "           1.4588e-01, -1.7119e-01,  1.0197e+00,  1.4452e-01, -4.0855e-01,\n",
      "          -7.7950e-02, -1.2361e-01, -1.8517e-01,  2.8257e-01, -1.9560e-02,\n",
      "          -2.9084e-01, -5.0662e-02, -4.6024e+00, -2.1610e-02,  3.9456e-01,\n",
      "           1.4459e+00, -6.8001e-02,  7.5022e-01, -8.8508e-01, -2.9696e-01,\n",
      "          -4.0681e-01, -2.0120e-01, -4.7310e-02, -4.2166e-02, -2.1992e+00,\n",
      "          -4.0464e-02, -1.2916e+00,  5.5669e-01,  3.5453e-01,  3.1345e-01,\n",
      "          -6.0879e-01, -8.5544e-02, -1.8978e-01,  3.6308e+00,  9.3560e-01,\n",
      "          -1.1119e-01,  3.0304e+00, -5.5676e-01,  4.3865e-01, -1.2526e+00,\n",
      "           3.2064e-01,  5.4929e-01,  1.2291e-01, -2.1064e-01,  1.3530e+00,\n",
      "           1.1144e-01,  8.1840e-02,  1.9361e-02, -2.4659e+00,  3.4390e-01,\n",
      "          -7.3622e-02,  9.5300e-01,  8.7964e-02,  7.4243e-02, -1.7263e-01,\n",
      "          -5.4505e-02, -3.2656e-01,  6.5085e-02, -3.1919e-02, -4.3005e-01,\n",
      "          -1.3743e+00, -1.0514e-01,  5.4344e-02,  6.1730e-01,  1.4582e-01,\n",
      "          -9.1345e-02, -9.4586e-01,  3.2924e-01,  3.0087e-01,  1.1823e-01,\n",
      "          -1.8968e-01, -7.7894e-02,  2.4460e-01, -1.1356e-02, -2.2905e+00,\n",
      "           4.3153e-02,  1.5354e-01, -1.5729e+00,  5.0290e-01, -1.9187e-01,\n",
      "           1.3147e+00, -1.1155e-01,  5.8552e-01,  6.3883e-03, -3.9380e-02,\n",
      "           1.5487e-02,  7.1835e-02,  1.3782e+00, -3.9002e-02,  1.3741e-01,\n",
      "           2.2482e-02,  8.1176e-02, -5.8497e-01, -4.1156e-02,  1.3398e-02,\n",
      "           6.9589e-01, -4.1714e-01,  1.9718e-01, -7.9333e-03,  2.3593e-02,\n",
      "          -5.3127e-02, -2.1908e-01,  7.3501e-02,  5.5380e-01,  4.6432e-02,\n",
      "          -3.2179e-02, -4.7147e-02, -1.0323e-01, -1.9635e-04,  4.4311e-02,\n",
      "           6.6846e-03,  1.9026e-01, -1.5566e-01,  1.2748e-02, -1.2016e+00,\n",
      "           4.7970e-02, -1.3002e-01,  7.0105e-02,  1.5839e-01,  1.2785e-01,\n",
      "          -1.7077e+00,  1.6995e-01, -1.2977e+00,  1.3873e-01, -1.8183e-02,\n",
      "          -7.9549e-02,  9.1610e-01, -6.7079e-02, -6.2034e-02, -1.6139e-01,\n",
      "          -7.4569e-01, -3.2840e-01, -4.0290e+00,  1.2577e-01, -2.0204e-01,\n",
      "           2.0001e-01, -1.1744e-01,  8.3621e-02, -1.3706e-01,  5.1602e-02,\n",
      "          -8.0036e-02,  8.2307e-02,  8.5354e-01, -1.4582e-01, -1.7525e-01,\n",
      "           1.4260e+00,  2.0808e+00,  4.0740e-02, -3.9022e-02,  1.1814e-01,\n",
      "          -1.9142e-01, -1.3352e+00, -9.7449e-01, -4.2681e-01, -7.4466e-02,\n",
      "           1.1503e+00, -5.2167e-01,  6.3594e-01, -1.6545e+00,  2.6447e-01,\n",
      "          -8.1599e-01, -3.7215e-02, -2.2381e-01,  1.9569e-01,  3.1199e+00,\n",
      "          -7.2655e-03,  1.3955e+00,  9.8602e-02,  2.6919e-01,  9.3715e-02,\n",
      "          -9.0589e-01, -1.6618e-02, -1.7523e-01,  1.5417e-01,  2.3837e-01,\n",
      "           6.1153e-02,  1.0323e+00, -1.0509e-01, -1.1426e+00, -4.1868e-02,\n",
      "          -7.3079e-02, -5.1109e-02,  7.5396e-02,  5.9902e-01,  1.1808e-01,\n",
      "           6.8389e-01, -1.2131e-01,  1.2271e-01,  8.3514e-02, -2.5202e-01,\n",
      "          -1.7565e-01, -9.7078e-02,  9.5573e-02, -9.7207e-01,  5.8390e-02,\n",
      "           4.4967e-02,  8.4488e-02, -1.3950e-01,  2.3404e-01, -2.2720e-01,\n",
      "           3.5314e-01, -1.0902e-01, -8.9772e-01, -2.7061e-01, -4.4769e-01,\n",
      "          -1.9360e+00,  5.7908e-01, -1.3338e+00,  3.3033e-01,  1.1852e+00,\n",
      "           3.7820e+00, -7.0208e-01,  8.7704e-02, -3.8823e-02, -8.0336e-02,\n",
      "           1.4580e-01,  6.1569e-02, -1.6459e-01, -1.3049e-02, -1.7404e+00,\n",
      "          -1.0840e+00,  1.3625e+00, -3.2854e-01,  2.9860e-01, -1.7801e-01,\n",
      "           4.6081e-01,  1.2482e-01, -1.7355e-01,  8.6204e-02, -3.8811e-01,\n",
      "           5.5021e-02,  7.5116e-02, -2.4489e-02, -1.2995e-01,  8.9706e-02,\n",
      "           1.6293e+00,  5.0170e-02,  9.0883e-01, -2.2445e-01, -3.5229e-01,\n",
      "           1.1827e+00,  8.4753e-01,  8.2146e-02, -3.2537e-01,  8.1212e-02,\n",
      "          -5.9769e-01,  7.0861e+00,  2.4516e-01, -1.4252e-01, -1.0087e+00,\n",
      "           5.5088e-01, -7.6636e-01,  1.9603e+00, -3.7853e-01, -1.6065e-01,\n",
      "           1.6859e-01, -1.7291e-01, -1.7667e-01,  4.2169e+00, -1.2672e-01,\n",
      "          -7.2178e-02,  1.4359e+00, -5.4508e-01,  9.1037e-02,  1.9399e-02,\n",
      "           6.1726e-01,  4.1378e-02,  5.0199e-02,  1.5265e-01,  5.8959e-02,\n",
      "          -9.7316e-02, -1.4854e-03,  1.1974e-01,  2.1597e-01,  1.0561e-01,\n",
      "          -4.1176e-03,  3.5846e-02, -8.0728e-01, -7.2616e-02, -1.9786e+00,\n",
      "          -9.6440e-03,  8.8832e-01, -8.7287e-02, -1.2438e-02,  2.8899e+00,\n",
      "          -1.2384e-01, -1.3294e-01,  8.2458e-02, -5.4560e-02, -2.8728e-01,\n",
      "           2.4131e-01, -1.1275e+00,  2.7031e-01,  3.1085e-01,  2.5915e+00,\n",
      "          -1.4176e-01, -1.8162e+00,  1.3004e-01,  1.3650e+00, -1.4561e+00,\n",
      "          -1.2682e-01, -1.3893e-01, -1.8348e+00,  8.7773e-02,  9.9765e-03,\n",
      "          -2.6898e-01, -7.8698e-02, -1.3946e-01,  1.7879e-02, -5.2452e-01,\n",
      "          -1.3882e-01,  1.5172e-02, -1.0664e-01,  1.4643e-01,  1.2842e-01,\n",
      "           3.3980e+00, -1.3805e-02]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([0]).unsqueeze(0).long().to(device)\n",
    "output, loss, hidden_states = model(x,output_hidden_states=True)\n",
    "print(hidden_states)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:48.019455900Z",
     "start_time": "2024-05-23T22:43:47.523455500Z"
    }
   },
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "last_hidden_state = hidden_states[-1]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:48.112454800Z",
     "start_time": "2024-05-23T22:43:48.019957900Z"
    }
   },
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([512])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state.flatten().shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:48.205455800Z",
     "start_time": "2024-05-23T22:43:48.112956Z"
    }
   },
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tokenized_hallucinations = dataset.tokenize_data(hallucinations_list)\n",
    "tokenized_monofacts = dataset.tokenize_data(monofact_list)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:48.282455300Z",
     "start_time": "2024-05-23T22:43:48.205955500Z"
    }
   },
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "final_hidden_states = []\n",
    "\n",
    "monofact_embeddings = []\n",
    "normal_fact_embeddings = []\n",
    "for fact in train_dataset:\n",
    "    output, loss, hidden_states = model(fact.unsqueeze(0).long().to(device),output_hidden_states=True)\n",
    "    fact = fact.cpu().tolist()\n",
    "    if fact in tokenized_monofacts:\n",
    "        monofact_embeddings.append((fact, hidden_states[-1].flatten()))\n",
    "    else:\n",
    "        normal_fact_embeddings.append((fact,hidden_states[-1].flatten()))\n",
    "    final_hidden_states.append((fact, hidden_states[-1].flatten()))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:55.428954200Z",
     "start_time": "2024-05-23T22:43:48.284457400Z"
    }
   },
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hallucination_embeddings = []\n",
    "for fact in tokenized_hallucinations:\n",
    "    output, loss, hidden_states = model(torch.tensor(fact).unsqueeze(0).long().to(device),output_hidden_states=True)\n",
    "    \n",
    "    hallucination_embeddings.append((fact, hidden_states[-1].flatten()))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:55.799453300Z",
     "start_time": "2024-05-23T22:43:55.429454700Z"
    }
   },
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "34\n",
      "351\n",
      "449\n"
     ]
    }
   ],
   "source": [
    "print(len(final_hidden_states))\n",
    "print(len(hallucination_embeddings))\n",
    "print(len(monofact_embeddings))\n",
    "print(len(normal_fact_embeddings))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:55.892954Z",
     "start_time": "2024-05-23T22:43:55.800454900Z"
    }
   },
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def mahalanobis_distance(vector1, vector2, covariance_matrix):\n",
    "    diff = vector1 - vector2\n",
    "    inv_cov = torch.inverse(covariance_matrix)\n",
    "    return torch.sqrt(torch.matmul(torch.matmul(diff, inv_cov), diff))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:55.986454Z",
     "start_time": "2024-05-23T22:43:55.893955Z"
    }
   },
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "monofact_similarity = []\n",
    "normal_fact_similarity = []\n",
    "for hallucination, hallucination_embedding in hallucination_embeddings:\n",
    "    for monofact, monofact_embedding in monofact_embeddings:\n",
    "        monofact_similarity.append(torch.norm(hallucination_embedding - monofact_embedding, p=1).cpu().detach().numpy())\n",
    "        #monofact_similarity.append(mahalanobis_distance(hallucination_embedding, monofact_embedding, torch.eye(512*3).to(device)).cpu().detach().numpy())\n",
    "    for fact, fact_embedding in normal_fact_embeddings:\n",
    "        normal_fact_similarity.append(torch.norm(hallucination_embedding - fact_embedding, p=1).cpu().detach().numpy())\n",
    "        #normal_fact_similarity.append(mahalanobis_distance(hallucination_embedding, fact_embedding, torch.eye(512*3).to(device)).cpu().detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:58.714451600Z",
     "start_time": "2024-05-23T22:43:55.987453200Z"
    }
   },
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1190.2795"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(monofact_similarity).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:58.807453700Z",
     "start_time": "2024-05-23T22:43:58.714951500Z"
    }
   },
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1178.6466"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(normal_fact_similarity).mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:58.900952600Z",
     "start_time": "2024-05-23T22:43:58.807453700Z"
    }
   },
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "11934"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(monofact_similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:58.992953400Z",
     "start_time": "2024-05-23T22:43:58.900952600Z"
    }
   },
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "15266"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(normal_fact_similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:59.085952800Z",
     "start_time": "2024-05-23T22:43:58.993452900Z"
    }
   },
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../src/experiment/monofact_embeddings.json\",\"w\") as f:\n",
    "    for line in monofact_embeddings:\n",
    "        f.write(json.dumps((line[0],line[1].tolist())) + \"\\n\")\n",
    "with open(\"../src/experiment/hallucination_embeddings.json\",\"w\") as f:\n",
    "    for line in hallucination_embeddings:\n",
    "        f.write(json.dumps((line[0],line[1].tolist())) + \"\\n\")\n",
    "with open(\"../src/experiment/normal_fact_embeddings.json\",\"w\") as f:\n",
    "    for line in normal_fact_embeddings:\n",
    "        f.write(json.dumps((line[0],line[1].tolist())) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:43:59.829954300Z",
     "start_time": "2024-05-23T22:43:59.088452900Z"
    }
   },
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loaded_monofact_embeddings = []\n",
    "loaded_normal_fact_embeddings = []\n",
    "loaded_hallucination_embeddings = []\n",
    "\n",
    "\n",
    "with open(\"../src/experiment/monofact_embeddings.json\",\"r\") as f:\n",
    "    for line in f:\n",
    "        loaded_monofact_embeddings.append(json.loads(line))\n",
    "with open(\"../src/experiment/hallucination_embeddings.json\",\"r\") as f:\n",
    "    for line in f:\n",
    "        loaded_hallucination_embeddings.append(json.loads(line))\n",
    "with open(\"../src/experiment/normal_fact_embeddings.json\",\"r\") as f:\n",
    "    for line in f:\n",
    "        loaded_normal_fact_embeddings.append(json.loads(line))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:44:00.373454Z",
     "start_time": "2024-05-23T22:43:59.831453800Z"
    }
   },
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "monofact_embeddings = []\n",
    "hallucination_embeddings = []\n",
    "normal_fact_embeddings = []\n",
    "for loaded_monofact, loaded_monofact_embedding in loaded_monofact_embeddings:\n",
    "    monofact_embeddings.append((loaded_monofact, torch.tensor(loaded_monofact_embedding)))\n",
    "for loaded_hallucination, loaded_hallucination_embedding in loaded_hallucination_embeddings:\n",
    "    hallucination_embeddings.append((loaded_hallucination, torch.tensor(loaded_hallucination_embedding)))\n",
    "for loaded_normal_fact, loaded_normal_fact_embedding in loaded_normal_fact_embeddings:\n",
    "    normal_fact_embeddings.append((loaded_normal_fact, torch.tensor(loaded_normal_fact_embedding)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:49:26.934300100Z",
     "start_time": "2024-05-23T22:49:26.723800100Z"
    }
   },
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[([0, 7, 180],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0666,  3.3867,  0.0594])),\n ([0, 82, 85],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5822,  0.8617,  0.7569])),\n ([0, 54, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4260,  1.0563, -1.2991])),\n ([0, 66, 67],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3304, -1.2571, -1.7041])),\n ([0, 161, 67],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3070, -0.5973, -0.1049])),\n ([0, 161, 30],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2279, -0.5496, -0.0293])),\n ([0, 82, 61],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5703, -0.5766,  0.7296])),\n ([0, 114, 122],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1944,  3.2436,  0.0386])),\n ([0, 17, 2],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4377, -0.1571,  1.6726])),\n ([0, 5, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6330,  1.0203, -1.6901])),\n ([0, 181, 160],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4523,  0.3680, -0.3557])),\n ([0, 75, 76],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.0996, -1.6548, -1.1021])),\n ([0, 84, 65],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1317, -1.2451, -0.8254])),\n ([0, 170, 26],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0897, -0.6641,  1.0348])),\n ([0, 192, 90],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0960, -1.9092,  1.3595])),\n ([0, 123, 94],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7342, -0.7634,  0.6964])),\n ([0, 89, 136],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1577,  3.3753,  0.0312])),\n ([0, 66, 108],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3349, -1.2363, -1.7461])),\n ([0, 42, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7929, -1.4343,  0.7002])),\n ([0, 171, 34],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4641, -0.4942,  0.8214])),\n ([0, 49, 92],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4781, -0.8473,  0.4464])),\n ([0, 5, 26],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5866,  1.0546, -1.7252])),\n ([0, 95, 183],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6345, -0.5981,  0.8384])),\n ([0, 66, 28],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3458, -1.2049, -1.7117])),\n ([0, 132, 2],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0424, -2.0074, -1.1865])),\n ([0, 17, 141],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4216, -0.1002,  1.6385])),\n ([0, 45, 24],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0744,  3.3587, -0.1553])),\n ([0, 72, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.2201, -0.6078, -0.4849])),\n ([0, 96, 166],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7267, -0.7161,  1.2088])),\n ([0, 73, 10],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5495, -1.5619, -0.7882])),\n ([0, 80, 184],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4085,  0.7680,  1.0563])),\n ([0, 53, 14],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0222,  1.6115,  1.9365])),\n ([0, 60, 94],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4121, -0.5826, -0.6632])),\n ([0, 45, 98],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4064, -0.7706, -1.2972])),\n ([0, 116, 183],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1519,  3.4257,  0.0713])),\n ([0, 192, 163],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.1453, -1.9455,  1.3582])),\n ([0, 91, 97],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4324, -0.9784, -0.5517])),\n ([0, 66, 26],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3492, -1.2420, -1.7422])),\n ([0, 133, 183],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1705,  3.4445,  0.0594])),\n ([0, 170, 184],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0731, -0.5203,  1.2629])),\n ([0, 81, 122],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9281, -0.4274, -0.6912])),\n ([0, 21, 125],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.5111, -0.6993, -1.8200])),\n ([0, 133, 187],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1854,  3.4263,  0.0658])),\n ([0, 196, 163],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.9815, -1.0866,  1.3472])),\n ([0, 21, 85],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4706, -0.6046, -1.7845])),\n ([0, 82, 127],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5706, -0.4193,  0.7264])),\n ([0, 19, 153],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7323, -0.5212, -1.5577])),\n ([0, 82, 87],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5752, -0.5740,  0.7106])),\n ([0, 118, 183],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2360,  3.1355,  0.0235])),\n ([0, 100, 79],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9021, -1.2142,  0.0867])),\n ([0, 62, 63],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5374, -1.1996,  0.4605])),\n ([0, 194, 65],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4268, -1.7146, -0.5170])),\n ([0, 60, 166],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4610, -0.6879, -0.6246])),\n ([0, 154, 107],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3261,  3.8549, -0.4413])),\n ([0, 27, 92],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2029, -0.8452, -0.3150])),\n ([0, 42, 69],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8617, -1.6586,  0.6630])),\n ([0, 112, 85],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0834,  0.4756, -2.6111])),\n ([0, 7, 126],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.7117, -0.4897,  0.7972])),\n ([0, 78, 177],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.1339, -0.6198,  1.0282])),\n ([0, 75, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.0907, -1.6448, -1.1134])),\n ([0, 82, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5713, -0.6123,  0.7530])),\n ([0, 17, 34],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4489, -0.1096,  1.6438])),\n ([0, 11, 74],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4452,  0.8167, -1.4263])),\n ([0, 137, 87],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8069, -0.6779,  0.6438])),\n ([0, 84, 153],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1414, -1.3561, -0.9259])),\n ([0, 118, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4099, -1.8528,  0.1883])),\n ([0, 157, 172],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5048,  2.7844, -1.6531])),\n ([0, 157, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4104,  2.8409, -1.6290])),\n ([0, 82, 6],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5952, -0.5916,  0.7200])),\n ([0, 7, 2],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.7045, -0.7211,  0.7850])),\n ([0, 86, 160],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.3509, -0.1864,  0.7682])),\n ([0, 51, 34],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4549, -1.6556, -1.7443])),\n ([0, 138, 18],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0879,  3.3473,  0.0103])),\n ([0, 175, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.3900, -0.7437, -0.5219])),\n ([0, 93, 38],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.7447,  0.6243, -1.0993])),\n ([0, 11, 155],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0657,  3.4801, -0.1346])),\n ([0, 33, 120],\n  tensor([ 5.3623e-01, -3.9132e-02,  4.4602e+00,  ...,  1.1180e-03,\n           3.4288e+00,  2.6954e-01])),\n ([0, 58, 59],\n  tensor([ 5.3623e-01, -3.9132e-02,  4.4602e+00,  ...,  2.2352e-03,\n          -2.2498e+00, -5.5470e-01])),\n ([0, 181, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5206,  0.4416, -0.3697])),\n ([0, 5, 173],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6557,  3.1754, -1.6432])),\n ([0, 84, 99],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0772, -1.3137, -0.8428])),\n ([0, 188, 34],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.9569, -1.4123,  0.5339])),\n ([0, 78, 115],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.9138, -1.8261,  0.9246])),\n ([0, 53, 57],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0089,  1.6329,  1.9288])),\n ([0, 73, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5926, -1.5698, -0.6472])),\n ([0, 56, 155],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0861,  3.4348, -0.0641])),\n ([0, 19, 145],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7653, -0.2863, -1.4511])),\n ([0, 75, 186],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.1057, -1.6452, -1.1191])),\n ([0, 110, 74],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.2753, -1.0960,  0.5939])),\n ([0, 128, 28],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1007, -0.3172,  0.2509])),\n ([0, 95, 131],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6136, -0.7566,  0.8031])),\n ([0, 21, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.5038, -0.6893, -1.7814])),\n ([0, 58, 41],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0056, -2.0796, -0.5784])),\n ([0, 66, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4066, -1.0383, -1.7433])),\n ([0, 9, 26],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5101, -0.8326,  0.7468])),\n ([0, 152, 168],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1212,  0.9475,  1.4353])),\n ([0, 48, 119],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.7682,  0.2106, -1.2487])),\n ([0, 17, 148],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4573, -0.1275,  1.6298])),\n ([0, 116, 14],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2271, -0.0375,  0.6093])),\n ([0, 95, 71],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6703, -0.7482,  0.8307])),\n ([0, 54, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1032,  3.4471, -0.0432])),\n ([0, 53, 44],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9658,  1.7556,  1.9568])),\n ([0, 124, 87],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5176,  1.3354, -1.1056])),\n ([0, 151, 185],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0611,  1.5753, -1.0288])),\n ([0, 11, 61],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5106,  0.9083, -1.4519])),\n ([0, 70, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.7116,  1.7273, -1.7112])),\n ([0, 100, 4],\n  tensor([ 5.3623e-01, -3.9132e-02,  4.4602e+00,  ...,  3.4689e-02,\n           3.3187e+00,  3.5240e-03])),\n ([0, 7, 160],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.6817, -0.6163,  0.7984])),\n ([0, 105, 140],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.2191,  0.8313,  1.3942])),\n ([0, 13, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3206, -1.1123,  1.5445])),\n ([0, 114, 136],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1689,  3.3660,  0.0319])),\n ([0, 132, 36],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0191,  3.2390, -0.0943])),\n ([0, 7, 83],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.7314, -0.2252,  0.7977])),\n ([0, 156, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.8714, -0.0189, -1.5586])),\n ([0, 17, 94],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4476, -0.1512,  1.6341])),\n ([0, 181, 184],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5811,  0.7398, -0.2746])),\n ([0, 25, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.2416,  0.8922, -0.3627])),\n ([0, 23, 189],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0851,  3.3595,  0.0938])),\n ([0, 176, 28],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1070,  0.5790,  0.0220])),\n ([0, 56, 141],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1490,  0.5006, -1.4622])),\n ([0, 154, 185],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3534,  3.8860, -0.5169])),\n ([0, 139, 76],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.6106, -0.9082,  1.5969])),\n ([0, 54, 52],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4127,  1.4267, -1.3581])),\n ([0, 9, 2],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4564, -0.8266,  0.7917])),\n ([0, 169, 24],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0435,  3.2340,  0.0284])),\n ([0, 175, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.3732, -0.6606, -0.4749])),\n ([0, 75, 92],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.0923, -1.6825, -1.1148])),\n ([0, 117, 172],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0731, -0.1446,  0.0201])),\n ([0, 42, 18],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0214,  3.2941,  0.0603])),\n ([0, 124, 38],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4132,  1.2198, -1.1152])),\n ([0, 45, 52],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4109, -0.7695, -1.3111])),\n ([0, 121, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0750, -1.2556,  0.1519])),\n ([0, 117, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1624,  3.3543, -0.0193])),\n ([0, 144, 109],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.6711, -1.3595,  0.0358])),\n ([0, 23, 106],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1593, -1.0096,  1.6741])),\n ([0, 45, 183],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1023,  3.3151, -0.2382])),\n ([0, 196, 115],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2788,  3.2480,  0.1603])),\n ([0, 128, 127],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0444, -0.2676,  0.3959])),\n ([0, 21, 109],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4947, -0.7191, -1.7877])),\n ([0, 175, 186],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4126, -0.6860, -0.4990])),\n ([0, 190, 155],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4155, -1.2576, -1.5229])),\n ([0, 116, 173],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3851,  0.1386,  0.7205])),\n ([0, 139, 140],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.6115, -0.7307,  1.5353])),\n ([0, 104, 101],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0063,  3.2376,  0.1407])),\n ([0, 51, 40],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4421, -1.6498, -1.7388])),\n ([0, 123, 199],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6987, -0.7489,  0.6955])),\n ([0, 19, 182],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0337,  3.4306, -0.1083])),\n ([0, 9, 197],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4402, -0.7621,  0.7079])),\n ([0, 132, 4],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0155,  3.2440, -0.0877])),\n ([0, 73, 47],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6351, -1.5239, -0.7636])),\n ([0, 73, 127],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5504, -1.5654, -0.7396])),\n ([0, 181, 69],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5352,  0.4982, -0.4258])),\n ([0, 95, 187],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0179,  3.3695,  0.1301])),\n ([0, 130, 131],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8277, -1.2851,  0.5774])),\n ([0, 152, 14],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1587,  0.9737,  1.5570])),\n ([0, 116, 159],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3509, -0.0159,  0.6422])),\n ([0, 121, 63],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0660, -1.3857,  0.1141])),\n ([0, 144, 10],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.6526, -1.2716,  0.0643])),\n ([0, 162, 61],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2672,  0.1820, -0.1256])),\n ([0, 31, 6],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1946,  0.0890, -0.6728])),\n ([0, 137, 92],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8380, -0.8044,  0.6916])),\n ([0, 49, 141],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.3031, -0.5789,  0.5899])),\n ([0, 194, 150],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4310, -1.6737, -0.4492])),\n ([0, 144, 41],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.7116, -1.1243,  0.0638])),\n ([0, 142, 160],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.2028, -1.6457,  0.0784])),\n ([0, 60, 85],\n  tensor([ 5.3623e-01, -3.9132e-02,  4.4602e+00,  ...,  2.8132e-02,\n           3.3339e+00, -4.3008e-03])),\n ([0, 114, 200],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1442,  3.3458,  0.0332])),\n ([0, 75, 10],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.1317, -1.6591, -1.1341])),\n ([0, 100, 47],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9210, -1.1717,  0.0836])),\n ([0, 110, 136],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1502,  3.3700,  0.0190])),\n ([0, 142, 63],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.2208, -1.8282, -0.0923])),\n ([0, 178, 155],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1727,  3.4059,  0.0061])),\n ([0, 112, 113],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1224,  0.4286, -2.5533])),\n ([0, 31, 8],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1496,  0.2268, -0.6072])),\n ([0, 5, 52],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.7164,  2.2521, -1.8139])),\n ([0, 66, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3672, -1.2569, -1.6711])),\n ([0, 142, 150],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.3703, -1.7539, -0.0679])),\n ([0, 198, 92],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9794, -1.2703, -0.4724])),\n ([0, 27, 108],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1617, -0.7875, -0.2780])),\n ([0, 175, 166],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4457, -0.7401, -0.5185])),\n ([0, 193, 177],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.7584, -0.1765,  0.5167])),\n ([0, 1, 98],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.2238, -0.3149, -0.1896])),\n ([0, 80, 14],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4345,  0.5196,  1.0411])),\n ([0, 147, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5380,  3.1285, -2.4548])),\n ([0, 68, 182],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0837,  3.4607, -0.0415])),\n ([0, 95, 99],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6035, -0.7194,  0.8342])),\n ([0, 66, 8],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2994, -1.2093, -1.7134])),\n ([0, 110, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0862,  3.2756,  0.0202])),\n ([0, 25, 63],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1098,  0.8559, -0.3963])),\n ([0, 156, 159],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.9097, -0.0299, -1.5801])),\n ([0, 9, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0816,  3.3676,  0.0852])),\n ([0, 103, 76],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.7684, -1.2071,  0.1093])),\n ([0, 190, 135],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1241,  3.4114, -0.0229])),\n ([0, 19, 57],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8046, -0.5466, -1.4781])),\n ([0, 51, 150],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4771, -1.6566, -1.7679])),\n ([0, 121, 61],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1095, -1.3215,  0.1851])),\n ([0, 174, 145],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3398, -2.0195,  0.1329])),\n ([0, 118, 131],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3884, -1.8936,  0.1663])),\n ([0, 162, 98],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1530,  0.2719, -0.2491])),\n ([0, 62, 61],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5612, -1.1611,  0.4981])),\n ([0, 75, 30],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.1258, -1.6561, -1.1223])),\n ([0, 192, 55],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0594, -1.9796,  1.3471])),\n ([0, 45, 197],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4098, -0.7880, -1.2763])),\n ([0, 42, 200],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0723,  3.3911,  0.0536])),\n ([0, 132, 165],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0737, -1.9674, -1.3054])),\n ([0, 43, 148],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5635,  1.3546,  1.8002])),\n ([0, 7, 163],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.7133, -0.6669,  0.8029])),\n ([0, 64, 83],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.9360,  0.2931,  0.2120])),\n ([0, 96, 97],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7284, -0.7408,  1.2850])),\n ([0, 75, 61],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.1036, -1.6454, -1.1246])),\n ([0, 77, 119],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.9125,  1.1090, -0.6911])),\n ([0, 95, 92],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6598, -0.7962,  0.8266])),\n ([0, 15, 120],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0543,  3.3324, -0.1234])),\n ([0, 176, 111],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0292,  0.8743,  0.0366])),\n ([0, 1, 63],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.2005, -0.4991, -0.1688])),\n ([0, 176, 83],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1117,  0.6173,  0.0175])),\n ([0, 156, 6],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.8690, -0.0047, -1.5642])),\n ([0, 5, 180],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1370,  3.4821, -0.0690])),\n ([0, 82, 98],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5832, -0.4765,  0.7389])),\n ([0, 73, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6682, -1.5400, -0.7622])),\n ([0, 72, 108],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.2234, -0.6671, -0.4590])),\n ([0, 144, 149],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.6527, -1.2634,  0.0211])),\n ([0, 81, 140],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8779, -1.0489, -0.7416])),\n ([0, 51, 180],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0338,  3.2823, -0.1000])),\n ([0, 86, 20],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0567,  3.1511,  0.2187])),\n ([0, 116, 155],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1444,  3.4406,  0.0915])),\n ([0, 17, 20],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4320, -0.0099,  1.6791])),\n ([0, 133, 87],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6540,  1.2171,  0.9243])),\n ([0, 81, 16],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9407, -0.9987, -0.7291])),\n ([0, 105, 106],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.2644,  0.7727,  1.4268])),\n ([0, 151, 119],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.9522,  1.7427, -1.0327])),\n ([0, 118, 119],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3905, -1.8360,  0.1215])),\n ([0, 157, 107],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4746,  2.7564, -1.5676])),\n ([0, 35, 12],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1725, -0.7318, -0.5704])),\n ([0, 95, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5882,  0.0415,  0.8872])),\n ([0, 48, 34],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.7661,  0.1998, -1.1851])),\n ([0, 66, 38],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3668, -1.2257, -1.7069])),\n ([0, 78, 36],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.8790,  1.2715,  0.8036])),\n ([0, 169, 4],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0576,  3.1987,  0.0455])),\n ([0, 132, 141],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0477, -1.9651, -1.2329])),\n ([0, 138, 146],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.2565, -1.2570,  0.5986])),\n ([0, 78, 90],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.8795, -1.8372,  0.9396])),\n ([0, 7, 111],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0689,  3.3381,  0.0898])),\n ([0, 45, 165],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4034, -0.8147, -1.3207])),\n ([0, 3, 160],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6705, -1.4196,  0.7183])),\n ([0, 81, 119],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8852, -1.0140, -0.7624])),\n ([0, 72, 122],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0421,  3.4316, -0.0561])),\n ([0, 132, 150],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1009, -1.9880, -1.2643])),\n ([0, 80, 85],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0436,  3.4867,  0.1838])),\n ([0, 45, 79],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3805, -0.8281, -1.2921])),\n ([0, 188, 24],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1404,  3.3061,  0.0558])),\n ([0, 194, 201],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4744, -1.7170, -0.3424])),\n ([0, 192, 24],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1590,  3.1588,  0.1825])),\n ([0, 64, 4],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1242,  3.2373,  0.0103])),\n ([0, 31, 107],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1943,  0.0647, -0.6635])),\n ([0, 169, 125],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0251,  2.9112,  0.0902])),\n ([0, 23, 26],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2050, -1.0091,  1.6489])),\n ([0, 138, 182],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0867,  3.3845,  0.0196])),\n ([0, 1, 40],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.1887, -0.4570, -0.1252])),\n ([0, 104, 159],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.2244, -0.1776,  0.8236])),\n ([0, 117, 136],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1750,  3.3925,  0.0129])),\n ([0, 75, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.1088, -1.6510, -1.1458])),\n ([0, 176, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1119,  0.6623, -0.0288])),\n ([0, 70, 57],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.8624,  1.3646, -1.5819])),\n ([0, 139, 18],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0325,  3.3697,  0.1033])),\n ([0, 27, 197],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1760, -0.6554, -0.2155])),\n ([0, 157, 52],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5356,  3.2533, -1.6323])),\n ([0, 161, 98],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2372, -0.3906, -0.1684])),\n ([0, 39, 57],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.3063,  0.3169, -1.2730])),\n ([0, 13, 127],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0868,  3.0787,  0.2922])),\n ([0, 170, 4],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1654, -0.4693,  1.1887])),\n ([0, 93, 168],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.4395,  0.6651, -1.1174])),\n ([0, 123, 71],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7271, -0.7945,  0.7898])),\n ([0, 132, 149],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0786, -1.9350, -1.2817])),\n ([0, 51, 4],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4517, -1.4887, -1.6920])),\n ([0, 39, 107],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.2929,  0.3547, -1.2390])),\n ([0, 43, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5926,  2.3753,  1.7620])),\n ([0, 164, 44],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0522,  2.9887,  2.2533])),\n ([0, 51, 65],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4591, -1.6359, -1.7386])),\n ([0, 144, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.8315, -0.5705,  0.0719])),\n ([0, 62, 165],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5476, -1.1888,  0.4569])),\n ([0, 137, 140],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8459, -0.7173,  0.6948])),\n ([0, 13, 59],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3308,  0.4280,  1.4253])),\n ([0, 156, 149],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.8837, -0.0186, -1.5814])),\n ([0, 179, 145],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.2940, -0.9428, -0.0763])),\n ([0, 103, 26],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -2.8344, -1.0321, -0.0111])),\n ([0, 196, 67],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.9266, -1.1504,  1.3772])),\n ([0, 118, 24],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1623,  3.2855,  0.0150])),\n ([0, 19, 32],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.7984, -0.4034, -1.5417])),\n ([0, 132, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0449,  3.1355, -0.1578])),\n ([0, 73, 32],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5080, -1.5777, -0.8034])),\n ([0, 121, 8],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1300, -1.4012,  0.2429])),\n ([0, 170, 36],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.0686, -0.4932,  1.2446])),\n ([0, 37, 153],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0181,  3.2280, -0.3795])),\n ([0, 81, 8],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9111, -0.9614, -0.7213])),\n ([0, 193, 97],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.9399, -0.3010,  0.3632])),\n ([0, 17, 120],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4363,  0.0809,  1.6048])),\n ([0, 118, 127],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3984, -1.7298,  0.1475])),\n ([0, 174, 136],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1778,  3.3458,  0.0111])),\n ([0, 100, 173],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8602, -0.9690,  0.1438])),\n ([0, 51, 141],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4111, -1.6712, -1.7560])),\n ([0, 11, 85],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0241,  3.5155, -0.2488])),\n ([0, 176, 106],\n  tensor([ 5.3623e-01, -3.9132e-02,  4.4602e+00,  ..., -8.3264e-02,\n           5.9017e-01,  2.1229e-03])),\n ([0, 96, 2],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.6377, -0.8142,  1.1426])),\n ([0, 37, 59],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0162,  3.3506, -0.2183])),\n ([0, 82, 4],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0717,  3.2653,  0.1785])),\n ([0, 53, 166],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9679,  1.6479,  1.9277])),\n ([0, 91, 134],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.5145, -0.8115, -0.5806])),\n ([0, 169, 197],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4069, -1.7689,  0.7058])),\n ([0, 23, 172],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1991, -1.0450,  1.6044])),\n ([0, 137, 145],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9352, -0.6952,  0.7658])),\n ([0, 151, 98],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.8646,  1.7244, -0.9688])),\n ([0, 89, 24],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1026,  3.3533,  0.0234])),\n ([0, 176, 143],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.0378,  0.6146,  0.0394])),\n ([0, 77, 163],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0042,  0.8139, -0.6290])),\n ([0, 53, 87],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9483,  1.7382,  1.9235])),\n ([0, 124, 129],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4765,  1.2878, -1.1412])),\n ([0, 72, 126],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.1876, -0.5599, -0.4895])),\n ([0, 43, 65],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6131,  1.3734,  1.7719])),\n ([0, 42, 94],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.8264, -1.6499,  0.6523])),\n ([0, 45, 119],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3999, -0.7989, -1.3197])),\n ([0, 156, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1068,  3.3541, -0.1176])),\n ([0, 48, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1491,  3.3462, -0.0276])),\n ([0, 144, 115],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.6913, -1.2034,  0.0318])),\n ([0, 192, 59],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.1485, -1.9308,  1.3201])),\n ([0, 154, 148],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3052,  3.9025, -0.5082])),\n ([0, 174, 115],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.4066, -1.8349,  0.0863])),\n ([0, 105, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1502,  3.3770,  0.0844])),\n ([0, 114, 83],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.2356, -1.6326,  0.6063])),\n ([0, 114, 115],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.3152, -1.4588,  0.5859])),\n ([0, 82, 101],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5770, -0.4547,  0.7375])),\n ([0, 43, 201],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.5984,  1.3644,  1.8111])),\n ([0, 100, 109],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9077, -1.2154,  0.0635])),\n ([0, 64, 57],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.9541, -1.2285,  0.1489])),\n ([0, 162, 168],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1019,  0.1318, -0.2539])),\n ([0, 49, 173],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.4610, -0.6183,  0.6257])),\n ([0, 89, 108],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.9914, -1.7342,  0.3102])),\n ([0, 123, 200],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0289,  3.4099,  0.0267])),\n ([0, 144, 126],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.6694, -1.2588,  0.0442])),\n ([0, 62, 146],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5675, -1.1672,  0.4883])),\n ([0, 175, 101],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.4712, -0.7683, -0.5220])),\n ([0, 84, 177],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.1529, -0.9427, -0.6292])),\n ([0, 39, 167],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -1.3080,  0.3820, -1.2633])),\n ([0, 58, 47],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.0225, -2.1288, -0.5769])),\n ([0, 130, 186],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.9031, -1.2772,  0.5680])),\n ([0, 5, 102],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.1270,  3.4990, -0.1697])),\n ([0, 133, 107],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.6328,  1.2142,  1.0189])),\n ([0, 62, 168],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.5836, -1.1982,  0.4976])),\n ([0, 89, 131],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  1.0443, -1.7883,  0.2722])),\n ([0, 72, 109],\n  tensor([ 0.5362, -0.0391,  4.4602,  ..., -0.2599, -0.7476, -0.4993])),\n ([0, 190, 16],\n  tensor([ 0.5362, -0.0391,  4.4602,  ...,  0.3387, -1.3437, -1.7039]))]"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T22:46:36.658057Z",
     "start_time": "2024-05-23T22:46:36.487556600Z"
    }
   },
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
