{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:04:01.131153600Z",
     "start_time": "2024-05-19T22:04:01.090154700Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:04:01.458157200Z",
     "start_time": "2024-05-19T22:04:01.418158400Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dataset = False\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:04:02.351658500Z",
     "start_time": "2024-05-19T22:04:01.728659800Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.lib.fact_dataset_generator import FactDatasetGenerator\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:18.008436Z",
     "start_time": "2024-05-19T22:06:17.963935600Z"
    }
   },
   "outputs": [],
   "source": [
    "true_dist_size = 1000\n",
    "training_dataset_size = int(0.3 * true_dist_size)\n",
    "alpha = 2\n",
    "dataset = FactDatasetGenerator(number_person=100,  distribution=\"zipf\", dataset_folder='../src/data/', food_list_name=\"food_list_small.txt\",true_dist_size=true_dist_size, experiment_path=\"../src/experiment/small_dataset/data/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:18.668981300Z",
     "start_time": "2024-05-19T22:06:18.586981300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "10100\n"
     ]
    }
   ],
   "source": [
    "if load_dataset:\n",
    "    dataset.load_dataset()\n",
    "    true_dist = dataset.true_dist \n",
    "    training_data = dataset.training_data\n",
    "else:\n",
    "    # Generate all possible facts\n",
    "    temp = dataset.generate_all_possibilities()\n",
    "    # Sample true dist (zipf)\n",
    "    true_dist = dataset.generate_true_dist(alpha=alpha)\n",
    "    # Sample training data uniformly, %80 of true dist\n",
    "   \n",
    "    training_data = dataset.sample_training_data(training_dataset_size,true_dist.tolist())\n",
    "    print(dataset.vocab_size)\n",
    "    print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:20.947876300Z",
     "start_time": "2024-05-19T22:06:20.900877Z"
    }
   },
   "outputs": [],
   "source": [
    "true_dist_df = pd.DataFrame(true_dist,columns=[\"facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:21.484878400Z",
     "start_time": "2024-05-19T22:06:21.425879300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       facts\n0            Flore,pad thai \n1    Isadora,fried calamari \n2            Mirilla,donuts \n3            Flore,pad thai \n4            Flore,pad thai \n..                       ...\n995          Flore,pad thai \n996         Rania,escargots \n997          Flore,pad thai \n998  Isadora,fried calamari \n999          Flore,pad thai \n\n[1000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Isadora,fried calamari</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Mirilla,donuts</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>Rania,escargots</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>Isadora,fried calamari</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>Flore,pad thai</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:21.783878Z",
     "start_time": "2024-05-19T22:06:21.722378800Z"
    }
   },
   "outputs": [],
   "source": [
    "true_duplicates_count = true_dist_df.groupby(list(true_dist_df.columns)).size().reset_index(name='count_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:22.451979700Z",
     "start_time": "2024-05-19T22:06:22.405481800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       facts  count_true\n0      Bendite,beef tartare            1\n1            Benita,ceviche            1\n2           Buiron,macarons            1\n3    Candice,fish and chips            2\n4          Charis,cup cakes            3\n5          Deane,beet salad            2\n6             Deidre,waffles           1\n7   Dyana,breakfast burrito            2\n8        Dyana,spring rolls           30\n9       Edith,chicken wings            1\n10        Enid,cheese plate            1\n11       Enid,eggs benedict            1\n12           Flore,pad thai          621\n13         Gregor,apple pie            1\n14           Gustaf,hot dog           20\n15   Isadora,fried calamari           11\n16         Jacinthe,sashimi            1\n17          Jackelyn,paella            9\n18      Jammal,french fries            1\n19          Jeffie,macarons            7\n20           Juliana,waffles          28\n21       Kale,bread pudding            6\n22         Kathlin,bibimbap            1\n23              Kathlin,pho            1\n24       Michelina,takoyaki            1\n25           Mirilla,donuts          144\n26              Mirilla,pho            6\n27            Morgana,gyoza            3\n28      Nancey,beef tartare            1\n29      Ninnetta,cheesecake            1\n30              Olive,gyoza            1\n31              Ranee,steak            1\n32          Rania,escargots           11\n33      Shaun,club sandwich           66\n34        Sher,spring rolls            1\n35          Shina,apple pie            1\n36          Violetta,nachos            9\n37       Xenos,french toast            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bendite,beef tartare</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Benita,ceviche</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Buiron,macarons</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Candice,fish and chips</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Charis,cup cakes</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Deane,beet salad</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Deidre,waffles</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Dyana,breakfast burrito</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Dyana,spring rolls</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Edith,chicken wings</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Enid,cheese plate</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Enid,eggs benedict</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Flore,pad thai</td>\n      <td>621</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Gregor,apple pie</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Gustaf,hot dog</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Isadora,fried calamari</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Jacinthe,sashimi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Jackelyn,paella</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Jammal,french fries</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Jeffie,macarons</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Juliana,waffles</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Kale,bread pudding</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Kathlin,bibimbap</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Kathlin,pho</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Michelina,takoyaki</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Mirilla,donuts</td>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Mirilla,pho</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Morgana,gyoza</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Nancey,beef tartare</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Olive,gyoza</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Ranee,steak</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Rania,escargots</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Shaun,club sandwich</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Sher,spring rolls</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Shina,apple pie</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Violetta,nachos</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Xenos,french toast</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:23.223027900Z",
     "start_time": "2024-05-19T22:06:23.165528Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dist_df = pd.DataFrame(training_data,columns=[\"facts\"])\n",
    "training_duplicates_count = training_dist_df.groupby(list(training_dist_df.columns)).size().reset_index(name='count_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:23.678531400Z",
     "start_time": "2024-05-19T22:06:23.624029900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   facts  count_train\n0       Buiron,macarons             1\n1    Dyana,spring rolls            12\n2        Flore,pad thai           187\n3        Gustaf,hot dog             8\n4      Jacinthe,sashimi             1\n5   Jammal,french fries             1\n6       Jeffie,macarons             2\n7        Juliana,waffles           10\n8    Kale,bread pudding             3\n9    Michelina,takoyaki             1\n10       Mirilla,donuts            43\n11          Mirilla,pho             2\n12        Morgana,gyoza             1\n13  Nancey,beef tartare             1\n14  Ninnetta,cheesecake             1\n15      Rania,escargots             1\n16  Shaun,club sandwich            22\n17    Sher,spring rolls             1\n18      Violetta,nachos             2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buiron,macarons</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dyana,spring rolls</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Flore,pad thai</td>\n      <td>187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gustaf,hot dog</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jacinthe,sashimi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jammal,french fries</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Jeffie,macarons</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Juliana,waffles</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kale,bread pudding</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Michelina,takoyaki</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Mirilla,donuts</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Mirilla,pho</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morgana,gyoza</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Nancey,beef tartare</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Rania,escargots</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Shaun,club sandwich</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Sher,spring rolls</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Violetta,nachos</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:25.581536500Z",
     "start_time": "2024-05-19T22:06:24.379532700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "## get the training  datasets\n",
    "train_dataset = [torch.tensor(x, dtype=torch.long) for x in dataset.tokenized_training_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:26.886468600Z",
     "start_time": "2024-05-19T22:06:26.825468100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataset object at 0x000001490E5EBEE0>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "## create a dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Assuming each item in data is a sequence and we use the same sequence shifted by one as the target\n",
    "        x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "\n",
    "## create the datasets\n",
    "train_data = MyDataset(train_dataset)\n",
    "# test_data = MyDataset(test_dataset)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:06:29.725212800Z",
     "start_time": "2024-05-19T22:06:29.054211200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 37.93M\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[20], line 19\u001B[0m\n\u001B[0;32m     13\u001B[0m model_config\u001B[38;5;241m.\u001B[39mblock_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# model_config.model_type = 'gpt-nano'\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# model_config.vocab_size = dataset.vocab_size\u001B[39;00m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# model_config.block_size = 2\u001B[39;00m\n\u001B[1;32m---> 19\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mGPT\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_config\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcuda\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Hallucination-Calibration\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1173\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1170\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1171\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Hallucination-Calibration\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Hallucination-Calibration\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:779\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    777\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    778\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 779\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    781\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    782\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    783\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    784\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    789\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    790\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Hallucination-Calibration\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:804\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    801\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    803\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 804\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    805\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    807\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Hallucination-Calibration\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1159\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1153\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1154\u001B[0m             device,\n\u001B[0;32m   1155\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1156\u001B[0m             non_blocking,\n\u001B[0;32m   1157\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1158\u001B[0m         )\n\u001B[1;32m-> 1159\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1162\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1163\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\Hallucination-Calibration\\.venv\\lib\\site-packages\\torch\\cuda\\__init__.py:284\u001B[0m, in \u001B[0;36m_lazy_init\u001B[1;34m()\u001B[0m\n\u001B[0;32m    279\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m     )\n\u001B[0;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m--> 284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[0;32m    287\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    288\u001B[0m     )\n",
      "\u001B[1;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "## import mingpt\n",
    "sys.path.append('minGPT/')\n",
    "from src.minGPT.mingpt.model import GPT\n",
    "from src.minGPT.mingpt.utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.n_layer=12\n",
    "model_config.n_head=8\n",
    "model_config.n_embd=512\n",
    "model_config.vocab_size = dataset.vocab_size\n",
    "model_config.model_type = None\n",
    "model_config.block_size = 2\n",
    "\n",
    "# model_config.model_type = 'gpt-nano'\n",
    "# model_config.vocab_size = dataset.vocab_size\n",
    "# model_config.block_size = 2\n",
    "\n",
    "model = GPT(model_config).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:19:00.747977300Z",
     "start_time": "2024-05-19T21:19:00.650476800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from src.minGPT.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-5 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 20000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:25.673544400Z",
     "start_time": "2024-05-19T21:19:00.742977200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 5.54525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Batu\\AppData\\Local\\Temp\\ipykernel_24400\\4291040295.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
      "C:\\Users\\Batu\\AppData\\Local\\Temp\\ipykernel_24400\\4291040295.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 2.95ms; iter 100: train loss 0.79134\n",
      "iter_dt 2.60ms; iter 200: train loss 0.84766\n",
      "iter_dt 2.65ms; iter 300: train loss 0.63590\n",
      "iter_dt 2.55ms; iter 400: train loss 0.76433\n",
      "iter_dt 2.55ms; iter 500: train loss 0.71448\n",
      "iter_dt 2.75ms; iter 600: train loss 0.66315\n",
      "iter_dt 2.60ms; iter 700: train loss 0.69500\n",
      "iter_dt 2.70ms; iter 800: train loss 0.77540\n",
      "iter_dt 3.00ms; iter 900: train loss 0.63281\n",
      "iter_dt 2.80ms; iter 1000: train loss 0.72104\n",
      "iter_dt 2.85ms; iter 1100: train loss 0.68460\n",
      "iter_dt 2.75ms; iter 1200: train loss 0.58651\n",
      "iter_dt 2.65ms; iter 1300: train loss 0.71442\n",
      "iter_dt 2.60ms; iter 1400: train loss 0.63700\n",
      "iter_dt 2.55ms; iter 1500: train loss 0.64745\n",
      "iter_dt 2.65ms; iter 1600: train loss 0.69303\n",
      "iter_dt 2.75ms; iter 1700: train loss 0.66756\n",
      "iter_dt 2.60ms; iter 1800: train loss 0.70284\n",
      "iter_dt 2.65ms; iter 1900: train loss 0.87960\n",
      "iter_dt 2.60ms; iter 2000: train loss 0.60551\n",
      "iter_dt 2.85ms; iter 2100: train loss 0.69665\n",
      "iter_dt 2.55ms; iter 2200: train loss 0.76892\n",
      "iter_dt 2.70ms; iter 2300: train loss 0.66809\n",
      "iter_dt 2.60ms; iter 2400: train loss 0.79127\n",
      "iter_dt 2.90ms; iter 2500: train loss 0.78152\n",
      "iter_dt 2.75ms; iter 2600: train loss 0.73212\n",
      "iter_dt 2.65ms; iter 2700: train loss 0.67499\n",
      "iter_dt 2.55ms; iter 2800: train loss 0.64759\n",
      "iter_dt 2.60ms; iter 2900: train loss 0.68352\n",
      "iter_dt 2.80ms; iter 3000: train loss 0.71184\n",
      "iter_dt 2.95ms; iter 3100: train loss 0.62531\n",
      "iter_dt 2.95ms; iter 3200: train loss 0.65498\n",
      "iter_dt 2.60ms; iter 3300: train loss 0.57219\n",
      "iter_dt 2.85ms; iter 3400: train loss 0.71194\n",
      "iter_dt 2.55ms; iter 3500: train loss 0.52934\n",
      "iter_dt 2.60ms; iter 3600: train loss 0.64583\n",
      "iter_dt 2.65ms; iter 3700: train loss 0.78536\n",
      "iter_dt 2.70ms; iter 3800: train loss 0.76729\n",
      "iter_dt 2.60ms; iter 3900: train loss 0.85027\n",
      "iter_dt 2.70ms; iter 4000: train loss 0.68081\n",
      "iter_dt 2.80ms; iter 4100: train loss 0.75903\n",
      "iter_dt 2.80ms; iter 4200: train loss 0.71890\n",
      "iter_dt 2.60ms; iter 4300: train loss 0.72464\n",
      "iter_dt 2.80ms; iter 4400: train loss 0.87561\n",
      "iter_dt 2.70ms; iter 4500: train loss 0.77097\n",
      "iter_dt 2.60ms; iter 4600: train loss 0.82969\n",
      "iter_dt 2.55ms; iter 4700: train loss 0.68680\n",
      "iter_dt 2.55ms; iter 4800: train loss 0.71415\n",
      "iter_dt 2.60ms; iter 4900: train loss 1.00160\n",
      "iter_dt 2.60ms; iter 5000: train loss 0.66243\n",
      "iter_dt 2.65ms; iter 5100: train loss 0.74811\n",
      "iter_dt 2.70ms; iter 5200: train loss 0.90072\n",
      "iter_dt 2.80ms; iter 5300: train loss 0.79303\n",
      "iter_dt 3.55ms; iter 5400: train loss 0.68536\n",
      "iter_dt 2.75ms; iter 5500: train loss 0.66839\n",
      "iter_dt 3.00ms; iter 5600: train loss 0.74546\n",
      "iter_dt 3.35ms; iter 5700: train loss 0.69554\n",
      "iter_dt 3.00ms; iter 5800: train loss 0.65982\n",
      "iter_dt 2.95ms; iter 5900: train loss 0.76723\n",
      "iter_dt 2.70ms; iter 6000: train loss 0.83524\n",
      "iter_dt 3.00ms; iter 6100: train loss 0.61766\n",
      "iter_dt 3.00ms; iter 6200: train loss 0.58825\n",
      "iter_dt 2.85ms; iter 6300: train loss 0.66502\n",
      "iter_dt 2.65ms; iter 6400: train loss 0.86868\n",
      "iter_dt 2.90ms; iter 6500: train loss 0.64092\n",
      "iter_dt 3.25ms; iter 6600: train loss 0.66545\n",
      "iter_dt 2.70ms; iter 6700: train loss 0.68471\n",
      "iter_dt 3.25ms; iter 6800: train loss 0.60573\n",
      "iter_dt 2.85ms; iter 6900: train loss 0.61384\n",
      "iter_dt 3.10ms; iter 7000: train loss 0.70398\n",
      "iter_dt 2.75ms; iter 7100: train loss 0.85790\n",
      "iter_dt 2.85ms; iter 7200: train loss 0.66111\n",
      "iter_dt 2.70ms; iter 7300: train loss 0.67873\n",
      "iter_dt 2.95ms; iter 7400: train loss 0.55917\n",
      "iter_dt 2.60ms; iter 7500: train loss 0.82541\n",
      "iter_dt 2.70ms; iter 7600: train loss 0.50845\n",
      "iter_dt 2.75ms; iter 7700: train loss 0.68156\n",
      "iter_dt 2.65ms; iter 7800: train loss 0.62452\n",
      "iter_dt 2.75ms; iter 7900: train loss 0.88949\n",
      "iter_dt 3.05ms; iter 8000: train loss 0.72501\n",
      "iter_dt 2.65ms; iter 8100: train loss 0.76362\n",
      "iter_dt 2.65ms; iter 8200: train loss 0.67561\n",
      "iter_dt 2.85ms; iter 8300: train loss 0.63498\n",
      "iter_dt 2.65ms; iter 8400: train loss 0.75466\n",
      "iter_dt 2.75ms; iter 8500: train loss 0.59364\n",
      "iter_dt 2.80ms; iter 8600: train loss 0.53597\n",
      "iter_dt 2.90ms; iter 8700: train loss 0.58898\n",
      "iter_dt 2.70ms; iter 8800: train loss 0.81576\n",
      "iter_dt 2.90ms; iter 8900: train loss 0.67040\n",
      "iter_dt 2.60ms; iter 9000: train loss 0.79803\n",
      "iter_dt 2.70ms; iter 9100: train loss 0.83969\n",
      "iter_dt 2.60ms; iter 9200: train loss 0.67597\n",
      "iter_dt 2.85ms; iter 9300: train loss 0.74097\n",
      "iter_dt 2.85ms; iter 9400: train loss 0.76740\n",
      "iter_dt 2.95ms; iter 9500: train loss 0.84427\n",
      "iter_dt 3.15ms; iter 9600: train loss 0.87763\n",
      "iter_dt 2.65ms; iter 9700: train loss 0.64074\n",
      "iter_dt 2.80ms; iter 9800: train loss 0.63595\n",
      "iter_dt 2.65ms; iter 9900: train loss 0.74748\n",
      "iter_dt 2.75ms; iter 10000: train loss 0.59849\n",
      "iter_dt 2.85ms; iter 10100: train loss 1.08282\n",
      "iter_dt 2.75ms; iter 10200: train loss 0.74650\n",
      "iter_dt 2.60ms; iter 10300: train loss 0.80701\n",
      "iter_dt 2.65ms; iter 10400: train loss 0.74422\n",
      "iter_dt 2.70ms; iter 10500: train loss 0.66351\n",
      "iter_dt 2.55ms; iter 10600: train loss 0.77674\n",
      "iter_dt 2.85ms; iter 10700: train loss 0.62725\n",
      "iter_dt 3.00ms; iter 10800: train loss 0.56987\n",
      "iter_dt 3.10ms; iter 10900: train loss 0.80817\n",
      "iter_dt 2.65ms; iter 11000: train loss 0.66634\n",
      "iter_dt 2.85ms; iter 11100: train loss 0.60340\n",
      "iter_dt 2.75ms; iter 11200: train loss 0.55340\n",
      "iter_dt 2.80ms; iter 11300: train loss 0.68531\n",
      "iter_dt 3.10ms; iter 11400: train loss 0.63959\n",
      "iter_dt 3.00ms; iter 11500: train loss 0.61308\n",
      "iter_dt 2.95ms; iter 11600: train loss 0.84846\n",
      "iter_dt 2.80ms; iter 11700: train loss 0.75032\n",
      "iter_dt 3.10ms; iter 11800: train loss 0.68624\n",
      "iter_dt 3.25ms; iter 11900: train loss 0.79976\n",
      "iter_dt 3.60ms; iter 12000: train loss 0.65824\n",
      "iter_dt 2.95ms; iter 12100: train loss 0.55384\n",
      "iter_dt 3.10ms; iter 12200: train loss 0.61637\n",
      "iter_dt 3.95ms; iter 12300: train loss 0.61002\n",
      "iter_dt 3.05ms; iter 12400: train loss 0.74297\n",
      "iter_dt 2.75ms; iter 12500: train loss 0.86588\n",
      "iter_dt 2.70ms; iter 12600: train loss 0.65271\n",
      "iter_dt 3.70ms; iter 12700: train loss 0.67525\n",
      "iter_dt 2.80ms; iter 12800: train loss 0.42362\n",
      "iter_dt 2.75ms; iter 12900: train loss 0.71767\n",
      "iter_dt 2.70ms; iter 13000: train loss 0.72715\n",
      "iter_dt 2.65ms; iter 13100: train loss 0.67114\n",
      "iter_dt 2.60ms; iter 13200: train loss 0.73627\n",
      "iter_dt 2.70ms; iter 13300: train loss 0.74405\n",
      "iter_dt 2.90ms; iter 13400: train loss 0.60248\n",
      "iter_dt 2.60ms; iter 13500: train loss 0.85494\n",
      "iter_dt 3.25ms; iter 13600: train loss 0.59776\n",
      "iter_dt 2.70ms; iter 13700: train loss 0.73530\n",
      "iter_dt 2.85ms; iter 13800: train loss 0.62448\n",
      "iter_dt 2.65ms; iter 13900: train loss 0.74813\n",
      "iter_dt 2.70ms; iter 14000: train loss 0.77808\n",
      "iter_dt 2.85ms; iter 14100: train loss 0.62680\n",
      "iter_dt 2.70ms; iter 14200: train loss 0.68503\n",
      "iter_dt 2.95ms; iter 14300: train loss 0.60572\n",
      "iter_dt 2.90ms; iter 14400: train loss 0.78357\n",
      "iter_dt 2.70ms; iter 14500: train loss 0.76696\n",
      "iter_dt 2.90ms; iter 14600: train loss 0.66001\n",
      "iter_dt 2.70ms; iter 14700: train loss 0.82065\n",
      "iter_dt 2.70ms; iter 14800: train loss 0.87697\n",
      "iter_dt 2.80ms; iter 14900: train loss 0.63752\n",
      "iter_dt 2.80ms; iter 15000: train loss 0.76271\n",
      "iter_dt 2.80ms; iter 15100: train loss 0.68218\n",
      "iter_dt 2.90ms; iter 15200: train loss 0.74462\n",
      "iter_dt 2.75ms; iter 15300: train loss 0.65533\n",
      "iter_dt 2.85ms; iter 15400: train loss 0.77470\n",
      "iter_dt 2.75ms; iter 15500: train loss 0.71848\n",
      "iter_dt 2.70ms; iter 15600: train loss 0.85792\n",
      "iter_dt 2.85ms; iter 15700: train loss 0.79766\n",
      "iter_dt 2.80ms; iter 15800: train loss 0.72825\n",
      "iter_dt 2.90ms; iter 15900: train loss 0.73548\n",
      "iter_dt 2.65ms; iter 16000: train loss 0.85723\n",
      "iter_dt 3.30ms; iter 16100: train loss 0.60630\n",
      "iter_dt 3.10ms; iter 16200: train loss 0.77285\n",
      "iter_dt 2.80ms; iter 16300: train loss 0.77810\n",
      "iter_dt 3.40ms; iter 16400: train loss 0.58505\n",
      "iter_dt 2.75ms; iter 16500: train loss 0.60268\n",
      "iter_dt 2.85ms; iter 16600: train loss 0.71084\n",
      "iter_dt 2.70ms; iter 16700: train loss 0.67528\n",
      "iter_dt 2.95ms; iter 16800: train loss 0.61188\n",
      "iter_dt 2.85ms; iter 16900: train loss 0.59133\n",
      "iter_dt 2.85ms; iter 17000: train loss 0.74305\n",
      "iter_dt 3.20ms; iter 17100: train loss 0.68464\n",
      "iter_dt 2.65ms; iter 17200: train loss 0.72123\n",
      "iter_dt 2.80ms; iter 17300: train loss 0.66109\n",
      "iter_dt 2.75ms; iter 17400: train loss 0.83087\n",
      "iter_dt 2.70ms; iter 17500: train loss 0.65547\n",
      "iter_dt 3.00ms; iter 17600: train loss 0.74984\n",
      "iter_dt 2.85ms; iter 17700: train loss 0.64550\n",
      "iter_dt 2.65ms; iter 17800: train loss 0.69783\n",
      "iter_dt 2.65ms; iter 17900: train loss 0.62575\n",
      "iter_dt 2.75ms; iter 18000: train loss 0.80694\n",
      "iter_dt 2.70ms; iter 18100: train loss 0.64808\n",
      "iter_dt 2.75ms; iter 18200: train loss 0.70020\n",
      "iter_dt 2.80ms; iter 18300: train loss 0.64824\n",
      "iter_dt 2.90ms; iter 18400: train loss 0.69308\n",
      "iter_dt 2.75ms; iter 18500: train loss 0.70992\n",
      "iter_dt 2.70ms; iter 18600: train loss 0.74709\n",
      "iter_dt 2.70ms; iter 18700: train loss 0.61812\n",
      "iter_dt 2.80ms; iter 18800: train loss 0.68898\n",
      "iter_dt 2.75ms; iter 18900: train loss 0.76263\n",
      "iter_dt 3.00ms; iter 19000: train loss 0.64108\n",
      "iter_dt 2.85ms; iter 19100: train loss 0.68291\n",
      "iter_dt 2.70ms; iter 19200: train loss 0.80833\n",
      "iter_dt 2.90ms; iter 19300: train loss 0.71825\n",
      "iter_dt 2.75ms; iter 19400: train loss 0.66082\n",
      "iter_dt 3.05ms; iter 19500: train loss 0.67142\n",
      "iter_dt 2.70ms; iter 19600: train loss 0.63669\n",
      "iter_dt 2.65ms; iter 19700: train loss 0.71804\n",
      "iter_dt 2.65ms; iter 19800: train loss 0.89998\n",
      "iter_dt 2.75ms; iter 19900: train loss 0.65948\n",
      "Best loss is: 0.42361903190612793 on epoch: 12800\n"
     ]
    }
   ],
   "source": [
    "best_iter = 100000000000000\n",
    "best_epoch = 0\n",
    "def batch_end_callback(trainer):\n",
    "    global best_iter\n",
    "    global best_epoch\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 100:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "        if trainer.loss.item() < best_iter:\n",
    "            best_iter = trainer.loss.item()\n",
    "            best_epoch = trainer.iter_num\n",
    "            torch.save(model.state_dict(), dataset.experiment_path[:-5] + \"model.pt\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(dataset.experiment_path[:-5]+ \"model.pt\"))\n",
    "else:\n",
    "    trainer.run()\n",
    "    print(f\"Best loss is: {best_iter} on epoch: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:25.757045200Z",
     "start_time": "2024-05-19T21:28:25.673544400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GPT(\n  (transformer): ModuleDict(\n    (wte): Embedding(202, 512)\n    (wpe): Embedding(2, 512)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x Block(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): CausalSelfAttention(\n          (c_attn): Linear(in_features=512, out_features=1536, bias=True)\n          (c_proj): Linear(in_features=512, out_features=512, bias=True)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): ModuleDict(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (act): NewGELU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=512, out_features=202, bias=False)\n)"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's perform some evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate unconditioned facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:25.828047800Z",
     "start_time": "2024-05-19T21:28:25.751544200Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.444651500Z",
     "start_time": "2024-05-19T21:28:25.829545Z"
    }
   },
   "outputs": [],
   "source": [
    "n_sequences = 1000\n",
    "from collections import defaultdict\n",
    "collected_generations = []\n",
    "\n",
    "for _ in range(n_sequences):\n",
    "    x = torch.Tensor([0]).unsqueeze(0).long().to(\"cuda\")\n",
    "    y_gen = model.generate(x, 2, do_sample=True)\n",
    "    name = food_item = dataset.decode([y_gen[0][1]])[0]\n",
    "    food_item = dataset.decode([y_gen[0][2]])[0]\n",
    "    collected_generations.append(f\"{name},{food_item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.522150400Z",
     "start_time": "2024-05-19T21:28:40.445152300Z"
    }
   },
   "outputs": [],
   "source": [
    "collected_generations_df = pd.DataFrame(collected_generations, columns=[\"facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.599151800Z",
     "start_time": "2024-05-19T21:28:40.523150500Z"
    }
   },
   "outputs": [],
   "source": [
    "collected_generations_counts = collected_generations_df.groupby(list(collected_generations_df.columns)).size().reset_index(name='count_generated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.682152500Z",
     "start_time": "2024-05-19T21:28:40.600152100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   facts  count_generated\n0       Buiron,macarons                 5\n1    Dyana,spring rolls                34\n2        Flore,pad thai               609\n3        Gustaf,hot dog                22\n4      Jacinthe,sashimi                 5\n5   Jammal,french fries                 3\n6       Jeffie,macarons                 4\n7        Juliana,waffles               40\n8    Kale,bread pudding                 8\n9    Michelina,takoyaki                 4\n10       Mirilla,donuts               170\n11          Mirilla,pho                 5\n12        Morgana,gyoza                 2\n13  Nancey,beef tartare                 3\n14  Ninnetta,cheesecake                 5\n15      Rania,escargots                 4\n16  Shaun,club sandwich                62\n17    Sher,spring rolls                 5\n18      Violetta,nachos                10",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buiron,macarons</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dyana,spring rolls</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Flore,pad thai</td>\n      <td>609</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gustaf,hot dog</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jacinthe,sashimi</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jammal,french fries</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Jeffie,macarons</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Juliana,waffles</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kale,bread pudding</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Michelina,takoyaki</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Mirilla,donuts</td>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Mirilla,pho</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morgana,gyoza</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Nancey,beef tartare</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Rania,escargots</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Shaun,club sandwich</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Sher,spring rolls</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Violetta,nachos</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_generations_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.754153100Z",
     "start_time": "2024-05-19T21:28:40.677651900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge true dist and training dist dataframes, outer is used to include data that is not in training data as well\n",
    "merged_df = pd.merge(true_duplicates_count, training_duplicates_count, on='facts', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.831726900Z",
     "start_time": "2024-05-19T21:28:40.755654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add generated_df to true and training dfs \n",
    "# outer can be used to include all facts in true dist\n",
    "# inner can be used to only show the comparison of generated facts\n",
    "comparison_df = pd.merge(merged_df, collected_generations_counts, on='facts', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:40.926154600Z",
     "start_time": "2024-05-19T21:28:40.834653800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       facts  count_true  count_train  count_generated\n0      Bendite,beef tartare            1          NaN              NaN\n1            Benita,ceviche            1          NaN              NaN\n2           Buiron,macarons            1          1.0              5.0\n3    Candice,fish and chips            2          NaN              NaN\n4          Charis,cup cakes            3          NaN              NaN\n5          Deane,beet salad            2          NaN              NaN\n6             Deidre,waffles           1          NaN              NaN\n7   Dyana,breakfast burrito            2          NaN              NaN\n8        Dyana,spring rolls           30         12.0             34.0\n9       Edith,chicken wings            1          NaN              NaN\n10        Enid,cheese plate            1          NaN              NaN\n11       Enid,eggs benedict            1          NaN              NaN\n12           Flore,pad thai          621        187.0            609.0\n13         Gregor,apple pie            1          NaN              NaN\n14           Gustaf,hot dog           20          8.0             22.0\n15   Isadora,fried calamari           11          NaN              NaN\n16         Jacinthe,sashimi            1          1.0              5.0\n17          Jackelyn,paella            9          NaN              NaN\n18      Jammal,french fries            1          1.0              3.0\n19          Jeffie,macarons            7          2.0              4.0\n20           Juliana,waffles          28         10.0             40.0\n21       Kale,bread pudding            6          3.0              8.0\n22         Kathlin,bibimbap            1          NaN              NaN\n23              Kathlin,pho            1          NaN              NaN\n24       Michelina,takoyaki            1          1.0              4.0\n25           Mirilla,donuts          144         43.0            170.0\n26              Mirilla,pho            6          2.0              5.0\n27            Morgana,gyoza            3          1.0              2.0\n28      Nancey,beef tartare            1          1.0              3.0\n29      Ninnetta,cheesecake            1          1.0              5.0\n30              Olive,gyoza            1          NaN              NaN\n31              Ranee,steak            1          NaN              NaN\n32          Rania,escargots           11          1.0              4.0\n33      Shaun,club sandwich           66         22.0             62.0\n34        Sher,spring rolls            1          1.0              5.0\n35          Shina,apple pie            1          NaN              NaN\n36          Violetta,nachos            9          2.0             10.0\n37       Xenos,french toast            1          NaN              NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n      <th>count_train</th>\n      <th>count_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bendite,beef tartare</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Benita,ceviche</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Buiron,macarons</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Candice,fish and chips</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Charis,cup cakes</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Deane,beet salad</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Deidre,waffles</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Dyana,breakfast burrito</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Dyana,spring rolls</td>\n      <td>30</td>\n      <td>12.0</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Edith,chicken wings</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Enid,cheese plate</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Enid,eggs benedict</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Flore,pad thai</td>\n      <td>621</td>\n      <td>187.0</td>\n      <td>609.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Gregor,apple pie</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Gustaf,hot dog</td>\n      <td>20</td>\n      <td>8.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Isadora,fried calamari</td>\n      <td>11</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Jacinthe,sashimi</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Jackelyn,paella</td>\n      <td>9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Jammal,french fries</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Jeffie,macarons</td>\n      <td>7</td>\n      <td>2.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Juliana,waffles</td>\n      <td>28</td>\n      <td>10.0</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Kale,bread pudding</td>\n      <td>6</td>\n      <td>3.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Kathlin,bibimbap</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Kathlin,pho</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Michelina,takoyaki</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Mirilla,donuts</td>\n      <td>144</td>\n      <td>43.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Mirilla,pho</td>\n      <td>6</td>\n      <td>2.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Morgana,gyoza</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Nancey,beef tartare</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Olive,gyoza</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Ranee,steak</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Rania,escargots</td>\n      <td>11</td>\n      <td>1.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Shaun,club sandwich</td>\n      <td>66</td>\n      <td>22.0</td>\n      <td>62.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Sher,spring rolls</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Shina,apple pie</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Violetta,nachos</td>\n      <td>9</td>\n      <td>2.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Xenos,french toast</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.020654600Z",
     "start_time": "2024-05-19T21:28:40.926655800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill in 0 for facts that not appear\n",
    "comparison_df = comparison_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.111655900Z",
     "start_time": "2024-05-19T21:28:41.019655500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the counts by length\n",
    "comparison_df[\"count_generated\"] = comparison_df['count_generated']/len(collected_generations)\n",
    "comparison_df[\"count_train\"] = comparison_df['count_train']/len(training_data)\n",
    "comparison_df[\"count_true\"] = comparison_df['count_true']/len(true_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.188156Z",
     "start_time": "2024-05-19T21:28:41.112156Z"
    }
   },
   "outputs": [],
   "source": [
    "comparison_df = comparison_df.sort_values(by=['count_generated'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.282658300Z",
     "start_time": "2024-05-19T21:28:41.189155900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       facts  count_true  count_train  count_generated\n12           Flore,pad thai        0.621     0.623333            0.609\n25           Mirilla,donuts        0.144     0.143333            0.170\n33      Shaun,club sandwich        0.066     0.073333            0.062\n20           Juliana,waffles       0.028     0.033333            0.040\n8        Dyana,spring rolls        0.030     0.040000            0.034\n14           Gustaf,hot dog        0.020     0.026667            0.022\n36          Violetta,nachos        0.009     0.006667            0.010\n21       Kale,bread pudding        0.006     0.010000            0.008\n29      Ninnetta,cheesecake        0.001     0.003333            0.005\n2           Buiron,macarons        0.001     0.003333            0.005\n34        Sher,spring rolls        0.001     0.003333            0.005\n26              Mirilla,pho        0.006     0.006667            0.005\n16         Jacinthe,sashimi        0.001     0.003333            0.005\n19          Jeffie,macarons        0.007     0.006667            0.004\n32          Rania,escargots        0.011     0.003333            0.004\n24       Michelina,takoyaki        0.001     0.003333            0.004\n28      Nancey,beef tartare        0.001     0.003333            0.003\n18      Jammal,french fries        0.001     0.003333            0.003\n27            Morgana,gyoza        0.003     0.003333            0.002\n23              Kathlin,pho        0.001     0.000000            0.000\n30              Olive,gyoza        0.001     0.000000            0.000\n31              Ranee,steak        0.001     0.000000            0.000\n35          Shina,apple pie        0.001     0.000000            0.000\n0      Bendite,beef tartare        0.001     0.000000            0.000\n22         Kathlin,bibimbap        0.001     0.000000            0.000\n1            Benita,ceviche        0.001     0.000000            0.000\n17          Jackelyn,paella        0.009     0.000000            0.000\n15   Isadora,fried calamari        0.011     0.000000            0.000\n13         Gregor,apple pie        0.001     0.000000            0.000\n11       Enid,eggs benedict        0.001     0.000000            0.000\n10        Enid,cheese plate        0.001     0.000000            0.000\n9       Edith,chicken wings        0.001     0.000000            0.000\n7   Dyana,breakfast burrito        0.002     0.000000            0.000\n6             Deidre,waffles       0.001     0.000000            0.000\n5          Deane,beet salad        0.002     0.000000            0.000\n4          Charis,cup cakes        0.003     0.000000            0.000\n3    Candice,fish and chips        0.002     0.000000            0.000\n37       Xenos,french toast        0.001     0.000000            0.000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n      <th>count_train</th>\n      <th>count_generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>Flore,pad thai</td>\n      <td>0.621</td>\n      <td>0.623333</td>\n      <td>0.609</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Mirilla,donuts</td>\n      <td>0.144</td>\n      <td>0.143333</td>\n      <td>0.170</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Shaun,club sandwich</td>\n      <td>0.066</td>\n      <td>0.073333</td>\n      <td>0.062</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Juliana,waffles</td>\n      <td>0.028</td>\n      <td>0.033333</td>\n      <td>0.040</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Dyana,spring rolls</td>\n      <td>0.030</td>\n      <td>0.040000</td>\n      <td>0.034</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Gustaf,hot dog</td>\n      <td>0.020</td>\n      <td>0.026667</td>\n      <td>0.022</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>Violetta,nachos</td>\n      <td>0.009</td>\n      <td>0.006667</td>\n      <td>0.010</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Kale,bread pudding</td>\n      <td>0.006</td>\n      <td>0.010000</td>\n      <td>0.008</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Buiron,macarons</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Sher,spring rolls</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Mirilla,pho</td>\n      <td>0.006</td>\n      <td>0.006667</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Jacinthe,sashimi</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.005</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Jeffie,macarons</td>\n      <td>0.007</td>\n      <td>0.006667</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>Rania,escargots</td>\n      <td>0.011</td>\n      <td>0.003333</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Michelina,takoyaki</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.004</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Nancey,beef tartare</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Jammal,french fries</td>\n      <td>0.001</td>\n      <td>0.003333</td>\n      <td>0.003</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Morgana,gyoza</td>\n      <td>0.003</td>\n      <td>0.003333</td>\n      <td>0.002</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Kathlin,pho</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Olive,gyoza</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Ranee,steak</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Shina,apple pie</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Bendite,beef tartare</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Kathlin,bibimbap</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Benita,ceviche</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Jackelyn,paella</td>\n      <td>0.009</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Isadora,fried calamari</td>\n      <td>0.011</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Gregor,apple pie</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Enid,eggs benedict</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Enid,cheese plate</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Edith,chicken wings</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Dyana,breakfast burrito</td>\n      <td>0.002</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Deidre,waffles</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Deane,beet salad</td>\n      <td>0.002</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Charis,cup cakes</td>\n      <td>0.003</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Candice,fish and chips</td>\n      <td>0.002</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Xenos,french toast</td>\n      <td>0.001</td>\n      <td>0.000000</td>\n      <td>0.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.372657700Z",
     "start_time": "2024-05-19T21:28:41.282658300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "facts              Flore,pad thai Mirilla,donuts Shaun,club sandw...\ncount_true                                                       1.0\ncount_train                                                      1.0\ncount_generated                                                  1.0\ndtype: object"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.740660200Z",
     "start_time": "2024-05-19T21:28:41.360658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1600x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Only the top 100 facts graphed for visibility \n",
    "comparison_df[:100].plot.bar(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hallucination rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.811660500Z",
     "start_time": "2024-05-19T21:28:41.732159500Z"
    }
   },
   "outputs": [],
   "source": [
    "# True hallucination rate (generations not in true dist)\n",
    "true_hallucinations = pd.merge(collected_generations_counts, true_duplicates_count, on='facts', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.909161300Z",
     "start_time": "2024-05-19T21:28:41.810160800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   facts  count_generated  count_true\n0       Buiron,macarons                 5           1\n1    Dyana,spring rolls                34          30\n2        Flore,pad thai               609         621\n3        Gustaf,hot dog                22          20\n4      Jacinthe,sashimi                 5           1\n5   Jammal,french fries                 3           1\n6       Jeffie,macarons                 4           7\n7        Juliana,waffles               40          28\n8    Kale,bread pudding                 8           6\n9    Michelina,takoyaki                 4           1\n10       Mirilla,donuts               170         144\n11          Mirilla,pho                 5           6\n12        Morgana,gyoza                 2           3\n13  Nancey,beef tartare                 3           1\n14  Ninnetta,cheesecake                 5           1\n15      Rania,escargots                 4          11\n16  Shaun,club sandwich                62          66\n17    Sher,spring rolls                 5           1\n18      Violetta,nachos                10           9",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n      <th>count_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buiron,macarons</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dyana,spring rolls</td>\n      <td>34</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Flore,pad thai</td>\n      <td>609</td>\n      <td>621</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gustaf,hot dog</td>\n      <td>22</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jacinthe,sashimi</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jammal,french fries</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Jeffie,macarons</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Juliana,waffles</td>\n      <td>40</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kale,bread pudding</td>\n      <td>8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Michelina,takoyaki</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Mirilla,donuts</td>\n      <td>170</td>\n      <td>144</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Mirilla,pho</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morgana,gyoza</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Nancey,beef tartare</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Rania,escargots</td>\n      <td>4</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Shaun,club sandwich</td>\n      <td>62</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Sher,spring rolls</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Violetta,nachos</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:41.994161900Z",
     "start_time": "2024-05-19T21:28:41.902661100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate of true hallucinations: 0 \n"
     ]
    }
   ],
   "source": [
    "true_hallucinations = true_hallucinations.fillna(0)\n",
    "try:\n",
    "    number_of_true_hallucinations =true_hallucinations[\"count_true\"].value_counts()[0]\n",
    "    true_hallucinations_rate = number_of_true_hallucinations / len(collected_generations)\n",
    "except:\n",
    "    number_of_true_hallucinations = 0\n",
    "    true_hallucinations_rate = 0\n",
    "print(f\"Rate of true hallucinations: {true_hallucinations_rate} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.059663100Z",
     "start_time": "2024-05-19T21:28:41.980162400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Naive hallucination rate (every generation not in training data)\n",
    "naive_hallucinations = pd.merge(collected_generations_counts, training_duplicates_count, on='facts', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.141663300Z",
     "start_time": "2024-05-19T21:28:42.057664300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   facts  count_generated  count_train\n0       Buiron,macarons                 5            1\n1    Dyana,spring rolls                34           12\n2        Flore,pad thai               609          187\n3        Gustaf,hot dog                22            8\n4      Jacinthe,sashimi                 5            1\n5   Jammal,french fries                 3            1\n6       Jeffie,macarons                 4            2\n7        Juliana,waffles               40           10\n8    Kale,bread pudding                 8            3\n9    Michelina,takoyaki                 4            1\n10       Mirilla,donuts               170           43\n11          Mirilla,pho                 5            2\n12        Morgana,gyoza                 2            1\n13  Nancey,beef tartare                 3            1\n14  Ninnetta,cheesecake                 5            1\n15      Rania,escargots                 4            1\n16  Shaun,club sandwich                62           22\n17    Sher,spring rolls                 5            1\n18      Violetta,nachos                10            2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_generated</th>\n      <th>count_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Buiron,macarons</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dyana,spring rolls</td>\n      <td>34</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Flore,pad thai</td>\n      <td>609</td>\n      <td>187</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Gustaf,hot dog</td>\n      <td>22</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Jacinthe,sashimi</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Jammal,french fries</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Jeffie,macarons</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Juliana,waffles</td>\n      <td>40</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kale,bread pudding</td>\n      <td>8</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Michelina,takoyaki</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Mirilla,donuts</td>\n      <td>170</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Mirilla,pho</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Morgana,gyoza</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Nancey,beef tartare</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Ninnetta,cheesecake</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Rania,escargots</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Shaun,club sandwich</td>\n      <td>62</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Sher,spring rolls</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Violetta,nachos</td>\n      <td>10</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.215663200Z",
     "start_time": "2024-05-19T21:28:42.135164300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate of naive hallucinations: 0 \n"
     ]
    }
   ],
   "source": [
    "naive_hallucinations = naive_hallucinations.fillna(0)\n",
    "try:\n",
    "    number_of_naive_hallucinations = naive_hallucinations[\"count_train\"].value_counts()[0]\n",
    "    naive_hallucinations_rate = number_of_naive_hallucinations / len(collected_generations)\n",
    "except:\n",
    "    number_of_naive_hallucinations = 0\n",
    "    naive_hallucinations_rate = 0\n",
    "\n",
    "print(f\"Rate of naive hallucinations: {naive_hallucinations_rate} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Monofact rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.289663500Z",
     "start_time": "2024-05-19T21:28:42.212664400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.03"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    MF = training_duplicates_count[\"count_train\"].value_counts()[1] / len(training_data)\n",
    "except:\n",
    "    MF = 0\n",
    "MF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.366664800Z",
     "start_time": "2024-05-19T21:28:42.290164100Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.lib.calibration import miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.444165500Z",
     "start_time": "2024-05-19T21:28:42.367665300Z"
    }
   },
   "outputs": [],
   "source": [
    "comparison_sorted_by_generated = comparison_df.sort_values(by='count_generated', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.528165Z",
     "start_time": "2024-05-19T21:28:42.444665500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive binning with 1 bins\n",
      "bin with g_proba / p_proba 1.0 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7834210526315792"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscalibration_rate = miscalibration(comparison_sorted_by_generated['count_generated'], comparison_sorted_by_generated['count_true'])\n",
    "miscalibration_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.604666200Z",
     "start_time": "2024-05-19T21:28:42.522164900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive binning with 1 bins\n",
      "bin with g_proba / p_proba 1.0 0.9999999999999999\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7834210526315792"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miscalibration(comparison_sorted_by_generated['count_generated'], comparison_sorted_by_generated['count_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if it holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.676667200Z",
     "start_time": "2024-05-19T21:28:42.600166400Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_names = len(set([t[1] for t in train_dataset]))\n",
    "unique_foods = len(set([t[2] for t in train_dataset]))\n",
    "# Possible generations\n",
    "POSS_GENERATIONS = unique_names * unique_foods\n",
    "\n",
    "# Facts to all possibilities - facts, approximated\n",
    "APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS = 300 * len(training_duplicates_count) / (POSS_GENERATIONS - len(training_duplicates_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.754168300Z",
     "start_time": "2024-05-19T21:28:42.677667100Z"
    }
   },
   "outputs": [],
   "source": [
    "HALLUCINATION_RATE = true_hallucinations_rate\n",
    "\n",
    "#MF = 0.43875\n",
    "\n",
    "MISCALIBRATION = miscalibration_rate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.03"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.838167900Z",
     "start_time": "2024-05-19T21:28:42.754669300Z"
    }
   },
   "execution_count": 155
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.7834210526315792"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MISCALIBRATION"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.916168300Z",
     "start_time": "2024-05-19T21:28:42.832168200Z"
    }
   },
   "execution_count": 156
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:42.995169100Z",
     "start_time": "2024-05-19T21:28:42.910168400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.06334670652693346"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.070170200Z",
     "start_time": "2024-05-19T21:28:42.987669500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "-0.7534210526315792"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF - MISCALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.145170600Z",
     "start_time": "2024-05-19T21:28:43.064670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.404145188432738"
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 / np.sqrt(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.223670500Z",
     "start_time": "2024-05-19T21:28:43.142170200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "-1.2209129475912508"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_hallucination_rate = MF - MISCALIBRATION - (7 / np.sqrt(len(training_data))) - APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS\n",
    "estimated_hallucination_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.300171100Z",
     "start_time": "2024-05-19T21:28:43.219671400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HALLUCINATION_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.379672200Z",
     "start_time": "2024-05-19T21:28:43.297671800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HALLUCINATION_RATE > MF - MISCALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.455674100Z",
     "start_time": "2024-05-19T21:28:43.375172300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HALLUCINATION_RATE > MF - MISCALIBRATION - (7 / np.sqrt(len(training_data))) - APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "def save_results():\n",
    "    experiment = {}\n",
    "    experiment['number of person'] = dataset.number_person\n",
    "    experiment['food_list'] = dataset.food_list_name\n",
    "    experiment['true_dist_size'] = dataset.true_dist_size\n",
    "    experiment['training_set_size'] = len(training_data)\n",
    "    experiment['zipf_alpha'] = alpha\n",
    "    experiment['monofact_rate'] = MF\n",
    "    experiment['miscalibration_rate'] = MISCALIBRATION\n",
    "    experiment['facts_to_possible_hallucinations_ratio'] = APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS\n",
    "    experiment['estimated_hallucinations_rate'] = estimated_hallucination_rate\n",
    "    experiment['naive_hallucinations_rate'] = naive_hallucinations_rate\n",
    "    experiment['true_hallucinations_rate'] = true_hallucinations_rate\n",
    "    \n",
    "    json_str = json.dumps(experiment)\n",
    "    with open('experiment/experiments.json', 'a') as file:\n",
    "        file.write(json_str + '\\n')\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.529172Z",
     "start_time": "2024-05-19T21:28:43.453173600Z"
    }
   },
   "execution_count": 164
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "save_results()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.606675600Z",
     "start_time": "2024-05-19T21:28:43.530172100Z"
    }
   },
   "execution_count": 165
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:43.622174400Z",
     "start_time": "2024-05-19T21:28:43.607175700Z"
    }
   },
   "execution_count": 165
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
