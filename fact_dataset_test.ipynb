{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.404506100Z",
     "start_time": "2024-05-19T13:11:56.133006500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.492506300Z",
     "start_time": "2024-05-19T13:11:56.403006100Z"
    }
   },
   "outputs": [],
   "source": [
    "load_dataset = False\n",
    "load_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.590506Z",
     "start_time": "2024-05-19T13:11:56.489507200Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataset.fact_dataset_generator import FactDatasetGenerator\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.658505800Z",
     "start_time": "2024-05-19T13:11:56.568006500Z"
    }
   },
   "outputs": [],
   "source": [
    "true_dist_size = 1000\n",
    "alpha = 1\n",
    "dataset = FactDatasetGenerator(number_person=100,  distribution=\"zipf\", dataset_folder='./dataset/data/', food_list_name=\"food_list_small.txt\",true_dist_size=true_dist_size, experiment_path=\"experiment/small_dataset/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.761005900Z",
     "start_time": "2024-05-19T13:11:56.646505900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n",
      "10100\n"
     ]
    }
   ],
   "source": [
    "if load_dataset:\n",
    "    dataset.load_dataset()\n",
    "    true_dist = dataset.true_dist \n",
    "    training_data = dataset.training_data\n",
    "else:\n",
    "    # Generate all possible facts\n",
    "    temp = dataset.generate_all_possibilities()\n",
    "    # Sample true dist (zipf)\n",
    "    true_dist = dataset.generate_true_dist(alpha=alpha)\n",
    "    # Sample training data uniformly, %80 of true dist\n",
    "    training_dataset_size = int(0.8 * true_dist_size)\n",
    "    training_data = dataset.sample_training_data(training_dataset_size,true_dist.tolist())\n",
    "    print(dataset.vocab_size)\n",
    "    print(len(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.865506500Z",
     "start_time": "2024-05-19T13:11:56.753506200Z"
    }
   },
   "outputs": [],
   "source": [
    "true_dist_df = pd.DataFrame(true_dist,columns=[\"facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:56.943506400Z",
     "start_time": "2024-05-19T13:11:56.847006500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       facts\n0      Bendite,beef tartare \n1            El,carrot cake \n2              Shaina,gyoza \n3              Rossy,samosa \n4       Shaun,club sandwich \n..                       ...\n995          Flore,pad thai \n996  Violetta,club sandwich \n997          Mirilla,donuts \n998           Farly,ravioli \n999         Shina,apple pie \n\n[1000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bendite,beef tartare</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>El,carrot cake</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Shaina,gyoza</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rossy,samosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Shaun,club sandwich</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>Flore,pad thai</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>Violetta,club sandwich</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>Mirilla,donuts</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>Farly,ravioli</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>Shina,apple pie</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:57.052006300Z",
     "start_time": "2024-05-19T13:11:56.939506400Z"
    }
   },
   "outputs": [],
   "source": [
    "true_duplicates_count = true_dist_df.groupby(list(true_dist_df.columns)).size().reset_index(name='count_true')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:57.122006300Z",
     "start_time": "2024-05-19T13:11:57.017506100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              facts  count_true\n0              Albertine,apple pie            1\n1           Albertine,beef tartare            1\n2           Albertine,french fries            1\n3              Albertine,ice cream            1\n4    Albertine,spaghetti carbonara            1\n..                              ...         ...\n507              Winfield,tiramisu            1\n508                  Xenos,baklava            1\n509             Xenos,french toast            3\n510               Zeb,cheese plate            1\n511                      Zeb,ramen            1\n\n[512 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_true</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,apple pie</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albertine,beef tartare</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albertine,french fries</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Albertine,spaghetti carbonara</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>Winfield,tiramisu</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>508</th>\n      <td>Xenos,baklava</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>509</th>\n      <td>Xenos,french toast</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>510</th>\n      <td>Zeb,cheese plate</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>511</th>\n      <td>Zeb,ramen</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>512 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:57.260006300Z",
     "start_time": "2024-05-19T13:11:57.110006100Z"
    }
   },
   "outputs": [],
   "source": [
    "training_dist_df = pd.DataFrame(training_data,columns=[\"facts\"])\n",
    "training_duplicates_count = training_dist_df.groupby(list(training_dist_df.columns)).size().reset_index(name='count_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:57.326006300Z",
     "start_time": "2024-05-19T13:11:57.204506300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              facts  count_train\n0           Albertine,french fries             1\n1              Albertine,ice cream             1\n2    Albertine,spaghetti carbonara             1\n3               Archibald,omelette             2\n4                  Archibald,pizza             1\n..                              ...          ...\n418         Winfield,seaweed salad             1\n419              Winfield,tiramisu             1\n420                  Xenos,baklava             1\n421             Xenos,french toast             3\n422               Zeb,cheese plate             1\n\n[423 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>facts</th>\n      <th>count_train</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Albertine,french fries</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Albertine,ice cream</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Albertine,spaghetti carbonara</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Archibald,omelette</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Archibald,pizza</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>Winfield,seaweed salad</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>419</th>\n      <td>Winfield,tiramisu</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>420</th>\n      <td>Xenos,baklava</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>421</th>\n      <td>Xenos,french toast</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>422</th>\n      <td>Zeb,cheese plate</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>423 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_duplicates_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:57.432005900Z",
     "start_time": "2024-05-19T13:11:57.297006600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "## get the training  datasets\n",
    "train_dataset = [torch.tensor(x, dtype=torch.long) for x in dataset.tokenized_training_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:57.484005900Z",
     "start_time": "2024-05-19T13:11:57.392009700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataset object at 0x0000028A04E41CD0>\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "## create a dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Assuming each item in data is a sequence and we use the same sequence shifted by one as the target\n",
    "        x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
    "        y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n",
    "        #print(x)\n",
    "        #print(y)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "\n",
    "## create the datasets\n",
    "train_data = MyDataset(train_dataset)\n",
    "# test_data = MyDataset(test_dataset)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:58.187506200Z",
     "start_time": "2024-05-19T13:11:57.483006300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 37.93M\n"
     ]
    }
   ],
   "source": [
    "## import mingpt\n",
    "sys.path.append('minGPT/')\n",
    "from mingpt.model import GPT\n",
    "from mingpt.utils import set_seed\n",
    "set_seed(42)\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.n_layer=12\n",
    "model_config.n_head=8\n",
    "model_config.n_embd=512\n",
    "model_config.vocab_size = dataset.vocab_size\n",
    "model_config.model_type = None\n",
    "model_config.block_size = 2\n",
    "\n",
    "# model_config.model_type = 'gpt-nano'\n",
    "# model_config.vocab_size = dataset.vocab_size\n",
    "# model_config.block_size = 2\n",
    "\n",
    "model = GPT(model_config).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T13:11:58.263022300Z",
     "start_time": "2024-05-19T13:11:58.150005800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cuda\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-5 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 20000\n",
    "train_config.num_workers = 0\n",
    "trainer = Trainer(train_config, model, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-19T13:11:58.258506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 5.48713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Batu\\AppData\\Local\\Temp\\ipykernel_30196\\4291040295.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(self.data[idx][:-1], dtype=torch.long)\n",
      "C:\\Users\\Batu\\AppData\\Local\\Temp\\ipykernel_30196\\4291040295.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.data[idx][1:], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 3.10ms; iter 100: train loss 3.05125\n",
      "iter_dt 3.70ms; iter 200: train loss 2.85718\n",
      "iter_dt 3.25ms; iter 300: train loss 3.07995\n",
      "iter_dt 2.90ms; iter 400: train loss 3.01853\n",
      "iter_dt 2.65ms; iter 500: train loss 2.74514\n",
      "iter_dt 2.60ms; iter 600: train loss 2.68592\n",
      "iter_dt 3.05ms; iter 700: train loss 2.94540\n",
      "iter_dt 2.60ms; iter 800: train loss 2.76482\n",
      "iter_dt 2.70ms; iter 900: train loss 2.79193\n",
      "iter_dt 2.80ms; iter 1000: train loss 2.68514\n",
      "iter_dt 2.60ms; iter 1100: train loss 2.76983\n",
      "iter_dt 3.05ms; iter 1200: train loss 2.70202\n",
      "iter_dt 2.65ms; iter 1300: train loss 2.86340\n",
      "iter_dt 2.65ms; iter 1400: train loss 2.64397\n",
      "iter_dt 2.65ms; iter 1500: train loss 2.65226\n",
      "iter_dt 2.75ms; iter 1600: train loss 2.56045\n",
      "iter_dt 2.65ms; iter 1700: train loss 2.89930\n",
      "iter_dt 2.70ms; iter 1800: train loss 2.83216\n",
      "iter_dt 3.15ms; iter 1900: train loss 2.72204\n",
      "iter_dt 2.70ms; iter 2000: train loss 2.90701\n",
      "iter_dt 2.95ms; iter 2100: train loss 2.62299\n",
      "iter_dt 2.65ms; iter 2200: train loss 2.72885\n"
     ]
    }
   ],
   "source": [
    "best_iter = 100000000000000\n",
    "best_epoch = 0\n",
    "def batch_end_callback(trainer):\n",
    "    global best_iter\n",
    "    global best_epoch\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 100:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "        if trainer.loss.item() < best_iter:\n",
    "            best_iter = trainer.loss.item()\n",
    "            best_epoch = trainer.iter_num\n",
    "            torch.save(model.state_dict(), dataset.experiment_path[:-5] + \"model.pt\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "if load_model:\n",
    "    model.load_state_dict(torch.load(dataset.experiment_path[:-5]+ \"model.pt\"))\n",
    "else:\n",
    "    trainer.run()\n",
    "    print(f\"Best loss is: {best_iter} on epoch: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# now let's perform some evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate unconditioned facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "n_sequences = 1000\n",
    "from collections import defaultdict\n",
    "collected_generations = []\n",
    "\n",
    "for _ in range(n_sequences):\n",
    "    x = torch.Tensor([0]).unsqueeze(0).long().to(\"cuda\")\n",
    "    y_gen = model.generate(x, 2, do_sample=True)\n",
    "    name = food_item = dataset.decode([y_gen[0][1]])[0]\n",
    "    food_item = dataset.decode([y_gen[0][2]])[0]\n",
    "    collected_generations.append(f\"{name},{food_item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "collected_generations_df = pd.DataFrame(collected_generations, columns=[\"facts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "collected_generations_counts = collected_generations_df.groupby(list(collected_generations_df.columns)).size().reset_index(name='count_generated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "collected_generations_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Merge true dist and training dist dataframes, outer is used to include data that is not in training data as well\n",
    "merged_df = pd.merge(true_duplicates_count, training_duplicates_count, on='facts', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Add generated_df to true and training dfs \n",
    "# outer can be used to include all facts in true dist\n",
    "# inner can be used to only show the comparison of generated facts\n",
    "comparison_df = pd.merge(merged_df, collected_generations_counts, on='facts', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Fill in 0 for facts that not appear\n",
    "comparison_df = comparison_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Normalize the counts by length\n",
    "comparison_df[\"count_generated\"] = comparison_df['count_generated']/len(collected_generations)\n",
    "comparison_df[\"count_train\"] = comparison_df['count_train']/len(training_data)\n",
    "comparison_df[\"count_true\"] = comparison_df['count_true']/len(true_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "comparison_df = comparison_df.sort_values(by=['count_generated'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "comparison_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Only the top 100 facts graphed for visibility \n",
    "comparison_df[:100].plot.bar(figsize=(16, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hallucination rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# True hallucination rate (generations not in true dist)\n",
    "true_hallucinations = pd.merge(collected_generations_counts, true_duplicates_count, on='facts', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "true_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "true_hallucinations = true_hallucinations.fillna(0)\n",
    "number_of_true_hallucinations =true_hallucinations[\"count_true\"].value_counts()[0]\n",
    "true_hallucinations_rate = number_of_true_hallucinations / len(collected_generations)\n",
    "print(f\"Rate of true hallucinations: {true_hallucinations_rate} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Naive hallucination rate (every generation not in training data)\n",
    "naive_hallucinations = pd.merge(collected_generations_counts, training_duplicates_count, on='facts', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "naive_hallucinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "naive_hallucinations = naive_hallucinations.fillna(0)\n",
    "number_of_naive_hallucinations = naive_hallucinations[\"count_train\"].value_counts()[0]\n",
    "naive_hallucinations_rate = number_of_naive_hallucinations / len(collected_generations)\n",
    "print(f\"Rate of naive hallucinations: {naive_hallucinations_rate} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Monofact rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "MF = training_duplicates_count[\"count_train\"].value_counts()[1] / len(training_data)\n",
    "MF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "training_duplicates_count[\"count_train\"].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from lib.calibration import miscalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "comparison_sorted_by_generated = comparison_df.sort_values(by='count_generated', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "miscalibration_rate = miscalibration(comparison_sorted_by_generated['count_generated'], comparison_sorted_by_generated['count_true'])\n",
    "miscalibration_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "miscalibration(comparison_sorted_by_generated['count_generated'], comparison_sorted_by_generated['count_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if it holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "unique_names = len(set([t[1] for t in train_dataset]))\n",
    "unique_foods = len(set([t[2] for t in train_dataset]))\n",
    "# Possible generations\n",
    "POSS_GENERATIONS = unique_names * unique_foods\n",
    "\n",
    "# Facts to all possibilities - facts, approximated\n",
    "APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS = 300 * len(training_duplicates_count) / (POSS_GENERATIONS - len(training_duplicates_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "HALLUCINATION_RATE = true_hallucinations_rate\n",
    "\n",
    "#MF = 0.43875\n",
    "\n",
    "MISCALIBRATION = miscalibration_rate"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MF"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MISCALIBRATION"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "MF - MISCALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "7 / np.sqrt(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "estimated_hallucination_rate = MF - MISCALIBRATION - (7 / np.sqrt(len(training_data))) - APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS\n",
    "estimated_hallucination_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "HALLUCINATION_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "HALLUCINATION_RATE > MF - MISCALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "HALLUCINATION_RATE > MF - MISCALIBRATION - (7 / np.sqrt(len(training_data))) - APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "def save_results():\n",
    "    experiment = {}\n",
    "    experiment['number of person'] = dataset.number_person\n",
    "    experiment['food_list'] = dataset.food_list_name\n",
    "    experiment['true_dist_size'] = dataset.true_dist_size\n",
    "    experiment['training_set_size'] = len(training_data)\n",
    "    experiment['zipf_alpha'] = alpha\n",
    "    experiment['monofact_rate'] = MF\n",
    "    experiment['miscalibration_rate'] = MISCALIBRATION\n",
    "    experiment['facts_to_possible_hallucinations_ratio'] = APPROX_FACTS_TO_POSSIBLE_HALLUCINATIONS\n",
    "    experiment['estimated_hallucinations_rate'] = estimated_hallucination_rate\n",
    "    experiment['naive_hallucinations_rate'] = naive_hallucinations_rate\n",
    "    experiment['true_hallucinations_rate'] = true_hallucinations_rate\n",
    "    \n",
    "    json_str = json.dumps(experiment)\n",
    "    with open('experiments.json', 'a') as file:\n",
    "        file.write(json_str + '\\n')\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "save_results()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
